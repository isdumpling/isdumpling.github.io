<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="知识笔记\r多阶段训练(multi-stage training)：指模型训练过程中分为多个阶段（阶段间目标或数据不同），每个阶段针对性地优化模型的不同能力，最终提升整体性能。\n"><title>故事汇：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
<link rel=canonical href=https://example.com/p/%E6%95%85%E4%BA%8B%E6%B1%87deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/><link rel=stylesheet href=/scss/style.min.2deeca980d2b0d58c1f28cdfd20b96c62f8357ef57495cd2d99f0054e39d1d6f.css><meta property='og:title' content="故事汇：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"><meta property='og:description' content="知识笔记\r多阶段训练(multi-stage training)：指模型训练过程中分为多个阶段（阶段间目标或数据不同），每个阶段针对性地优化模型的不同能力，最终提升整体性能。\n"><meta property='og:url' content='https://example.com/p/%E6%95%85%E4%BA%8B%E6%B1%87deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/'><meta property='og:site_name' content='一只饺子'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='机器学习'><meta property='article:tag' content='笔记'><meta property='article:tag' content='故事汇'><meta property='article:modified_time' content='2025-04-01T01:42:54+08:00'><meta property='og:image' content='https://example.com/post/img/26.jpg'><meta name=twitter:title content="故事汇：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"><meta name=twitter:description content="知识笔记\r多阶段训练(multi-stage training)：指模型训练过程中分为多个阶段（阶段间目标或数据不同），每个阶段针对性地优化模型的不同能力，最终提升整体性能。\n"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://example.com/post/img/26.jpg'><link rel="shortcut icon" href=/img/icon.svg><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/canvas-nest.js/2.0.4/canvas-nest.js></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/1fc88c9ce946a5621185d27c512d6ae_hu_bc1d6b840fc37823.jpg width=300 height=328 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>一只饺子</a></h1><h2 class=site-description>奶龙也是龙</h2></div></header><ol class=menu-social><li><a href=https://github.com/isdumpling target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/about><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://example.com/en/>English</option><option value=https://example.com/ selected>中文</option><option value=https://example.com/ar/>عربي</option></select></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#知识笔记>知识笔记</a></li><li><a href=#读书笔记>读书笔记</a><ol><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a><ol><li><a href=#核心贡献>核心贡献</a></li></ol></li><li><a href=#discussion>Discussion</a><ol><li><a href=#蒸馏和强化学习的比较>蒸馏和强化学习的比较</a></li><li><a href=#未成功的尝试>未成功的尝试</a></li></ol></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E6%95%85%E4%BA%8B%E6%B1%87deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/><img src=/post/img/26.jpg loading=lazy alt="Featured image of post 故事汇：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E6%95%85%E4%BA%8B%E6%B1%87deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/>故事汇：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</a></h2></div><footer class=article-time>最后修改:
<time class=article-time--updated datetime="2025-04-01 01:42:54 +0800 CST" title="2025-04-01 01:42:54 +0800 CST">2025-04-01</time><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><h2 id=知识笔记>知识笔记</h2><ul><li><p><strong>多阶段训练(multi-stage training)</strong>：指模型训练过程中分为多个阶段（阶段间目标或数据不同），每个阶段针对性地优化模型的不同能力，最终提升整体性能。</p></li><li><p><strong>冷启动数据(cold start data)</strong>：指在模型训练初期（或新任务启动时）使用的特定引导数据，用于解决模型初期因缺乏足够信息导致的性能低下或不稳定问题。</p></li><li><p><strong>训练后阶段</strong>：指在机器学习模型完成训练后的一系列操作，包括模型评估、优化、部署、监控等。</p></li><li><p><strong>预训练与训练的差别</strong></p><ul><li><strong>预训练</strong>：在大规模通用数据集上进行</li><li><strong>训练</strong>：在特定任务上调整模型参数的过程</li></ul></li><li><p><strong>推理导向的强化学习(Reasoning-Oriented RL)</strong>：动态奖励机制和结构化探索策略</p></li></ul><p><a class=link href=https://arxiv.org/pdf/2501.12948 target=_blank rel=noopener>原文传送门</a></p><p>膜拜大佬</p><h2 id=读书笔记>读书笔记</h2><h3 id=abstract>Abstract</h3><ul><li><strong>DeepSeek-R1-Zero</strong><ul><li>通过强化学习训练，且没监督微调</li><li>推理能力优秀</li><li>可读性差，语言混合</li></ul></li><li><strong>DeepSeek-R1</strong><ul><li>在强化学习之前结合多阶段训练和冷启动数据</li></ul></li></ul><h3 id=introduction>Introduction</h3><ul><li>训练后阶段可提高推理任务的准确性<ul><li>所需计算资源比预训练少</li></ul></li><li>OpenAI o1引入了思考时间<ul><li>有效的测试时间缩放的挑战依旧是一个问题</li></ul></li><li>使用纯强化学习过程的自我进化，使得DeepSeek-R1-Zero在推理基准测试上与OpenAI-01相当<ul><li>使用DeepSeek-v3-Base作为基础模型</li><li>采用PRPO作为强化学习框架</li><li>可读性差，语言混乱</li></ul></li><li>引入DeepSeek-R1。结合少量冷启动数据和多级训练流水线<ul><li><strong>冷启动数据微调</strong>：修复基础语言能力<ul><li>收集数千条高质量冷启动数据（例如：人工标注的数学解题步骤、语法规范的写作范文）</li><li>用这些数据对基础模型 <code>DeepSeek-V3-Base</code> 进行监督微调（SFT）。</li></ul></li><li><strong>推理导向的RL训练</strong>：提升特定任务的推理能力<ul><li>使用强化学习（如PPO算法）训练模型，奖励函数侧重推理正确性（如解题步骤分、最终答案分）。</li><li>训练接近收敛时，模型能稳定生成正确但可能可读性较差的答案</li></ul></li><li><strong>拒绝采样生成新SFT数据</strong>：从RL模型的结果中提取高质量数据，重新注入监督训练<ul><li>让RL模型的结果中提取高质量数据，重新注入监督训练</li><li>通过规则或奖励模型筛选出推理正确且可读性高的结果（例如保留前10%的优质答案）</li><li>混入新RL数据和原有监督数据</li><li>用混合数据重新微调DeepSeek-V3-Base</li></ul></li><li><strong>全场景二次RL训练</strong>：在多任务竞争中进一步平衡性能<ul><li>输入涵盖所有任务的提示（如同时包含数学题、写作要求、事实问答）</li><li>设计多维度奖励函数，如数学任务：步骤正确性+答案准确性；写作任务：流畅性+语法正确性</li><li>基于混合奖励进行RL训练，迫使模型兼顾多领域性能</li></ul></li></ul></li></ul><h4 id=核心贡献>核心贡献</h4><ol><li><p><strong>后训练(Post-Training)</strong>：直接对基础模型进行大规模强化学习（RL）</p><ol><li>创新点<ol><li>跳过监督微调(SFT)</li><li>激励模型自主探索思维链(CoT)</li></ol></li><li>意义：证明纯RL训练可激发LLM推理能力（无需SFT提供参考答案）</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-TEXT data-lang=TEXT><span class=line><span class=cl>步骤1：将方程改写为 3x² - 2x - 8 = 0  
</span></span><span class=line><span class=cl>步骤2：尝试因式分解 → 失败 → 反思：“可能需要使用求根公式。”  
</span></span><span class=line><span class=cl>步骤3：应用求根公式 x = [2 ± √(4 + 96)] / 6  
</span></span><span class=line><span class=cl>步骤4：计算判别式 √100 = 10 → x = (2 ± 10)/6  
</span></span><span class=line><span class=cl>步骤5：验证解是否满足原方程 → 确认 x=2 和 x=-4/3 均为解  
</span></span></code></pre></td></tr></table></div></div><ol start=3><li>开发流程<ol><li><strong>第一阶段RL</strong>：基于基础模型进行RL训练，奖励函数侧重推理正确性。探索更优推理模式（如数学解题策略、代码调试逻辑）</li><li><strong>第一阶段SFT</strong>：混合RL生成的优质推理数据与通用领域SFT数据。固化RL探索到的优质推理模式，并补充非推理能力（如写作、对话）。</li><li><strong>第二阶段RL</strong>：引入人类反馈（如人工标注偏好排序）优化奖励模型。对齐人类偏好（如可读性、安全性）</li><li><strong>第二阶段SFT</strong>：平衡多任务性能，防止RL过度优化单一领域</li></ol></li></ol></li><li><p><strong>蒸馏(Distillation)</strong>：让小模型继承大模型推理能力</p><ol><li><strong>核心思想</strong>：用大模型生成的推理数据训练小模型，使其超越RL训练的小模型</li><li>降低推理成本，促进小模型实际应用</li></ol></li></ol><h3 id=discussion>Discussion</h3><h4 id=蒸馏和强化学习的比较>蒸馏和强化学习的比较</h4><ul><li>将更强大的模型提炼成更小的模型可以得到很好的结果，而依赖于大规模RL的模型需要巨大的计算能力，甚至可能达不到提炼的性能</li><li>尽管提炼策略既经济又有效，但要超越智能的界限，可能仍然需要更强大的基础模型和更大规模的强化学习</li></ul><h4 id=未成功的尝试>未成功的尝试</h4><ul><li><strong>过程奖励模型(Process Reward Model, PRM)</strong><ul><li>在一般推理中明确定义一个细粒度的步骤是一个挑战</li><li>确定当前中间步骤是否正确是一项具有挑战性的任务</li><li>一旦引入了基于模型的PRM，就不可避免地会导致奖励黑客行为。而重新培训奖励模型需要额外的培训资源，这使整个培训流程变得复杂</li></ul></li><li><strong>蒙特卡洛树搜索(Monte Carlo Tree Search, MCTS)</strong><ul><li>将答案分解为更小的部分，以允许模型系统地探索解决方案空间</li><li>为了方便这一点，提示模型生成多个标签，这些标签对应于搜索所需的特定推理步骤</li><li>难点：<ul><li>token的生成有很多空间。解决方案：为每个节点设置最大扩展限制，但可能会陷入局部最优</li><li>价值模型直接影响生成的质量</li></ul></li></ul></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a>
<a href=/tags/%E7%AC%94%E8%AE%B0/>笔记</a>
<a href=/tags/%E6%95%85%E4%BA%8B%E6%B1%87/>故事汇</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 2025-04-01 01:42 CST</span></section><section class=article-pageviews><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/></svg>
<span>页面浏览量<span id=busuanzi_value_page_pv>Loading</span></span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E6%95%85%E4%BA%8B%E6%B1%87dynamic-distillation-network-for-cross-domain-few-shot-recognition-with-unlabeled-data/><div class=article-image><img src=/post/img/15.jpg loading=lazy data-key data-hash=/post/img/15.jpg></div><div class=article-details><h2 class=article-title>故事汇：Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data</h2></div></a></article><article class=has-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-1%E9%A2%84%E6%B5%8B%E6%9C%AC%E9%A2%91%E9%81%93%E8%A7%82%E6%B5%8B%E4%BA%BA%E6%95%B0%E4%B8%8A/><div class=article-image><img src=/post/img/4.jpg loading=lazy data-key data-hash=/post/img/4.jpg></div><div class=article-details><h2 class=article-title>机器学习（李宏毅）笔记 1：预测本频道观测人数（上）</h2></div></a></article><article class=has-image><a href=/p/pytorch%E8%AF%AD%E6%B3%95/><div class=article-image><img src=/post/img/12.jpg loading=lazy data-key data-hash=/post/img/12.jpg></div><div class=article-details><h2 class=article-title>PyTorch语法</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/><div class=article-image><img src=/post/img/13.jpg loading=lazy data-key data-hash=/post/img/13.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）1：线性模型</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA2%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/><div class=article-image><img src=/post/img/14.jpg loading=lazy data-key data-hash=/post/img/14.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）2：梯度下降算法</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2025 一只饺子</section><section class=powerby><div class=site-stats><span class=stat-item><i class="fas fa-users"></i> 访客数：<span id=busuanzi_value_site_uv>Loading</span>
</span><span class=stat-item><i class="fas fa-eye"></i> 访问量：<span id=busuanzi_value_site_pv>Loading</span>
</span><span class=stat-item><a href=https://eu.umami.is/share/y6kXo4CE3oYHXQ37/farb.github.io target=_blank rel=noopener><i class="fas fa-chart-line"></i> 详细统计</a></span></div><br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><!doctype html><html><head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js></script></head><body><div class=demo><div id=player1></div></div><script>var ap=new APlayer({element:document.getElementById("player1"),fixed:!0,autoplay:!1,mini:!0,theme:"#f8f4fc",loop:"all",order:"random",preload:"auto",volume:.4,mutex:!0,listFolded:!0,listMaxHeight:"500px",lrcType:0,music:[{name:"奶龙の小曲",artist:"我是奶龙",url:"/music/我是奶龙 (今夜星光闪闪)(DJ版) - 奶龙.mp3",cover:"/img/我是奶龙.jpg",weight:1},{name:"将军の小曲",artist:"恩！情！",url:"/music/阿悠悠 - 你若三冬（将军进行曲） (0_8xDJ沈乐版).mp3",cover:"/img/将军.png",weight:2},{name:"祁厅长进步の小曲",artist:"我太想进步了",url:"/music/鸳鸯戏 (哎呦小情郎你莫愁)(0.9x) - 略略略.mp3",cover:"/img/祁厅长の进步.jpg",weight:3},{name:"卡卡的小曲",artist:"忠！诚！",url:"/music/小轩仔仔-Shake And Sway (光州小曲).mp3",cover:"/img/全卡卡.jpg",weight:4}]})</script></body><style>#backTopBtn{display:none;position:fixed;bottom:30px;z-index:99;cursor:pointer;width:30px;height:30px;background-image:url(https://example.com/icons/backTop.svg)}</style><script>function initScrollTop(){let t=document.querySelector(".right-sidebar");if(!t)return;let e=document.createElement("div");e.id="backTopBtn",e.onclick=backToTop,t.appendChild(e),window.onscroll=function(){document.body.scrollTop>20||document.documentElement.scrollTop>20?e.style.display="block":e.style.display="none"}}function backToTop(){window.scrollTo({top:0,behavior:"smooth"})}initScrollTop()</script><script defer src=https://cn.vercount.one/js></script></body></html>