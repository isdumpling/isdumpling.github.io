<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="使用穷举法寻找线性回归模型中最佳权重参数w\r注意：\n对于numpy需要先下载依赖pip install numpy 对于matplotlib.pyplot，若有anaconda则无需下载 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import numpy as np; import matplotlib.pyplot as plt x_data = [1.0,2.0,3.0] y_data = [2.0,4.0,6.0] w_list = [] mse_list = [] # 定义前馈函数 def forward(x): return x * w # 定义损失函数 def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 for w in np.arange(0.0, 4.0, 0.1): print(&#34;w = &#34;, w) loss_sum = 0 # zip函数：将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表 for x_val, y_val in zip(x_data, y_data): y_pred_val = forward(x_val) loss_val = loss(x_val, y_val) loss_sum += loss_val print('\\t',x_val,y_val,y_pred_val,loss_val) print('MSE = ', loss_sum / 3) w_list.append(w) mse_list.append(loss_sum / 3) plt.plot(w_list, mse_list) plt.xlabel(&#34;w&#34;) plt.ylabel(&#34;loss&#34;) plt.show() 实现线性模型并输出loss的3D图形\r思路\r设计线性模型$y=\\omega x+b$ 预估$\\omega,b$的范围并用$W,B$数组存储 $\\omega=1_n \\cdot W,b=B\\cdot 1_m^T$构成参数空间$(w,b)$的笛卡尔积网络 $L_{sum}=0_{n\\times m}$ $MSE=\\frac{1}{N}\\sum$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D x_data = np.array([1.0, 2.0, 3.0]) y_data = np.array([5.0, 8.0, 11.0]) def forward(x): return x * w + b def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 W = np.arange(0.0, 4.1, 0.1) B = np.arange(0.0, 4.1, 0.1) w, b = np.meshgrid(W, B) loss_sum = np.zeros_like(w) for x_val, y_val in zip(x_data, y_data): loss_val = loss(x_val,y_val) loss_sum += loss_val mse = loss_sum / len(x_data) fig = plt.figure() # 创建一个新的窗口 ax = fig.add_subplot(111,projection='3d') # ax.plot_surface(w,b,mse,cmap='viridis') # camp='viridis'指定颜色映射 ax.set_xlabel('w') ax.set_ylabel('b') ax.set_zlabel('MSE') plt.show() "><title>Pytorch实践（刘二大人）1：线性模型</title>
<link rel=canonical href=https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/><link rel=stylesheet href=/scss/style.min.2deeca980d2b0d58c1f28cdfd20b96c62f8357ef57495cd2d99f0054e39d1d6f.css><meta property='og:title' content="Pytorch实践（刘二大人）1：线性模型"><meta property='og:description' content="使用穷举法寻找线性回归模型中最佳权重参数w\r注意：\n对于numpy需要先下载依赖pip install numpy 对于matplotlib.pyplot，若有anaconda则无需下载 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import numpy as np; import matplotlib.pyplot as plt x_data = [1.0,2.0,3.0] y_data = [2.0,4.0,6.0] w_list = [] mse_list = [] # 定义前馈函数 def forward(x): return x * w # 定义损失函数 def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 for w in np.arange(0.0, 4.0, 0.1): print(&#34;w = &#34;, w) loss_sum = 0 # zip函数：将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表 for x_val, y_val in zip(x_data, y_data): y_pred_val = forward(x_val) loss_val = loss(x_val, y_val) loss_sum += loss_val print('\\t',x_val,y_val,y_pred_val,loss_val) print('MSE = ', loss_sum / 3) w_list.append(w) mse_list.append(loss_sum / 3) plt.plot(w_list, mse_list) plt.xlabel(&#34;w&#34;) plt.ylabel(&#34;loss&#34;) plt.show() 实现线性模型并输出loss的3D图形\r思路\r设计线性模型$y=\\omega x+b$ 预估$\\omega,b$的范围并用$W,B$数组存储 $\\omega=1_n \\cdot W,b=B\\cdot 1_m^T$构成参数空间$(w,b)$的笛卡尔积网络 $L_{sum}=0_{n\\times m}$ $MSE=\\frac{1}{N}\\sum$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D x_data = np.array([1.0, 2.0, 3.0]) y_data = np.array([5.0, 8.0, 11.0]) def forward(x): return x * w + b def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 W = np.arange(0.0, 4.1, 0.1) B = np.arange(0.0, 4.1, 0.1) w, b = np.meshgrid(W, B) loss_sum = np.zeros_like(w) for x_val, y_val in zip(x_data, y_data): loss_val = loss(x_val,y_val) loss_sum += loss_val mse = loss_sum / len(x_data) fig = plt.figure() # 创建一个新的窗口 ax = fig.add_subplot(111,projection='3d') # ax.plot_surface(w,b,mse,cmap='viridis') # camp='viridis'指定颜色映射 ax.set_xlabel('w') ax.set_ylabel('b') ax.set_zlabel('MSE') plt.show() "><meta property='og:url' content='https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/'><meta property='og:site_name' content='一只饺子'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='机器学习'><meta property='article:tag' content='代码实践'><meta property='article:modified_time' content='2025-03-11T15:19:48+08:00'><meta property='og:image' content='https://example.com/post/img/13.jpg'><meta name=twitter:title content="Pytorch实践（刘二大人）1：线性模型"><meta name=twitter:description content="使用穷举法寻找线性回归模型中最佳权重参数w\r注意：\n对于numpy需要先下载依赖pip install numpy 对于matplotlib.pyplot，若有anaconda则无需下载 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import numpy as np; import matplotlib.pyplot as plt x_data = [1.0,2.0,3.0] y_data = [2.0,4.0,6.0] w_list = [] mse_list = [] # 定义前馈函数 def forward(x): return x * w # 定义损失函数 def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 for w in np.arange(0.0, 4.0, 0.1): print(&#34;w = &#34;, w) loss_sum = 0 # zip函数：将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表 for x_val, y_val in zip(x_data, y_data): y_pred_val = forward(x_val) loss_val = loss(x_val, y_val) loss_sum += loss_val print('\\t',x_val,y_val,y_pred_val,loss_val) print('MSE = ', loss_sum / 3) w_list.append(w) mse_list.append(loss_sum / 3) plt.plot(w_list, mse_list) plt.xlabel(&#34;w&#34;) plt.ylabel(&#34;loss&#34;) plt.show() 实现线性模型并输出loss的3D图形\r思路\r设计线性模型$y=\\omega x+b$ 预估$\\omega,b$的范围并用$W,B$数组存储 $\\omega=1_n \\cdot W,b=B\\cdot 1_m^T$构成参数空间$(w,b)$的笛卡尔积网络 $L_{sum}=0_{n\\times m}$ $MSE=\\frac{1}{N}\\sum$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D x_data = np.array([1.0, 2.0, 3.0]) y_data = np.array([5.0, 8.0, 11.0]) def forward(x): return x * w + b def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 W = np.arange(0.0, 4.1, 0.1) B = np.arange(0.0, 4.1, 0.1) w, b = np.meshgrid(W, B) loss_sum = np.zeros_like(w) for x_val, y_val in zip(x_data, y_data): loss_val = loss(x_val,y_val) loss_sum += loss_val mse = loss_sum / len(x_data) fig = plt.figure() # 创建一个新的窗口 ax = fig.add_subplot(111,projection='3d') # ax.plot_surface(w,b,mse,cmap='viridis') # camp='viridis'指定颜色映射 ax.set_xlabel('w') ax.set_ylabel('b') ax.set_zlabel('MSE') plt.show() "><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://example.com/post/img/13.jpg'><link rel="shortcut icon" href=/img/icon.svg><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/canvas-nest.js/2.0.4/canvas-nest.js></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/1fc88c9ce946a5621185d27c512d6ae_hu_bc1d6b840fc37823.jpg width=300 height=328 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>一只饺子</a></h1><h2 class=site-description>奶龙也是龙</h2></div></header><ol class=menu-social><li><a href=https://github.com/isdumpling target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/about><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://example.com/en/>English</option><option value=https://example.com/ selected>中文</option><option value=https://example.com/ar/>عربي</option></select></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#使用穷举法寻找线性回归模型中最佳权重参数w>使用穷举法寻找线性回归模型中最佳权重参数<code>w</code></a></li><li><a href=#实现线性模型并输出loss的3d图形>实现线性模型并输出loss的3D图形</a><ol><li><a href=#思路>思路</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/><img src=/post/img/13.jpg loading=lazy alt="Featured image of post Pytorch实践（刘二大人）1：线性模型"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/>Pytorch实践（刘二大人）1：线性模型</a></h2></div><footer class=article-time>最后修改:
<time class=article-time--updated datetime="2025-03-11 15:19:48 +0800 CST" title="2025-03-11 15:19:48 +0800 CST">2025-03-11</time><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><h2 id=使用穷举法寻找线性回归模型中最佳权重参数w>使用穷举法寻找线性回归模型中最佳权重参数<code>w</code></h2><p>注意：</p><ul><li>对于<code>numpy</code>需要先下载依赖<code>pip install numpy</code></li><li>对于<code>matplotlib.pyplot</code>，若有<code>anaconda</code>则无需下载</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_data</span> <span class=o>=</span> <span class=p>[</span><span class=mf>1.0</span><span class=p>,</span><span class=mf>2.0</span><span class=p>,</span><span class=mf>3.0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>y_data</span> <span class=o>=</span> <span class=p>[</span><span class=mf>2.0</span><span class=p>,</span><span class=mf>4.0</span><span class=p>,</span><span class=mf>6.0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>w_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>mse_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义前馈函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span> <span class=o>*</span> <span class=n>w</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义损失函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>loss</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>forward</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>y_pred</span> <span class=o>-</span> <span class=n>y</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>4.0</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;w = &#34;</span><span class=p>,</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_sum</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=c1># zip函数：将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>x_val</span><span class=p>,</span> <span class=n>y_val</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>x_data</span><span class=p>,</span> <span class=n>y_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y_pred_val</span> <span class=o>=</span> <span class=n>forward</span><span class=p>(</span><span class=n>x_val</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss_val</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>x_val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss_sum</span> <span class=o>+=</span> <span class=n>loss_val</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\t</span><span class=s1>&#39;</span><span class=p>,</span><span class=n>x_val</span><span class=p>,</span><span class=n>y_val</span><span class=p>,</span><span class=n>y_pred_val</span><span class=p>,</span><span class=n>loss_val</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;MSE = &#39;</span><span class=p>,</span> <span class=n>loss_sum</span> <span class=o>/</span> <span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>w_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mse_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss_sum</span> <span class=o>/</span> <span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>w_list</span><span class=p>,</span> <span class=n>mse_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;w&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=实现线性模型并输出loss的3d图形>实现线性模型并输出loss的3D图形</h2><h3 id=思路>思路</h3><ol><li>设计线性模型$y=\omega x+b$</li><li>预估$\omega,b$的范围并用$W,B$数组存储</li><li>$\omega=1_n \cdot W,b=B\cdot 1_m^T$构成参数空间$(w,b)$的笛卡尔积网络</li><li>$L_{sum}=0_{n\times m}$</li><li>$MSE=\frac{1}{N}\sum$</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mpl_toolkits.mplot3d</span> <span class=kn>import</span> <span class=n>Axes3D</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>y_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>5.0</span><span class=p>,</span> <span class=mf>8.0</span><span class=p>,</span> <span class=mf>11.0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span> <span class=o>*</span> <span class=n>w</span> <span class=o>+</span> <span class=n>b</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>loss</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>forward</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>y_pred</span> <span class=o>-</span> <span class=n>y</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>W</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>4.1</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>B</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>4.1</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>w</span><span class=p>,</span> <span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>W</span><span class=p>,</span> <span class=n>B</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>loss_sum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>x_val</span><span class=p>,</span> <span class=n>y_val</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>x_data</span><span class=p>,</span> <span class=n>y_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_val</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>x_val</span><span class=p>,</span><span class=n>y_val</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_sum</span> <span class=o>+=</span> <span class=n>loss_val</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mse</span> <span class=o>=</span> <span class=n>loss_sum</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>x_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span> <span class=c1># 创建一个新的窗口</span>
</span></span><span class=line><span class=cl><span class=n>ax</span> <span class=o>=</span> <span class=n>fig</span><span class=o>.</span><span class=n>add_subplot</span><span class=p>(</span><span class=mi>111</span><span class=p>,</span><span class=n>projection</span><span class=o>=</span><span class=s1>&#39;3d&#39;</span><span class=p>)</span> <span class=c1># </span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>plot_surface</span><span class=p>(</span><span class=n>w</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>mse</span><span class=p>,</span><span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>)</span> <span class=c1># camp=&#39;viridis&#39;指定颜色映射</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;w&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;b&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ax</span><span class=o>.</span><span class=n>set_zlabel</span><span class=p>(</span><span class=s1>&#39;MSE&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-tags><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a>
<a href=/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5/>代码实践</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 2025-03-11 15:19 CST</span></section><section class=article-pageviews><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/></svg>
<span>页面浏览量<span id=busuanzi_value_page_pv>Loading</span></span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/pytorch%E8%AF%AD%E6%B3%95/><div class=article-image><img src=/post/img/12.jpg loading=lazy data-key data-hash=/post/img/12.jpg></div><div class=article-details><h2 class=article-title>PyTorch语法</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA2%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/><div class=article-image><img src=/post/img/14.jpg loading=lazy data-key data-hash=/post/img/14.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）2：梯度下降算法</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA3%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/><div class=article-image><img src=/post/img/15.jpg loading=lazy data-key data-hash=/post/img/15.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）3：反向传播</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA4%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/><div class=article-image><img src=/post/img/16.jpg loading=lazy data-key data-hash=/post/img/16.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）4：用PyTorch实现线性回归</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA5%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92/><div class=article-image><img src=/post/img/17.jpg loading=lazy data-key data-hash=/post/img/17.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）5：逻辑斯蒂回归</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2025 一只饺子</section><section class=powerby><div class=site-stats><span class=stat-item><i class="fas fa-users"></i> 访客数：<span id=busuanzi_value_site_uv>Loading</span>
</span><span class=stat-item><i class="fas fa-eye"></i> 访问量：<span id=busuanzi_value_site_pv>Loading</span>
</span><span class=stat-item><a href=https://eu.umami.is/share/y6kXo4CE3oYHXQ37/farb.github.io target=_blank rel=noopener><i class="fas fa-chart-line"></i> 详细统计</a></span></div><br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><style>#backTopBtn{display:none;position:fixed;bottom:30px;z-index:99;cursor:pointer;width:30px;height:30px;background-image:url(https://example.com/icons/backTop.svg)}</style><script>function initScrollTop(){let t=document.querySelector(".right-sidebar");if(!t)return;let e=document.createElement("div");e.id="backTopBtn",e.onclick=backToTop,t.appendChild(e),window.onscroll=function(){document.body.scrollTop>20||document.documentElement.scrollTop>20?e.style.display="block":e.style.display="none"}}function backToTop(){window.scrollTo({top:0,behavior:"smooth"})}initScrollTop()</script><script defer src=https://cn.vercount.one/js></script></body></html>