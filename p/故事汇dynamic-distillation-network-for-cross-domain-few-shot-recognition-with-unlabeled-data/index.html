<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="原文链接\r传送门\n知识清单\rAbstract\r小样本学习方法(few-shot learning)：让模型仅通过极少量样本（如1-5个样本，称为1-shot或5-shot）快速学习新任务 元学习(meta-learning)：通过大量相似任务（如分类不同模型）训练模型 例如：训练时让模型学习“如何区分5种类别的鸟类”，测试时快速适应“区分5种新鸟类”。 跨领域小样本学习(cross-domain few-shot)：基础数据集与目标数据集来自不同领域（如自然图像→医学影像），且目标数据极少或无标签 STARTUP：解决跨领域小样本学习中目标数据无标签的问题 自训练(self-training)：用预训练教师模型对无标签目标数据生成伪标签（即软标签），再结合少量标注数据训练学生模型 固定教师 软标签(soft labels)：概率分布形式的标签（如[0.7, 0.3]表示“70%概率是类别A”），而非硬标签（如[1, 0]） 弱增强(weakly-augmented)：对输入数据施加轻微变换的预处理操作，比强增强更温和 Introduction\r指数移动平均(EMA)：通过加权平均更新参数，赋予近期参数更高的权重，同时保留历史参数的衰减影响。\n"><title>故事汇：Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data</title>
<link rel=canonical href=https://example.com/p/%E6%95%85%E4%BA%8B%E6%B1%87dynamic-distillation-network-for-cross-domain-few-shot-recognition-with-unlabeled-data/><link rel=stylesheet href=/scss/style.min.2deeca980d2b0d58c1f28cdfd20b96c62f8357ef57495cd2d99f0054e39d1d6f.css><meta property='og:title' content="故事汇：Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data"><meta property='og:description' content="原文链接\r传送门\n知识清单\rAbstract\r小样本学习方法(few-shot learning)：让模型仅通过极少量样本（如1-5个样本，称为1-shot或5-shot）快速学习新任务 元学习(meta-learning)：通过大量相似任务（如分类不同模型）训练模型 例如：训练时让模型学习“如何区分5种类别的鸟类”，测试时快速适应“区分5种新鸟类”。 跨领域小样本学习(cross-domain few-shot)：基础数据集与目标数据集来自不同领域（如自然图像→医学影像），且目标数据极少或无标签 STARTUP：解决跨领域小样本学习中目标数据无标签的问题 自训练(self-training)：用预训练教师模型对无标签目标数据生成伪标签（即软标签），再结合少量标注数据训练学生模型 固定教师 软标签(soft labels)：概率分布形式的标签（如[0.7, 0.3]表示“70%概率是类别A”），而非硬标签（如[1, 0]） 弱增强(weakly-augmented)：对输入数据施加轻微变换的预处理操作，比强增强更温和 Introduction\r指数移动平均(EMA)：通过加权平均更新参数，赋予近期参数更高的权重，同时保留历史参数的衰减影响。\n"><meta property='og:url' content='https://example.com/p/%E6%95%85%E4%BA%8B%E6%B1%87dynamic-distillation-network-for-cross-domain-few-shot-recognition-with-unlabeled-data/'><meta property='og:site_name' content='一只饺子'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='机器学习'><meta property='article:tag' content='笔记'><meta property='article:tag' content='故事汇'><meta property='article:modified_time' content='2025-04-01T01:42:54+08:00'><meta property='og:image' content='https://example.com/post/img/15.jpg'><meta name=twitter:title content="故事汇：Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data"><meta name=twitter:description content="原文链接\r传送门\n知识清单\rAbstract\r小样本学习方法(few-shot learning)：让模型仅通过极少量样本（如1-5个样本，称为1-shot或5-shot）快速学习新任务 元学习(meta-learning)：通过大量相似任务（如分类不同模型）训练模型 例如：训练时让模型学习“如何区分5种类别的鸟类”，测试时快速适应“区分5种新鸟类”。 跨领域小样本学习(cross-domain few-shot)：基础数据集与目标数据集来自不同领域（如自然图像→医学影像），且目标数据极少或无标签 STARTUP：解决跨领域小样本学习中目标数据无标签的问题 自训练(self-training)：用预训练教师模型对无标签目标数据生成伪标签（即软标签），再结合少量标注数据训练学生模型 固定教师 软标签(soft labels)：概率分布形式的标签（如[0.7, 0.3]表示“70%概率是类别A”），而非硬标签（如[1, 0]） 弱增强(weakly-augmented)：对输入数据施加轻微变换的预处理操作，比强增强更温和 Introduction\r指数移动平均(EMA)：通过加权平均更新参数，赋予近期参数更高的权重，同时保留历史参数的衰减影响。\n"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://example.com/post/img/15.jpg'><link rel="shortcut icon" href=/img/icon.svg><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/canvas-nest.js/2.0.4/canvas-nest.js></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/1fc88c9ce946a5621185d27c512d6ae_hu_bc1d6b840fc37823.jpg width=300 height=328 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>一只饺子</a></h1><h2 class=site-description>奶龙也是龙</h2></div></header><ol class=menu-social><li><a href=https://github.com/isdumpling target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/about><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://example.com/en/>English</option><option value=https://example.com/ selected>中文</option><option value=https://example.com/ar/>عربي</option></select></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#原文链接>原文链接</a></li><li><a href=#知识清单>知识清单</a><ol><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#related-work>Related Work</a></li></ol></li><li><a href=#品细品>品，细品</a><ol><li><a href=#abstract-1>Abstract</a></li><li><a href=#introduction-1>Introduction</a><ol><li><a href=#典型小样本学习跨领域小样本学习本文提出的新设定的区别>典型小样本学习、跨领域小样本学习、本文提出的新设定的区别</a></li></ol></li><li><a href=#related-work-1>Related Work</a></li><li><a href=#methodology>Methodology</a><ol><li><a href=#proposed-method>Proposed Method</a></li></ol></li><li><a href=#experiments>Experiments</a><ol><li><a href=#experimental-setup>Experimental Setup</a></li></ol></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E6%95%85%E4%BA%8B%E6%B1%87dynamic-distillation-network-for-cross-domain-few-shot-recognition-with-unlabeled-data/><img src=/post/img/15.jpg loading=lazy alt="Featured image of post 故事汇：Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E6%95%85%E4%BA%8B%E6%B1%87dynamic-distillation-network-for-cross-domain-few-shot-recognition-with-unlabeled-data/>故事汇：Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data</a></h2></div><footer class=article-time>最后修改:
<time class=article-time--updated datetime="2025-04-01 01:42:54 +0800 CST" title="2025-04-01 01:42:54 +0800 CST">2025-04-01</time><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 14 分钟</time></div></footer></div></header><section class=article-content><h2 id=原文链接>原文链接</h2><p><a class=link href=https://arxiv.org/pdf/2106.07807 target=_blank rel=noopener>传送门</a></p><h2 id=知识清单>知识清单</h2><h3 id=abstract>Abstract</h3><ul><li><strong>小样本学习方法(few-shot learning)</strong>：让模型仅通过极少量样本（如1-5个样本，称为1-shot或5-shot）快速学习新任务</li><li><strong>元学习(meta-learning)</strong>：通过大量相似任务（如分类不同模型）训练模型<ul><li>例如：训练时让模型学习“如何区分5种类别的鸟类”，测试时快速适应“区分5种新鸟类”。</li></ul></li><li><strong>跨领域小样本学习(cross-domain few-shot)</strong>：基础数据集与目标数据集来自不同领域（如自然图像→医学影像），且目标数据极少或无标签</li><li><strong>STARTUP</strong>：解决跨领域小样本学习中目标数据无标签的问题<ul><li><strong>自训练(self-training)</strong>：用预训练教师模型对无标签目标数据生成伪标签（即软标签），再结合少量标注数据训练学生模型</li><li><strong>固定教师</strong></li></ul></li><li><strong>软标签(soft labels)</strong>：概率分布形式的标签（如[0.7, 0.3]表示“70%概率是类别A”），而非硬标签（如[1, 0]）</li><li><strong>弱增强(weakly-augmented)</strong>：对输入数据施加轻微变换的预处理操作，比强增强更温和</li></ul><h3 id=introduction>Introduction</h3><ul><li><p><strong>指数移动平均(EMA)</strong>：通过加权平均更新参数，赋予近期参数更高的权重，同时保留历史参数的衰减影响。</p><ul><li>教师网络的参数$\theta_t$由学生网络参数$\theta_s$通过EMA更新。其中$\beta$是衰减率</li></ul><p>$$
\theta_t \leftarrow \beta \cdot \theta_t + (1-\beta)\cdot \theta_s
$$</p></li><li><p><strong>蒸馏(Distillation)</strong>：知识蒸馏是一种将“教师模型”的知识迁移到“学生模型”的技术，通常通过让学生模仿教师的输出来实现。核心思想是让学生学习教师的软标签（概率分布），而不仅是真实标签的硬标签。</p><ul><li><strong>教师生成软标签</strong>：输入数据经教师模型前向传播，输出概率分布（如分类任务的类别概率）</li><li><strong>学生匹配软标签</strong>：学生模型对相同（或增强后的）数据输出概率，并通过损失函数（如 KL 散度）逼近教师的输出。</li></ul></li><li><p><strong>支持集(Support Set)</strong>：一小批带有标签的样本，用来“教”模型快速认识新任务中的类别。</p></li><li><p><strong>查询集(Query Set)</strong>：一批需要分类的样本，用来测试模型是否真正学会了新类别。</p></li></ul><blockquote><p>注意：支持集和查询集、训练集和测试集是有不同的</p><ol><li>训练集/测试集的目的是训练一个模型解决单一固定任务</li><li>支持集/测试集让模型快速适应新任务</li><li>训练集 vs 支持集：如果只用支持集（如每类1张图）训练传统模型，模型会严重过拟合（只会背答案，无法泛化）。支持集必须配合元学习框架，让模型提前掌握“快速学习能力”。</li><li>测试集 vs 查询集：测试集是静态的，任务固定；查询集是动态的，每次任务不同（如今天分类鸟类，明天分类岩石）。查询集的评估目标是“模型能否快速适应新任务”，而非“是否精通某一任务”。</li></ol></blockquote><h3 id=related-work>Related Work</h3><ul><li><strong>生成式方法</strong>：通过生成新样本来扩充数据<ul><li>自己画一些假狗的照片（生成数据），结合真实照片一起训练<ul><li>比如用尺子量新照片和样本照片的"鼻子长度"&ldquo;耳朵形状"等特征，越像狗分越高</li></ul></li></ul></li><li><strong>基于度量的方法</strong>：核心是学习样本间的相似度计算方式、<ul><li><strong>Matching Networks</strong>：把照片变成数学向量，计算相似度</li><li><strong>Prototypical Networks</strong>：先计算所有样本的平均特征（比如哈士奇平均有蓝眼睛、竖耳朵），新照片和这个平均值对比</li><li><strong>Relation Networks</strong>：让AI自己发明一套「相似度计算公式」，而不是用现成的余弦相似度</li></ul></li><li><strong>基于自适应的方法</strong>：通过参数调整快速适应新任务<ul><li><strong>MAML</strong>：提前把模型参数训练得像橡皮泥一样，遇到新任务只需微调几步<ul><li>比如先学会识别动物轮廓，遇到新动物时快速调整细节（斑马条纹/长颈鹿脖子）</li></ul></li></ul></li><li><strong>元学习(Meta-learning)</strong>：“学会学习”的范式，通过多个任务训练模型获取可迁移的知识<ul><li>先让AI玩100个「用5张图认新东西」的小游戏（每个游戏认不同动物）</li><li>AI在这些游戏中总结出经验：比耳朵形状比颜色更重要，先看轮廓再看细节</li><li>遇到新游戏（比如用5张企鹅照片认企鹅），就能快速应用这些经验</li></ul></li><li><strong>自训练(Self-training)</strong>：一种半监督学习方法，其核心思想是通过模型自身的预测结果（伪标签）逐步扩充训练数据<ul><li><strong>基本流程</strong><ul><li><strong>初始训练</strong>：使用少量有标签数据训练基础模型（Teacher Model）</li><li><strong>伪标签生成</strong>：用该模型预测无标签数据的类别，筛选高置信度预测结果作为伪标签</li><li><strong>数据扩充</strong>：将伪标签数据与原始有标签数据合并，重新训练模型（Student Model）</li><li><strong>迭代优化</strong>：重复步骤2-3，直至模型收敛或达到终止条件</li></ul></li><li><strong>通俗解释</strong>：假设你是一个学生<ul><li><strong>第一步</strong>：老师先教你10道数学题（有标签数据），你学会了基本解法</li><li><strong>第二步</strong>：老师布置100道新题（无标签数据），你先用学会的方法做完，并挑出自己最有把握的50道题（高置信度伪标签）</li><li><strong>第三步</strong>：把这50道自认为正确的题当作「参考答案」，结合原来的10道题重新复习</li><li><strong>第四步</strong>：重复做题→选答案→复习的过程，直到你觉得所有题都会了</li><li><strong>注意风险</strong>：如果前几步自己做错了还当成正确答案，后面会越错越离谱（错误累积）。所以老师通常会要求：只相信95分以上的答案（置信度阈值），或者让多个同学互相对答案（多模型协同）</li></ul></li></ul></li><li><strong>半监督学习(Semi-supervised Learning)</strong>：用少量带答案（标签）和大量不带答案的数据（无标签）一起训练模型</li><li><strong>FixMatch</strong>：用自信的猜测教自己</li><li><strong>STARTUP(Self-Training Adaptation Using Pseudo-labels)</strong>：通过伪标签和自监督对比学习，，利用目标领域的未标注数据提升模型在跨域任务中的性能。<ul><li><strong>核心问题设定</strong>：<ul><li><strong>基础域（Source Domain）</strong>：有大量标注数据（如自然图像）</li><li><strong>目标域（Target Domain）</strong>：仅有极少量标注数据（如医学图像），但可能有大量未标注数据。</li><li><strong>目标</strong>：让模型从基础域迁移到目标域，仅用少量目标域标注样本实现高精度分类。</li></ul></li><li><strong>方法流程</strong><ol><li><strong>预训练模型</strong>：在基础域上训练一个分类模型（如ResNet），作为固定（Frozen）的预训练模型。</li><li><strong>生成伪标签</strong>：使用预训练模型对目标域的未标注数据生成伪标签（即预测结果作为“软标签”）</li><li><strong>联合训练</strong>：结合基础域的标注数据（真实标签）和目标域的伪标签数据，重新训练模型。</li><li><strong>自监督对比学习</strong>：在未标注数据上加入对比损失（如SimCLR），学习对数据增强鲁棒的特征表示。</li></ol></li><li><strong>大白话</strong>：先蒙答案，蒙完再改，改的时候还要自我检查</li></ul></li></ul><h2 id=品细品>品，细品</h2><h3 id=abstract-1>Abstract</h3><ul><li><strong>现有工作</strong>：依赖于在与目标数据集同域的大型基础数据集上进行网络元学习<ul><li><strong>缺陷</strong>：在基础域和目标域存在显著差异的跨域小样本学习效果不行</li></ul></li><li><strong>本文提出</strong>：使用动态蒸馏，有效利用新/基础数据集的未标记图像<ul><li>通过教师网络对未标记图像的弱增强版本生成预测</li><li>通过学生网络对同一图像的强增强版本进行预测</li><li>通过一致性正则化约束两者匹配</li><li>教师网络的参数通过学生网络参数的指数移动平均动态更新</li></ul></li></ul><h3 id=introduction-1>Introduction</h3><h4 id=典型小样本学习跨领域小样本学习本文提出的新设定的区别>典型小样本学习、跨领域小样本学习、本文提出的新设定的区别</h4><p><img src=/img/%e4%b8%89%e7%a7%8d%e5%b0%8f%e6%a0%b7%e6%9c%ac.png loading=lazy alt=三者差别></p><ul><li><strong>典型小样本学习（左）</strong><ul><li>基础数据集和目标数据集来自同一领域</li><li>类别互不相交</li></ul></li><li><strong>跨领域小样本学习（中）</strong><ul><li>基础数据集与目标数据存在领域差异</li></ul></li><li><strong>本文提出的设定（右）</strong><ul><li>在元训练阶段引入无标签目标数据</li></ul></li></ul><p><strong>通俗易懂的解释</strong>：</p><ul><li><strong>典型小样本学习（左）</strong>：你是一个只会画“猫和狗”的画家，现在要快速学会画“鸟和鱼”。<ul><li><strong>基础训练</strong>：你之前画过大量<strong>不同品种的猫和狗</strong>（同一领域：动物）</li><li><strong>小样本任务</strong>：客户给你看<strong>1张鸟的照片</strong>和<strong>1张鱼的照片</strong>（支持集），要求你画出这两种动物的其他姿势（查询集）</li><li><strong>关键点</strong><ul><li>你学的（猫狗）和要画的（鸟鱼）都是<strong>动物</strong>，只是品种不同（同一领域，类别不相交）</li><li>你靠之前的动物绘画经验（如毛发、眼睛的画法），快速模仿鸟和鱼的特征</li></ul></li><li><strong>类比总结</strong><ul><li><strong>领域相同</strong>：全是动物</li><li><strong>挑战</strong>：用旧知识（画猫狗）解决同类新问题（画鸟鱼）</li></ul></li></ul></li><li><strong>跨领域小样本学习（中）</strong>：你是一个画“自然风景”的画家，现在要快速学会画“抽象几何图形”<ul><li><strong>基础训练</strong>：你之前画过大量<strong>山川、河流、树木</strong>（自然领域）</li><li><strong>小样本任务</strong>：客户给你看<strong>1个三角形</strong>和<strong>1个圆形</strong>（支持集），要求你画出其他几何图形（如六边形）</li><li><strong>关键点</strong><ul><li>自然风景（曲线、光影）和几何图形（直线、对称）属于<strong>完全不同的领域</strong></li><li>你只能用画风景的经验（如颜色搭配）去“硬猜”如何画几何图形，效果可能很差</li></ul></li><li><strong>类比总结</strong><ul><li><strong>领域不同</strong>：自然风景 vs. 几何图形</li><li><strong>挑战</strong>：旧经验（自然）和新任务（几何）毫无关联，从头适应难如登天</li></ul></li></ul></li><li><strong>本文提出的新设定</strong>：你是一个画“自然风景”的画家，但客户提前给了你一堆<strong>未标注的几何图形草稿</strong>，现在要快速学会画“抽象几何图形”<ul><li><strong>基础训练</strong><ul><li>你画过大量自然风景（带标签的源数据）</li><li>还看过很多<strong>未标注的几何图形草稿</strong>（无标签目标数据），虽然不知道它们具体是什么，但熟悉了直线、对称等特征。</li></ul></li><li><strong>小样本任务</strong>：客户给你看<strong>1个三角形</strong>和<strong>1个圆形</strong>（支持集），要求你画出其他几何图形。</li><li><strong>关键点</strong><ul><li>未标注的几何草稿让你提前适应了“几何领域”的风格（如直线比曲线多）。</li><li>结合自然风景的绘画技巧（如色彩搭配）和几何领域的特征，你能更快画出客户想要的图形。</li></ul></li><li><strong>类比总结</strong><ul><li><strong>领域不同</strong>：自然风景（源） vs. 几何图形（目标）。</li><li><strong>秘密武器</strong>：提前看过未标注的几何草稿（无标签目标数据），相当于“预习”了新领域的规则。</li></ul></li></ul></li></ul><h3 id=related-work-1>Related Work</h3><ul><li><p><strong>Few-shot classification</strong>: 少样本分类可分为三大类：生成式、基于度量、基于适应。早期少样本学习工作基于元学习</p></li><li><p><strong>Self-training</strong>: 自训练通过训练学生模型来模仿教师模型的预测</p></li><li><p><strong>Semi-supervised Learning</strong>:</p><ul><li><strong>核心思想</strong>：同时利用少量有标签数据和大量无标签数据进行训练</li><li><strong>FixMatch方法核心逻辑</strong><ul><li><strong>弱增强生成伪标签</strong>：对无标签图像做弱增强（如平移、旋转），用模型预测其伪标签。</li><li><strong>强增强训练一致性</strong>：若伪标签置信度高，则对同一图像做强增强（如颜色失真、模糊），并让模型预测与伪标签一致。</li></ul></li><li><strong>作者改进方法</strong><ul><li><strong>一致性正则化</strong>：强制模型对同一数据的不同增强版本（如弱增强和强增强）输出一致。与FixMatch类似，但不假设无标签数据与有标签数据同领域。</li><li><strong>均值教师网络</strong>：用教师模型（Teacher Network）生成伪标签，学生模型（Student Network）学习。教师模型是学生模型的指数移动平均（EMA），稳定性更高，伪标签噪声更小。</li></ul></li></ul></li><li><p><strong>Cross-domain few-shot learning</strong></p><ul><li>现有最先进方法在跨域少样本学习上难以达到理想准确率</li><li><strong>现有方法：STARTUP</strong><ul><li><strong>方法</strong>：用预训练模型为未标记的目标域数据生成伪标签，结合基础域标注数据和目标域伪标签训练模型。</li><li><strong>局限</strong>：伪标签依赖<strong>固定预训练模型</strong>，若模型不适应目标领域，错误会累积（如用自然图像预训练的模型直接标注医学影像）。需要额外设计<strong>自监督对比损失</strong>（如SimCLR），增加计算复杂度。</li></ul></li><li><strong>本文方法：动态蒸馏(Dynamic Distillation)</strong><ol><li><strong>监督学习</strong>：使用标记的基础数据集优化监督交叉熵损失。</li><li><strong>动态蒸馏</strong><ul><li>对目标图像的弱增强版本，用教师网络生成预测</li><li>对同一图像的强增强版本，由学生网络生成预测</li><li>通过蒸馏损失约束两者预测分布一致</li><li>教师预测应用温度锐化以鼓励学生输出低熵预测</li></ul></li><li><strong>参数更新</strong>：学生网络通过监督损失和蒸馏损失联合优化，教师网络参数采用学生网络的指数移动平均更新。</li><li><strong>少样本评估</strong>：仅需在少样本支撑集上学习新分类器头，直接对查询集进行评估。</li></ol></li></ul><p><img src=/img/%e5%8a%a8%e6%80%81%e8%92%b8%e9%a6%8f.jpeg loading=lazy alt=动态蒸馏></p></li></ul><h3 id=methodology>Methodology</h3><h4 id=proposed-method>Proposed Method</h4><ul><li><p><strong>Encoder</strong>：通过知识蒸馏方法，在源数据集和目标数据集上联合训练基础编码器。将嵌入网络表示为$f_s$，它将输入图像$x$编码为一个$d$维向量$f_s(x)$。我们在$f_s$上添加一个分类头$g_s$，用于从嵌入向量中预测$n_c$个逻辑值(logits)，其中$n_c$是基数据集（base dataset）的类别总数。由于基数据集中的样本标签已知，我们计算监督交叉熵损失：
$$
l_{CE}(y,p)=H(y,p)\
p=Softmax(g_s(f_s(x)))
H(a,b)=-alog b
$$</p><ul><li><strong>核心目标</strong>：通过<strong>知识蒸馏</strong>（类似“老师教学生”），让编码器同时学习源数据集（如动物图片）和目标数据集（如医疗X光片）的特征，提升跨域任务的泛化能力。</li><li><strong>模型结构</strong><ul><li><strong>编码器</strong>$f_s$：将输入图像（如一张x光片）转换为一个向量，这个向量代表图像的特征（如形状、纹理）</li><li><strong>分类器头</strong>$g_s$：接在编码器后面，将特征向量映射到类别概率</li></ul></li><li><strong>监督损失</strong><ul><li><strong>输入</strong>：源数据集（带标签）的图片</li><li>计算步骤：<ol><li>编码器提取特征 $\rightarrow f_s(x)$</li><li>分类器预测类别概率 $\rightarrow p = Softmax(g_s(f_s(x)))$</li><li>用交叉熵损失$l_{CE}$衡量预测概率$p$和真实标签$y$的差距</li></ol></li><li><strong>通俗解释</strong>：如果真实标签是“肺炎”，但模型预测概率为0.1，损失会很大；如果预测概率是0.9，损失就小。这个过程迫使编码器和分类器学习源数据集的分类能力。</li></ul></li></ul></li><li><p><strong>Dynamic distillation</strong>：</p><ul><li><strong>核心思想</strong><ul><li><strong>教师-学生模式</strong>：教师网络生成“参考答案”（伪标签），学生网络通过模仿教师来学习</li><li><strong>动态更新</strong>：教师网络不是固定的，而是随着学生网络的训练逐步更新，类似“老师跟着学生一起进步”。</li></ul></li><li><strong>关键步骤</strong><ul><li><strong>数据增强</strong>：迫使模型对不同增强版本预测一致，提升鲁棒性</li><li><strong>伪标签生成</strong>：<ol><li>教师网络处理弱增强图像$x_i^w$，生成软目标$p_i^w$（概率分布，而非硬标签）</li><li>学生网络处理强增强图像$x_i^s$，生成预测$p_i^s$</li></ol></li><li><strong>损失计算</strong><ul><li>监督损失$l_{CE}$：在源数据（带标签）上计算交叉熵损失</li><li>蒸馏损失$l_U$：迫使学生网络的预测$p_i^s$与教师网络的伪标签$p_i^w$一致</li><li>总损失是两者的加权和（$\lambda$控制未标记数据的重要性）</li></ul></li><li><strong>教师网络更新</strong><ul><li>教师网络的权重是学生网络权重的历史平均（动量更新）</li><li>动态更新使得教师网络更稳定，避免伪标签噪声过大。</li></ul></li></ul></li></ul></li></ul><h3 id=experiments>Experiments</h3><h4 id=experimental-setup>Experimental Setup</h4><ul><li><p><strong>数据集</strong></p><ul><li><strong>基数据集(Base Dataset)</strong><ul><li><strong>miniImageNet</strong>：从<code>ImageNet</code>中选取的100个类别，每个类别含600张图像（总计60,000张），类别覆盖通用物体（如动物、日常用品），用于监督预训练。</li><li><strong>tieredImageNet</strong>：更大的基数据集，包含608个类别（34个超类），分为训练（351类）、验证（97类）、测试（160类），用于验证模型对大规模数据的泛化性。</li></ul></li><li><strong>新领域数据集(Novel Dataset)</strong><ul><li><strong>CropDisease</strong>：农业植物病害图像，类别与miniImageNet的语义差异显著（领域差异大）。</li><li><strong>EuroSAT</strong>：遥感卫星图像（土地利用分类），与自然图像分布不同（低分辨率、多光谱特征）。</li><li><strong>ISIC</strong>：皮肤病医学影像（皮肤镜图像），模态差异明显（纹理、颜色分布独特）。</li><li><strong>ChestX</strong>：胸部X光影像（肺炎分类），灰度图像且解剖结构复杂。</li><li><strong>选择依据</strong>：按与miniImageNet的领域差异递增排序（CropDisease差异最小，ChestX差异最大），用于测试跨域小样本泛化性。</li></ul></li><li><strong>数据划分协议</strong><ul><li><strong>无标签集</strong>$D_U$：从每个新数据集中随机抽取20%样本（例如，CropDisease若含1,000张，则取200张作为$D_U$）</li><li><strong>评估集</strong>：剩余80%样本用于<code>5-way K-shot</code> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>分类任务（支持集采样K张/类，查询集评估）。</li></ul></li></ul></li><li><p><strong>小样本评估</strong>：在支持集上训练逻辑回归分类器，在查询集测试性能</p></li><li><p><strong>实验1：BSCD-FSL基准测试duibi</strong></p><p><img src=/img/dc-table1.png loading=lazy alt="Table 1"></p><ul><li><strong>模型对比</strong>：<ul><li>传统元学习（MetaOpt、MAML、ProtoNet）</li><li>自监督学习（SimCLR）</li><li>混合方法（Transfer+SimCLR）</li><li>最新跨域方法（STARTUP）</li></ul></li><li><strong>训练设置</strong><ul><li>基础数据集：miniImageNet（80 类）</li><li>目标数据集：未标记数据（20% 目标集）</li><li>主干网络：ResNet-10（miniImageNet）</li></ul></li><li><strong>评估指标</strong>：5 分类 1-shot/5-shot 准确率（600 次运行的均值 ±95% 置信区间）</li><li><strong>优点</strong><ul><li>Ours 在所有数据集上均超越 STARTUP（平均提升 5.5%~8.8%）</li><li>动态教师网络生成的伪标签随训练优化，优于固定教师（STARTUP）</li></ul></li></ul></li><li><p><strong>实验2：tiredImageNet基础数据实验</strong></p><p><img src=/img/dc-table2.png loading=lazy alt="Table 2"></p><ul><li><strong>目的</strong>：验证方法在大规模基础数据集上的泛化性</li><li><strong>数据集</strong>：tieredImageNet（608 类，划分为 34 个超级类别）</li><li><strong>模型对比</strong>：<ul><li>基于 miniImageNet 的基准</li><li>基于 tieredImageNet 的基线</li></ul></li><li><strong>训练设置</strong><ul><li>更大主干网络：ResNet-18</li><li>元训练策略：MAML 框架</li></ul></li><li><strong>评估指标</strong>：5 分类 1-shot/5-shot 准确率</li><li><strong>关键发现</strong>：<ul><li>使用 tieredImageNet 预训练未显著提升性能（对比 miniImageNet）</li><li>验证跨域少样本学习中<strong>数据质量＞数据量</strong>的假设</li></ul></li></ul></li><li><p><strong>实验3：相似域少样本性能</strong></p><p><img src=/img/dc-table3.png loading=lazy alt="Table 3"></p><ul><li><strong>目的</strong>：验证方法在同域 / 相似域的有效性</li><li><strong>数据集</strong><ul><li>miniImageNet（同域）</li><li>tieredImageNet（相似域）</li></ul></li><li><strong>训练设置</strong>：<ul><li>未标记数据来自目标域测试集的 20%</li><li>主干网络：ResNet-10（miniImageNet）、ResNet-18（tieredImageNet）</li></ul></li><li><strong>对比对象</strong>：<ul><li>Transfer（仅监督训练）</li><li>STARTUP（同域无效）</li></ul></li><li><strong>关键发现</strong>：<ul><li>Ours 在同域任务中仍优于 STARTUP（tieredImageNet 1-shot 提升 7.7%）</li><li>动态蒸馏对域差异不敏感，兼具跨域和同域适应性</li></ul></li></ul></li><li><p><strong>实验4：动态蒸馏效果分析</strong></p><p><img src=/img/dc-table4.png loading=lazy alt="Table 4"></p><p><img src=/img/dc-figure3.png loading=lazy></p><ul><li><strong>目的</strong>：揭示动态蒸馏如何优化特征表示</li><li><strong>量化分析</strong>（表 4）：<ul><li>方法：K 均值聚类 + V-measure 评分</li><li>指标：真实标签与聚类结果的一致性（V-score）</li></ul></li><li><strong>可视化分析</strong>（图 3）：<ul><li>方法：t-SNE 降维展示特征分布</li><li>对比：Transfer 基准 vs Ours</li></ul></li><li><strong>关键发现</strong><ul><li><strong>聚类质量</strong>：Ours 在 EuroSAT（85.2%）和 CropDisease（91.3%）上 V-score 最高</li><li><strong>特征分离</strong>：可视化显示 Ours 生成的嵌入具有更好的类间区分性</li><li><strong>机制验证</strong>：蒸馏损失隐式促进特征聚类，无需显式对比学习</li></ul></li></ul></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>5-way指在小样本学习任务中，对5个类别进行分类。K-shot指每个分类提供k个带标签的样本作为训练支持集&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></section><footer class=article-footer><section class=article-tags><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a>
<a href=/tags/%E7%AC%94%E8%AE%B0/>笔记</a>
<a href=/tags/%E6%95%85%E4%BA%8B%E6%B1%87/>故事汇</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 2025-04-01 01:42 CST</span></section><section class=article-pageviews><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/></svg>
<span>页面浏览量<span id=busuanzi_value_page_pv>Loading</span></span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E6%95%85%E4%BA%8B%E6%B1%87deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/><div class=article-image><img src=/post/img/26.jpg loading=lazy data-key data-hash=/post/img/26.jpg></div><div class=article-details><h2 class=article-title>故事汇：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</h2></div></a></article><article class=has-image><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-1%E9%A2%84%E6%B5%8B%E6%9C%AC%E9%A2%91%E9%81%93%E8%A7%82%E6%B5%8B%E4%BA%BA%E6%95%B0%E4%B8%8A/><div class=article-image><img src=/post/img/4.jpg loading=lazy data-key data-hash=/post/img/4.jpg></div><div class=article-details><h2 class=article-title>机器学习（李宏毅）笔记 1：预测本频道观测人数（上）</h2></div></a></article><article class=has-image><a href=/p/pytorch%E8%AF%AD%E6%B3%95/><div class=article-image><img src=/post/img/12.jpg loading=lazy data-key data-hash=/post/img/12.jpg></div><div class=article-details><h2 class=article-title>PyTorch语法</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/><div class=article-image><img src=/post/img/13.jpg loading=lazy data-key data-hash=/post/img/13.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）1：线性模型</h2></div></a></article><article class=has-image><a href=/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA2%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/><div class=article-image><img src=/post/img/14.jpg loading=lazy data-key data-hash=/post/img/14.jpg></div><div class=article-details><h2 class=article-title>Pytorch实践（刘二大人）2：梯度下降算法</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2025 一只饺子</section><section class=powerby><div class=site-stats><span class=stat-item><i class="fas fa-users"></i> 访客数：<span id=busuanzi_value_site_uv>Loading</span>
</span><span class=stat-item><i class="fas fa-eye"></i> 访问量：<span id=busuanzi_value_site_pv>Loading</span>
</span><span class=stat-item><a href=https://eu.umami.is/share/y6kXo4CE3oYHXQ37/farb.github.io target=_blank rel=noopener><i class="fas fa-chart-line"></i> 详细统计</a></span></div><br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><!doctype html><html><head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js></script></head><body><div class=demo><div id=player1></div></div><script>var ap=new APlayer({element:document.getElementById("player1"),fixed:!0,autoplay:!1,mini:!0,theme:"#f8f4fc",loop:"all",order:"random",preload:"auto",volume:.4,mutex:!0,listFolded:!0,listMaxHeight:"500px",lrcType:0,music:[{name:"奶龙の小曲",artist:"我是奶龙",url:"/music/我是奶龙 (今夜星光闪闪)(DJ版) - 奶龙.mp3",cover:"/img/我是奶龙.jpg",weight:1},{name:"将军の小曲",artist:"恩！情！",url:"/music/阿悠悠 - 你若三冬（将军进行曲） (0_8xDJ沈乐版).mp3",cover:"/img/将军.png",weight:2},{name:"祁厅长进步の小曲",artist:"我太想进步了",url:"/music/鸳鸯戏 (哎呦小情郎你莫愁)(0.9x) - 略略略.mp3",cover:"/img/祁厅长の进步.jpg",weight:3},{name:"卡卡的小曲",artist:"忠！诚！",url:"/music/小轩仔仔-Shake And Sway (光州小曲).mp3",cover:"/img/全卡卡.jpg",weight:4}]})</script></body><style>#backTopBtn{display:none;position:fixed;bottom:30px;z-index:99;cursor:pointer;width:30px;height:30px;background-image:url(https://example.com/icons/backTop.svg)}</style><script>function initScrollTop(){let t=document.querySelector(".right-sidebar");if(!t)return;let e=document.createElement("div");e.id="backTopBtn",e.onclick=backToTop,t.appendChild(e),window.onscroll=function(){document.body.scrollTop>20||document.documentElement.scrollTop>20?e.style.display="block":e.style.display="none"}}function backToTop(){window.scrollTo({top:0,behavior:"smooth"})}initScrollTop()</script><script defer src=https://cn.vercount.one/js></script></body></html>