---
title: 机器学习（李宏毅）笔记 3：机器学习任务攻略
params:
  author: 一只饺子
tags:
  - 机器学习
categories: 机器学习
typora-root-url: ./..\..\static
mindmap: true
image: post/img/6.jpg
---



## 机器学习的框架

训练集：${(x^1,\widehat{y}^1),(x^2,\widehat{y}^2),...,{x^n,\widehat{y}^n}}$

测试集：${x^{n+1},x^{n+2}},...,x^{n+m}$



**训练步骤**：

1. 带有未知参数的函数：$y=f_{\theta}(x)$
2. 根据训练数据定义损失函数：$L(\theta)$
3. 优化：$\theta ^{*}=arg min_{\theta}L$ 



## 通用指南

```markdown
{{<mind-md>}}
- loss on training data
	- large
		- model bias
			- make your model complex
		- optimization
			- next lecture
	- small
		- loss on testing data
			- small
				- ＜（＾－＾）＞
			- large
				- overfitting
					- more training data
					- data augmentation
					- make your model simpler
				- mismatch
{{</mind-md>}}
	
```



## 模型偏差和优化问题的对比



### 模型偏差

* 模型过简单
* 解决方式：重新设置你的模型，使其更加有弹性



### 优化问题

1. 通过对比获得洞见
   1. 当深层网络效果不如浅层网络时，需排除模型容量不足的可能。
   2. 若浅层网络能拟合训练数据，而深层网络不能，说明优化存在问题（而非模型表达能力不足）。
2. 从较浅的网络开始训练
   1. 浅层网络更容易优化（梯度传播路径短，参数少）。
   2. 若浅层网络能正常训练，但加深后效果变差，可定位到优化问题（如梯度消失/爆炸）。
3. 深层网络训练损失不降
   1. 深层网络的假设空间包含浅层网络（例如深层网络的前几层可模拟浅层网络）。
   2. 理论上，深层网络在训练数据上的损失应 ≤ 浅层网络损失（因其模型容量更大）。
   3. 若实际训练中深层网络损失更高，说明优化器未能找到更优解（而非模型能力不足）。



### 模型复杂度和损失的关系

#### **1. 训练损失（Training Loss）**

- **规律**：随着模型复杂度增加，训练损失单调递减。
- **原因**：复杂模型有更强的拟合能力，可以逼近甚至完美拟合训练数据。
- **极端情况**：过参数化模型（如深度神经网络）可实现训练损失趋近于零（记忆训练样本）。



#### **2. 验证/测试损失（Validation/Test Loss）**

- 规律

  ：先降低后升高，形成U型曲线。

  - **低复杂度**：模型无法捕捉数据规律（欠拟合），损失较高。
  - **适当复杂度**：模型拟合数据真实分布，损失最低。
  - **高复杂度**：模型过度拟合噪声（过拟合），损失回升。



数学解释：
$$
泛化误差=偏差^2+方差+不可约方差
$$

### 训练资料和测试资料的mismatch



**原因：**

1. 训练集和测试集的特征（如数值范围、类别比例）差异大。
2. 分类任务中类别比例差异，或回归任务中目标值范围不同。

**体现：**

1. **训练集表现**：模型损失低、准确率高（看似“表现优秀”）。
2. **测试集表现**：损失显著升高、准确率骤降（模型无法泛化）。

**解决办法（举例）**：

1. 将数据集分为A, B, C三份
2. 首先用A, B作为训练集，C为测试集
3. 第二次用A, C作为训练集，B为测试集
4. 第三次用B, C作为训练集，A为测试集

