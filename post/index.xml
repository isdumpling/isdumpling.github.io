<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 一只饺子</title><link>https://example.com/post/</link><description>Recent content in Posts on 一只饺子</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>一只饺子</copyright><lastBuildDate>Sat, 22 Mar 2025 14:18:54 +0800</lastBuildDate><atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml"/><item><title>机器学习（李宏毅）笔记 1：预测本频道观测人数（上）</title><link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-1%E9%A2%84%E6%B5%8B%E6%9C%AC%E9%A2%91%E9%81%93%E8%A7%82%E6%B5%8B%E4%BA%BA%E6%95%B0%E4%B8%8A/</link><pubDate>Tue, 25 Feb 2025 17:21:44 +0800</pubDate><guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-1%E9%A2%84%E6%B5%8B%E6%9C%AC%E9%A2%91%E9%81%93%E8%A7%82%E6%B5%8B%E4%BA%BA%E6%95%B0%E4%B8%8A/</guid><description>&lt;img src="https://example.com/post/img/4.jpg" alt="Featured image of post 机器学习（李宏毅）笔记 1：预测本频道观测人数（上）" />&lt;ul>
&lt;li>
&lt;p>机器学习约等于寻找一个函数。比如：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>speech recognition:&lt;/strong> 输入一段“How are you”的语音，我们得到$f(音频) = &amp;ldquo;How are you&amp;rdquo;$&lt;/li>
&lt;li>&lt;strong>image recognition&lt;/strong>: 输入一张猫的图片，我们得到$f(cat.jpg)= &amp;ldquo;cat&amp;rdquo;$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>函数的不同类型有：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>regression&lt;/strong>：回归函数。该函数输出一个标量。比如，当我们预测第二天的$PM2.5$，我们输入：$PM2.5today, temperature, Concentration of O_3$，经过一个函数得到$PM2.5 of tomorrow$&lt;/li>
&lt;li>&lt;strong>Classification&lt;/strong>: 分类函数。给定一些选项，该函数会输出正确的选项&lt;/li>
&lt;li>&lt;strong>structure learning&lt;/strong>：结构学习。让机器学会创造这件事情&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="如何使用机器寻找一个函数">如何使用机器寻找一个函数？
&lt;/h3>&lt;p>总的来说分为三步:&lt;/p>
&lt;ol>
&lt;li>定义带函数的参数&lt;/li>
&lt;li>定义损失函数&lt;/li>
&lt;li>优化参数&lt;/li>
&lt;/ol>
&lt;p>这里引入了一个例子。一youtuber根据自己从前每日视频播放量，预测第二天的视频播放量&lt;/p>
&lt;h4 id="1-定义带参数的函数">1. 定义带参数的函数
&lt;/h4>&lt;p>我们有$y=f(数据集)-&amp;gt;y=b+wx_1$&lt;/p>
&lt;p>$w$和$b$是未知参数，对于初始$w_0$和$b_0$，我们通过&lt;del>猜&lt;/del>&lt;!-- raw HTML omitted -->domain knowledge&lt;!-- raw HTML omitted -->（专业领域知识）来进行推测&lt;/p>
&lt;h4 id="2-定义损失函数">2. 定义损失函数
&lt;/h4>&lt;ul>
&lt;li>损失函数是一个带参数的函数：$L(b, w)$&lt;/li>
&lt;li>损失函数能评测一组数据的优劣如何&lt;/li>
&lt;/ul>
&lt;p>我们假设$L(0.5k, 1)$，则$y = b + wx_1 - &amp;gt;y=0.5k+1x_1$
该youtuber的2017/01/01的播放量是$4.8k$，01/02的播放量为$4.9k$，01/03的播放量为$7.5k$&lt;/p>
&lt;p>带入01/01的数据，我们预测01/02为$y=0.5+1\times 4.8=5.3$&lt;/p>
&lt;p>那么我们可得:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>$e=|y-\widehat{y}|$，$L$是&lt;!-- raw HTML omitted -->平均绝对误差&lt;!-- raw HTML omitted -->(absolute error, MAE)，且有$MAE = \frac{1}{N}\sum_{i= 1}^{N}|y_{pred}^{(i)}-y_{true}^{(i)}|$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$e=(y-\widehat y)^2$，$L$是&lt;!-- raw HTML omitted -->均方误差&lt;!-- raw HTML omitted -->(mean square error, MSE)，且有$MSE=\frac{1}{N}\sum_{i=1}^N(y_{pred}^{(i)}-y_{true}^{(i)})^2$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$y=b+\sum_i c_isigmoid(b_i+\sum_j w_{ij}x_j)$&lt;/p></description></item><item><title>NoSQL Chapter 1</title><link>https://example.com/p/nosql-chapter-1/</link><pubDate>Tue, 25 Feb 2025 16:32:11 +0800</pubDate><guid>https://example.com/p/nosql-chapter-1/</guid><description>&lt;img src="https://example.com/post/img/10.avif" alt="Featured image of post NoSQL Chapter 1" />&lt;h2 id="get-familiar-with-nosql-database">Get familiar with NoSQL Database
&lt;/h2>&lt;h3 id="understanding-nosql-database">Understanding NoSQL Database
&lt;/h3>&lt;p>&lt;strong>the important features of NoSQL&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Schema Flexibility&lt;/strong>: allows for the storage of various data types&lt;/li>
&lt;li>&lt;strong>Horizontal Scalability&lt;/strong>: scaled out by distributing data across multiple servers&lt;/li>
&lt;li>&lt;strong>High Availability and Fault Tolerance&lt;/strong>: Build-in replication and sharding features&lt;/li>
&lt;li>&lt;strong>Performance&lt;/strong>: Optimized for specific use cases&lt;/li>
&lt;li>&lt;strong>Diverse Data Models&lt;/strong>: Support various data models&lt;/li>
&lt;li>&lt;strong>Cost-Effectiveness&lt;/strong>: The ability to scale out using commodity hardware and no need to invest the expensive, high-end servers&lt;/li>
&lt;/ul>
&lt;h3 id="introduction-to-nosql">Introduction to NoSQL
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Two types of databases&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>relational databases&lt;/strong>&lt;/li>
&lt;li>&lt;strong>non-relational databases&lt;/strong>, often called NoSQL databases&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>A NoSQL database&lt;/strong> is used to store large quantities of complex and diverse data&lt;/li>
&lt;li>&lt;strong>MongoDB&lt;/strong> is one of the most established NoSQL databases
&lt;ul>
&lt;li>&lt;strong>data aggregation&lt;/strong>&lt;/li>
&lt;li>&lt;strong>ACID&lt;/strong>
&lt;ul>
&lt;li>Atomicity&lt;/li>
&lt;li>Consistency&lt;/li>
&lt;li>Isolation&lt;/li>
&lt;li>Durability&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>horizontal scaling&lt;/strong>&lt;/li>
&lt;li>&lt;strong>charts&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="relational-database-vs-nosql">Relational Database VS NoSQL
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Relational Database Management Systems&lt;/strong>
&lt;ul>
&lt;li>store &lt;strong>structured data&lt;/strong>&lt;/li>
&lt;li>in the form of &lt;strong>tables&lt;/strong> that consist of rows and columns&lt;/li>
&lt;li>have relationships with other tables&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>NoSQL Database Management Systems&lt;/strong>
&lt;ul>
&lt;li>store &lt;strong>unstructured and semi-structured data&lt;/strong>&lt;/li>
&lt;li>store the data &lt;strong>without a schema&lt;/strong> and support &lt;strong>dynamic schema&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Feature&lt;/th>
&lt;th>Relational Database&lt;/th>
&lt;th>NoSQL Database&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Schema&lt;/td>
&lt;td>1. follows a rigid schema 2. have a definition of all the desired columns and their types&lt;/td>
&lt;td>1. does not impose a rigid schema 2. store the unstructured data with dynamic structures&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Data model/Storage Structure&lt;/td>
&lt;td>1. data is stored in tables 2. each record is stored as a row&lt;/td>
&lt;td>1. data is stored in different formats 2. storage structure are documents, graphs, key-values and wide columns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Normalization&lt;/td>
&lt;td>used to remove duplicate data and avoid data anomalies&lt;/td>
&lt;td>focus more on fast data retrieval and the data can be normalized&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Scaling&lt;/td>
&lt;td>hard to scale and generally scaled vertically&lt;/td>
&lt;td>both vertical and horizontal scaling&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="types-of-nosql">Types of NoSQL
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Typical Usage&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Key-value&lt;/td>
&lt;td>Image stores, Key-based filesystems, Object cache, Systems designed to scale&lt;/td>
&lt;td>Berkeley DB, Memcache, Redis, Riak, DynamoDB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Column family&lt;/td>
&lt;td>Web crawler results, Big data problems that can relax consistency rules&lt;/td>
&lt;td>Apache HBase&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Graph&lt;/td>
&lt;td>Social networks, Fraud detection, Relationship-heavy data&lt;/td>
&lt;td>Neo4j, AllergroGraph&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Document&lt;/td>
&lt;td>High-variability data, Document search&lt;/td>
&lt;td>MongoDB, CouchDB&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="understanding-the-mongodb">Understanding the MongoDB
&lt;/h2>&lt;h2 id="understanding-the-redis-database">Understanding the Redis Database
&lt;/h2>&lt;h2 id="understand-the-similarities-and-difference-with-other-softwares">Understand the similarities and difference with Other Software&amp;rsquo;s
&lt;/h2></description></item><item><title>git</title><link>https://example.com/p/git/</link><pubDate>Tue, 25 Feb 2025 16:21:44 +0800</pubDate><guid>https://example.com/p/git/</guid><description>&lt;img src="https://example.com/post/img/2.jpg" alt="Featured image of post git" />&lt;h2 id="与github仓库建立连接并提交修改">与GitHub仓库建立连接并提交修改
&lt;/h2>&lt;ol>
&lt;li>SSH密钥配备完成且有相关权限&lt;/li>
&lt;li>初始化本地仓库：&lt;code>git init&lt;/code>&lt;/li>
&lt;li>关联远程仓库：
&lt;ol>
&lt;li>HTTPS: &lt;code>git remote add origin https://github.com/username/repositoryname.git&lt;/code>&lt;/li>
&lt;li>SSH:&lt;code>git remote add origin git@github.com:username/repositoryname.git&lt;/code>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>首次拉取文件：&lt;code>git pull origin main&lt;/code>&lt;/li>
&lt;li>更改文件&lt;/li>
&lt;li>提交更改到本地：
&lt;ol>
&lt;li>添加所有更改：&lt;code>git add .&lt;/code>&lt;/li>
&lt;li>添加提交说明：&lt;code>git commit -m &amp;quot;你的提交说明&amp;quot;&lt;/code>&lt;/li>
&lt;li>推送到远程仓库：&lt;code>git push -u origin main&lt;/code>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h2 id="更改分支">更改分支
&lt;/h2>&lt;ol>
&lt;li>查看本地分支（当前分支会用&lt;code>*&lt;/code>标出）：&lt;code>git branch&lt;/code>&lt;/li>
&lt;li>查看所有分支（本地+远程跟踪分支）：&lt;code>git branch -a&lt;/code>&lt;/li>
&lt;li>切换现有分支
&lt;ol>
&lt;li>直接切换：&lt;code>git checkout 分支名&lt;/code>。如：切换到&lt;code>develop&lt;/code>分支：&lt;code>git checkout develop&lt;/code>&lt;/li>
&lt;li>拉取远程分支并切换：&lt;code>git checkout -b 本地分支名 origin/远程分支名&lt;/code>。如：同步远程的&lt;code>feature/login&lt;/code>分支到本地：&lt;code>git checkout -b feature/login origin/feature/login&lt;/code>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>创建并切换到新分支：
&lt;ol>
&lt;li>创建新分支并立即切换：&lt;code>git checkout -b 新分支名&lt;/code>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>推送新分支到远程仓库：&lt;code>git push orign 分支名&lt;/code>&lt;/li>
&lt;/ol></description></item><item><title>Hadoop Chapter 1: Big Data Concept(CN)</title><link>https://example.com/p/hadoop-chapter-1-big-data-conceptcn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/hadoop-chapter-1-big-data-conceptcn/</guid><description>&lt;img src="https://example.com/post/img/24.jpg" alt="Featured image of post Hadoop Chapter 1: Big Data Concept(CN)" />&lt;p>&lt;a class="link" href="https://xn--8mr985eba830aiye.vip/p/hadoop-chapter-1-big-data-concepten/" target="_blank" rel="noopener"
>English Version Portal&lt;/a>&lt;/p>
&lt;h2 id="什么是大数据">什么是大数据
&lt;/h2>&lt;ul>
&lt;li>指体积庞大的数据集合&lt;/li>
&lt;li>随时间呈指数级增长&lt;/li>
&lt;li>传统数据管理工具无法有效存储或处理&lt;/li>
&lt;li>具有海量规模的数据&lt;/li>
&lt;/ul>
&lt;h3 id="大数据类型">大数据类型
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>结构化数据&lt;/strong>：能够以固定格式存储、访问和处理的数据&lt;/li>
&lt;li>&lt;strong>非结构化数据&lt;/strong>：形式或结构未知的数据&lt;/li>
&lt;li>&lt;strong>半结构化数据&lt;/strong>：同时包含两种形式的数据&lt;/li>
&lt;/ul>
&lt;h3 id="大数据特征">大数据特征
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>体量（Volume）&lt;/strong>：数据规模庞大&lt;/li>
&lt;li>&lt;strong>多样性（Variety）&lt;/strong>：数据来源和性质的异构性&lt;/li>
&lt;li>&lt;strong>速度（Velocity）&lt;/strong>：数据生成速率&lt;/li>
&lt;li>&lt;strong>真实性（Veracity）&lt;/strong>：待分析的内容质量&lt;/li>
&lt;/ul>
&lt;h3 id="大数据处理优势">大数据处理优势
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>商业决策&lt;/strong>：可利用外部智能辅助决策&lt;/li>
&lt;li>&lt;strong>客户服务提升&lt;/strong>：改善服务质量&lt;/li>
&lt;li>&lt;strong>风险预警&lt;/strong>：早期识别产品/服务风险&lt;/li>
&lt;li>&lt;strong>运营效率&lt;/strong>：提高运营效能&lt;/li>
&lt;/ul>
&lt;h2 id="hadoop生态系统">Hadoop生态系统
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>数据存储&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>HDFS&lt;/strong>：分布式文件系统&lt;/li>
&lt;li>&lt;strong>HBase&lt;/strong>：列式数据库存储&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数据处理&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>MapReduce&lt;/strong>：集群计算框架&lt;/li>
&lt;li>&lt;strong>YARN&lt;/strong>：集群资源管理系统&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数据访问&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Hive&lt;/strong>：SQL查询引擎&lt;/li>
&lt;li>&lt;strong>Pig&lt;/strong>：数据流处理&lt;/li>
&lt;li>&lt;strong>Mahout&lt;/strong>：机器学习库&lt;/li>
&lt;li>&lt;strong>Avro&lt;/strong>：远程过程调用&lt;/li>
&lt;li>&lt;strong>Sqoop&lt;/strong>：数据迁移工具&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数据管理&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Oozie&lt;/strong>：工作流调度&lt;/li>
&lt;li>&lt;strong>Chukwa&lt;/strong>：系统监控&lt;/li>
&lt;li>&lt;strong>ZooKeeper&lt;/strong>：协调服务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hbase">HBase
&lt;/h3>&lt;ul>
&lt;li>开源非关系型分布式数据库&lt;/li>
&lt;li>NoSQL数据库类型&lt;/li>
&lt;li>支持所有数据类型&lt;/li>
&lt;li>可处理Hadoop生态系统内的任何数据&lt;/li>
&lt;li>运行于HDFS之上，提供类BigTable功能&lt;/li>
&lt;li>使用Java编写，支持REST/Avro/Thrift API&lt;/li>
&lt;/ul>
&lt;h3 id="hive">Hive
&lt;/h3>&lt;ul>
&lt;li>构建于Hadoop之上&lt;/li>
&lt;li>管理大规模分布式数据集&lt;/li>
&lt;li>核心功能：
&lt;ul>
&lt;li>提供ETL（抽取/转换/加载）工具&lt;/li>
&lt;li>存储、查询和分析HDFS/HBase数据&lt;/li>
&lt;li>将SQL转换为MapReduce任务进行海量数据分析&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>特有查询语言HQL（类SQL语法）&lt;/li>
&lt;li>支持SQL用户直接查询&lt;/li>
&lt;li>允许开发者自定义MapReduce处理复杂分析&lt;/li>
&lt;li>局限性：
&lt;ul>
&lt;li>不完全支持事务&lt;/li>
&lt;li>无法修改表数据（更新/删除/插入）&lt;/li>
&lt;li>查询延迟较高&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop">Hadoop
&lt;/h3>&lt;ul>
&lt;li>采用分布式存储处理海量信息&lt;/li>
&lt;li>数据分片存储于多个独立节点&lt;/li>
&lt;li>HDFS专为大规模数据集设计的文件系统&lt;/li>
&lt;li>核心特性：
&lt;ul>
&lt;li>低成本&lt;/li>
&lt;li>高扩展性&lt;/li>
&lt;li>灵活性&lt;/li>
&lt;li>高速处理&lt;/li>
&lt;li>容错机制&lt;/li>
&lt;li>高吞吐量&lt;/li>
&lt;li>最小化网络流量&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="storm">Storm
&lt;/h3>&lt;ul>
&lt;li>开源分布式实时计算系统&lt;/li>
&lt;li>简化流式数据的可靠处理&lt;/li>
&lt;li>高性能（单节点每秒百万级处理）&lt;/li>
&lt;li>主要特点：
&lt;ul>
&lt;li>易扩展性&lt;/li>
&lt;li>容错机制&lt;/li>
&lt;li>低延迟处理&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="zookeeper">ZooKeeper
&lt;/h3>&lt;ul>
&lt;li>Hadoop生态系统的协调者&lt;/li>
&lt;li>分布式环境中的服务协调中枢&lt;/li>
&lt;/ul>
&lt;h2 id="hadoop发展历程与版本">Hadoop发展历程与版本
&lt;/h2>&lt;ul>
&lt;li>大数据两大核心问题：
&lt;ul>
&lt;li>海量数据存储&lt;/li>
&lt;li>存储数据处理&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Hadoop作为解决方案包含：
&lt;ul>
&lt;li>HDFS分布式文件系统&lt;/li>
&lt;li>YARN资源管理器&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="发展大事记">发展大事记
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>2002&lt;/strong>：Apache Nutch项目启动&lt;/li>
&lt;li>&lt;strong>2003&lt;/strong>：Google发布GFS论文&lt;/li>
&lt;li>&lt;strong>2004&lt;/strong>：Google发布MapReduce论文&lt;/li>
&lt;li>&lt;strong>2005&lt;/strong>：Nutch分布式文件系统诞生&lt;/li>
&lt;li>&lt;strong>2006&lt;/strong>：Hadoop与HDFS正式发布&lt;/li>
&lt;li>&lt;strong>2007&lt;/strong>：Yahoo部署千节点集群&lt;/li>
&lt;li>&lt;strong>2013&lt;/strong>：Hadoop 2.0发布&lt;/li>
&lt;li>&lt;strong>2017&lt;/strong>：Hadoop 3.0发布&lt;/li>
&lt;/ul>
&lt;h2 id="hadoop发行版评估标准">Hadoop发行版评估标准
&lt;/h2>&lt;h3 id="性能表现">性能表现
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>早期重点&lt;/strong>：高吞吐量&lt;/li>
&lt;li>&lt;strong>当前趋势&lt;/strong>：兼顾低延迟&lt;/li>
&lt;li>低延迟两大关键指标：
&lt;ul>
&lt;li>原生性能&lt;/li>
&lt;li>扩展能力&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="扩展能力">扩展能力
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>文件系统&lt;/strong>：突破单NameNode架构瓶颈，实现分布式元数据管理&lt;/li>
&lt;li>&lt;strong>节点规模&lt;/strong>：支持千节点级扩展&lt;/li>
&lt;li>&lt;strong>存储密度&lt;/strong>：支持高密度磁盘节点扩展&lt;/li>
&lt;/ul>
&lt;h3 id="可靠性">可靠性
&lt;/h3>&lt;p>Apache Hadoop设计具备从单服务器到数千节点的线性扩展能力，并具有高度容错特性。&lt;/p></description></item><item><title>Hadoop Chapter 1: Big Data Concept(EN)</title><link>https://example.com/p/hadoop-chapter-1-big-data-concepten/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/hadoop-chapter-1-big-data-concepten/</guid><description>&lt;img src="https://example.com/post/img/" alt="Featured image of post Hadoop Chapter 1: Big Data Concept(EN)" />&lt;p>&lt;a class="link" href="https://xn--8mr985eba830aiye.vip/p/hadoop-chapter-1-big-data-conceptcn/" target="_blank" rel="noopener"
>中文版传送门&lt;/a>&lt;/p>
&lt;h2 id="what-is-big-data">What is Big Data
&lt;/h2>&lt;ul>
&lt;li>A collection of data that is huge in volume&lt;/li>
&lt;li>growing exponentially with time&lt;/li>
&lt;li>none of traditional data management tools can store it or process it efficiently&lt;/li>
&lt;li>a data but with huge size&lt;/li>
&lt;/ul>
&lt;h3 id="types-of-big-data">Types of Big Data
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Structured&lt;/strong>: Any data that can be stored, accessed and processed in the form of fixed format is termed as a &amp;lsquo;structured&amp;rsquo; data&lt;/li>
&lt;li>&lt;strong>Unstructured&lt;/strong>: Any data with unknown form or the structure is classified as unstructured data.&lt;/li>
&lt;li>&lt;strong>Semi-structured&lt;/strong>: Semi-structured data can contain both the forms of data.&lt;/li>
&lt;/ul>
&lt;h3 id="characteristics-of-big-data">Characteristics of Big Data
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Volume&lt;/strong>: enormous size&lt;/li>
&lt;li>&lt;strong>Variety&lt;/strong>: heterogeneous sources and the nature of data&lt;/li>
&lt;li>&lt;strong>Velocity&lt;/strong>: the speed of generation of data&lt;/li>
&lt;li>&lt;strong>Veracity&lt;/strong>: the content quality that should be analyzed&lt;/li>
&lt;/ul>
&lt;h3 id="advantages-of-big-data-processing">Advantages Of Big Data Processing
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Businesses&lt;/strong> can utilize outside intelligence while taking decisions.&lt;/li>
&lt;li>Improved &lt;strong>customer service&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Early identification&lt;/strong> of risk to the product/services, if any.&lt;/li>
&lt;li>Better &lt;strong>operational efficiency&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="hadoop-ecosystem">Hadoop Ecosystem
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>Data Storage&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>HDFS&lt;/strong>: File System&lt;/li>
&lt;li>&lt;strong>HBase&lt;/strong>: Column DB Storage&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Data Processing&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Map Reduce&lt;/strong>: Cluster Management&lt;/li>
&lt;li>&lt;strong>YARN&lt;/strong>: Cluster &amp;amp; Resource Management&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Data Access&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Hive&lt;/strong>: SQL&lt;/li>
&lt;li>&lt;strong>Pig&lt;/strong>: Dataflow&lt;/li>
&lt;li>&lt;strong>Mahout&lt;/strong>: Machine Learning&lt;/li>
&lt;li>&lt;strong>Avro&lt;/strong>: RPC&lt;/li>
&lt;li>&lt;strong>Sqoop&lt;/strong>: Data Access&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Data Management&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Oozie&lt;/strong>: Workflow Monitoring&lt;/li>
&lt;li>&lt;strong>Chukwa&lt;/strong>: Monitoring&lt;/li>
&lt;li>&lt;strong>ZooKeeper&lt;/strong>: Management&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hbase">HBase
&lt;/h3>&lt;ul>
&lt;li>an open-source, non-relational distributed database&lt;/li>
&lt;li>it is a NoSQL database&lt;/li>
&lt;li>support all types of data&lt;/li>
&lt;li>can handle anything and everything inside Hadoop ecosystem&lt;/li>
&lt;li>run on top of HDFS and provides BigTable-like capabilities&lt;/li>
&lt;li>written in Java, and HBase applications can be written in REST, Avro, and Thrift APIs&lt;/li>
&lt;/ul>
&lt;h3 id="hive">HIVE
&lt;/h3>&lt;ul>
&lt;li>built on Apache Hadoop&lt;/li>
&lt;li>manage large distributed data sets&lt;/li>
&lt;li>provides following features:
&lt;ul>
&lt;li>provides tools to extract/transform/load data(ETL)&lt;/li>
&lt;li>store, query, and analyze large-scale data stored in HDFS(or HBase)&lt;/li>
&lt;li>SQL is converted into MapReduce jobs and run on Hadoop to perform statistical analysis and processing of massive data&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>defines a query language HQL(similar to SQL)&lt;/li>
&lt;li>users familiar with SQL can query data directly
using Hive&lt;/li>
&lt;li>allows mapReducer-savvy developers to develop custom mappers and reducers to handle the complex analysis work&lt;/li>
&lt;li>disadvantages
&lt;ul>
&lt;li>does not correctly support transactions&lt;/li>
&lt;li>cannot modify table data(cannot update, delete, insert)&lt;/li>
&lt;li>slow query speed&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop">Hadoop
&lt;/h3>&lt;ul>
&lt;li>use a distributed approach to store the massive volume of information&lt;/li>
&lt;li>data was divided up and allocated to many individual databases&lt;/li>
&lt;li>HDFS is a specially design file system for storing huge datasets&lt;/li>
&lt;li>main features
&lt;ul>
&lt;li>cost&lt;/li>
&lt;li>scalability&lt;/li>
&lt;li>flexibility&lt;/li>
&lt;li>speed&lt;/li>
&lt;li>fault tolerance&lt;/li>
&lt;li>high throughput&lt;/li>
&lt;li>minimum network traffic&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="storm">STORM
&lt;/h3>&lt;ul>
&lt;li>a free, open source distributed real-time computing system&lt;/li>
&lt;li>simplifies the reliable processing of streaming data&lt;/li>
&lt;li>very fast, one test achieved one million group processing per second on a single node&lt;/li>
&lt;li>storm features:
&lt;ul>
&lt;li>easy to expand&lt;/li>
&lt;li>storm fault tolerance&lt;/li>
&lt;li>low latency&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="zookeeper">Zookeeper
&lt;/h3>&lt;ul>
&lt;li>is the coordinator of any Hadoop job which includes a combination of services in a Hadoop Ecosystem&lt;/li>
&lt;li>coordinates with various services in a distributed environment&lt;/li>
&lt;/ul>
&lt;h2 id="hadoop-history--versions">Hadoop History &amp;amp; Versions
&lt;/h2>&lt;ul>
&lt;li>Two main problems with big data
&lt;ul>
&lt;li>store such large amounts of data&lt;/li>
&lt;li>process the stored data&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Hadoop is the solution to the big data problem&lt;/li>
&lt;li>consists two components
&lt;ul>
&lt;li>Hadoop Distributed File System(HDFS)&lt;/li>
&lt;li>YARN&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-history">Hadoop History
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>2002&lt;/strong>: Apache Nutch was wtarted&lt;/li>
&lt;li>&lt;strong>2003&lt;/strong>: Google publish Google File System paper&lt;/li>
&lt;li>&lt;strong>2004&lt;/strong>: Google released paper on MapReduce&lt;/li>
&lt;li>&lt;strong>2005&lt;/strong>: Nutch Distributed File System was introduced&lt;/li>
&lt;li>&lt;strong>2006&lt;/strong>: Hadoop was introduced along HDFS&lt;/li>
&lt;li>&lt;strong>2007&lt;/strong>: Yahoo runs two cluster of 1000 machines&lt;/li>
&lt;li>&lt;strong>2013&lt;/strong>: Hadoop 2 was released&lt;/li>
&lt;li>&lt;strong>2017&lt;/strong>: Hadoop 3 was released&lt;/li>
&lt;/ul>
&lt;h2 id="hadoop-distribution-evaluation-criteria">Hadoop Distribution evaluation criteria
&lt;/h2>&lt;h3 id="performance">Performance
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>in the early days&lt;/strong>: fast throughput&lt;/li>
&lt;li>&lt;strong>now&lt;/strong>: includes low latency&lt;/li>
&lt;li>recent emphasis on low latency focuses on two key attributes
&lt;ul>
&lt;li>&lt;strong>raw performance&lt;/strong>&lt;/li>
&lt;li>&lt;strong>scalability&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="scalability">Scalability
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>File&lt;/strong> Hadoop&amp;rsquo;s default architecture consists of a single NameNode. Hadoop platform avoids single NameNode bottlenecks and has a distributed metadata architecture&lt;/li>
&lt;li>&lt;strong>Node number&lt;/strong> your chosen Hadoop implementation may need to scale to 1,000 nodes or more&lt;/li>
&lt;li>&lt;strong>Node capacity/density&lt;/strong> you need to scale nodes with higher disk density&lt;/li>
&lt;/ul>
&lt;h3 id="reliability">Reliability
&lt;/h3>&lt;p>Apache Hadoop is designed to scale from a single server to thousands of computers and is highly fault-tolerant&lt;/p></description></item><item><title>Hadoop Chapter 2: Hadoop and Big Data Architecture(CN)</title><link>https://example.com/p/hadoop-chapter-2-hadoop-and-big-data-architecturecn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/hadoop-chapter-2-hadoop-and-big-data-architecturecn/</guid><description>&lt;img src="https://example.com/post/img/25.jpg" alt="Featured image of post Hadoop Chapter 2: Hadoop and Big Data Architecture(CN)" />&lt;h2 id="hadoop-操作系统模式">Hadoop 操作系统模式
&lt;/h2>&lt;p>&lt;strong>Hadoop 四大核心运行模式&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>本地运行模式&lt;/strong>&lt;/li>
&lt;li>&lt;strong>伪分布式运行模式&lt;/strong>&lt;/li>
&lt;li>&lt;strong>完全分布式运行模式&lt;/strong>&lt;/li>
&lt;li>&lt;strong>高可用性(HA)运行模式&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-本地运行模式">Hadoop 本地运行模式
&lt;/h3>&lt;ul>
&lt;li>默认运行模式&lt;/li>
&lt;li>以单个 Java 进程运行&lt;/li>
&lt;li>又称作本地（独立）模式&lt;/li>
&lt;/ul>
&lt;h4 id="模式配置要求">模式配置要求
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>操作系统&lt;/strong>: Windows 或 Linux x64&lt;/li>
&lt;li>&lt;strong>JDK 版本&lt;/strong>: JDK jdk1.8.0_241&lt;/li>
&lt;li>&lt;strong>Hadoop 版本&lt;/strong>: 3.x&lt;/li>
&lt;/ul>
&lt;p>核心配置文件: hadoop-env.sh&lt;/p>
&lt;h3 id="hadoop-伪分布式模式">Hadoop 伪分布式模式
&lt;/h3>&lt;h4 id="模式概述">模式概述
&lt;/h4>&lt;ul>
&lt;li>模拟完全分布式环境
&lt;ul>
&lt;li>单节点运行 Hadoop&lt;/li>
&lt;li>所有 Hadoop 守护进程运行于同一服务器节点&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>包含五大核心进程
&lt;ul>
&lt;li>名称节点（NameNode）&lt;/li>
&lt;li>数据节点（DataNode）&lt;/li>
&lt;li>第二名称节点（SecondaryNameNode）&lt;/li>
&lt;li>资源管理器（ResourceManager）&lt;/li>
&lt;li>节点管理器（NodeManager）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="hdfs-守护进程">HDFS 守护进程
&lt;/h4>&lt;ul>
&lt;li>HDFS 用于存储海量数据&lt;/li>
&lt;li>正常运行所需进程
&lt;ul>
&lt;li>NameNode&lt;/li>
&lt;li>DataNode&lt;/li>
&lt;li>SecondaryNameNode&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>执行 &lt;code>start-dfs.sh&lt;/code> 命令启动 HDFS 守护进程对外提供服务&lt;/li>
&lt;/ul>
&lt;h4 id="yarn-守护进程">Yarn 守护进程
&lt;/h4>&lt;ul>
&lt;li>Hadoop 3.x 资源管理系统&lt;/li>
&lt;li>核心进程
&lt;ul>
&lt;li>ResourceManager&lt;/li>
&lt;li>NodeManager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>执行 &lt;code>start-yarn.sh&lt;/code> 启动服务&lt;/li>
&lt;/ul>
&lt;h4 id="伪分布式模式配置">伪分布式模式配置
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>HDFS 配置&lt;/strong>
&lt;ul>
&lt;li>&lt;code>core-site.xml&lt;/code>: 配置 NameNode RPC 远程通信地址，默认端口号 &lt;code>8020&lt;/code>&lt;/li>
&lt;li>&lt;code>hdfs-site.xml&lt;/code>: 设置数据块副本数为 1&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>YARN 配置&lt;/strong>
&lt;ul>
&lt;li>&lt;code>mapred-site.xml&lt;/code>: 指定 MapReduce 运行框架为 YARN&lt;/li>
&lt;li>&lt;code>yarn-site.xml&lt;/code>: 配置 ResourceManager 通信地址及 NodeManager 辅助服务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>其他配置&lt;/strong>
&lt;ul>
&lt;li>&lt;code>hadoop-env.sh&lt;/code>: 设置 hadoop.sh 中的 Java 环境变量&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-高可用性运行模式">Hadoop 高可用性运行模式
&lt;/h3>&lt;h4 id="hdfs-高可用架构">HDFS 高可用架构
&lt;/h4>&lt;ul>
&lt;li>通过主备双 NameNode 机制提升可用性
&lt;ul>
&lt;li>活跃 NameNode（Active）&lt;/li>
&lt;li>备用 NameNode（Standby/Passive）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>需解决两大核心问题
&lt;ul>
&lt;li>主备 NameNode 状态实时同步&lt;/li>
&lt;li>同一时刻仅允许一个活跃节点&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="ha-架构实现方案">HA 架构实现方案
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>仲裁日志节点方案&lt;/strong>
&lt;ul>
&lt;li>通过 JournalNodes 集群保持主备同步&lt;/li>
&lt;li>活跃 NameNode 将 EditLog 更新至 JournalNodes&lt;/li>
&lt;li>备用节点持续读取 JournalNodes 的 EditLog 变更并应用&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>共享存储方案&lt;/strong>
&lt;ul>
&lt;li>通过共享存储设备保持主备同步&lt;/li>
&lt;li>活跃 NameNode 将命名空间修改记录至共享存储的 EditLog&lt;/li>
&lt;li>备用节点读取共享存储的 EditLog 变更并应用&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>管理员必须配置至少一种隔离机制（fencing）&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-权限管理">Hadoop 权限管理
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>两级访问控制体系&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>系统级&lt;/strong>: 服务级别授权（ServiceLevel Authorization），控制指定服务是否可访问&lt;/li>
&lt;li>&lt;strong>调度器级&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="动态扩容-datanode">动态扩容 DataNode
&lt;/h3>&lt;ul>
&lt;li>在主节点增加主机名配置，并同步至所有 DataNode 节点&lt;/li>
&lt;li>Hadoop 已预制新 DataNode 配置参数，扩容步骤如下:
&lt;ul>
&lt;li>新增主机名至 hosts 文件&lt;/li>
&lt;li>分发 hadoop 安装文件至新节点&lt;/li>
&lt;li>启动新节点服务&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="动态缩容-datanode">动态缩容 DataNode
&lt;/h3>&lt;ul>
&lt;li>创建 exclude 排除文件&lt;/li>
&lt;li>将待下线节点主机名加入排除文件&lt;/li>
&lt;/ul>
&lt;h3 id="负载均衡">负载均衡
&lt;/h3>&lt;p>节点扩容后如需实现负载均衡，需执行平衡命令:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">bin/start-balancer.sh -threshold &lt;span class="m">10&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="hadoop-与大数据计算架构">Hadoop 与大数据计算架构
&lt;/h2>&lt;h3 id="hadoop-大数据生态定位">Hadoop 大数据生态定位
&lt;/h3>&lt;ul>
&lt;li>Hadoop 生态既非编程语言亦非服务&lt;/li>
&lt;li>是解决大数据问题的平台框架&lt;/li>
&lt;li>生态中多数服务围绕四大核心组件扩展
&lt;ul>
&lt;li>分布式存储 HDFS&lt;/li>
&lt;li>资源调度 YARN&lt;/li>
&lt;li>计算框架 MapReduce&lt;/li>
&lt;li>公共组件库 Common&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-实时计算架构">Hadoop 实时计算架构
&lt;/h3>&lt;p>&lt;img src="https://example.com/img/Big_Data_Technology_Ecosystem.jpg"
loading="lazy"
alt="Big Data Technology Ecosystem"
>&lt;/p></description></item><item><title>Hadoop Chapter 2: Hadoop and Big Data Architecture(EN)</title><link>https://example.com/p/hadoop-chapter-2-hadoop-and-big-data-architectureen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/hadoop-chapter-2-hadoop-and-big-data-architectureen/</guid><description>&lt;img src="https://example.com/post/img/25.jpg" alt="Featured image of post Hadoop Chapter 2: Hadoop and Big Data Architecture(EN)" />&lt;h2 id="hadoop-operating-modes">Hadoop Operating modes
&lt;/h2>&lt;p>&lt;strong>four main modes of Hadoop operation&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Local runtime mode&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Pseudo-distributed operation mode&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Fully distributed operation mode&lt;/strong>&lt;/li>
&lt;li>&lt;strong>High availability(HA) operating mode&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-local-operation-mode">Hadoop Local operation mode
&lt;/h3>&lt;ul>
&lt;li>default mode&lt;/li>
&lt;li>run as a single Java process&lt;/li>
&lt;li>called Local(Standalone) mode&lt;/li>
&lt;/ul>
&lt;h4 id="mode-configuration">Mode Configuration
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>OS&lt;/strong>: Windows or Linux x64&lt;/li>
&lt;li>&lt;strong>The JDK&lt;/strong>: JDK jdk1.8.0_241&lt;/li>
&lt;li>&lt;strong>Hadoop&lt;/strong>: 3.x&lt;/li>
&lt;/ul>
&lt;p>configuration file: hadoop-env.sh&lt;/p>
&lt;h3 id="hadoop-pseudo-distributed-mode">Hadoop pseudo-distributed mode
&lt;/h3>&lt;h4 id="overview">Overview
&lt;/h4>&lt;ul>
&lt;li>simulate a fully distributed environment
&lt;ul>
&lt;li>Hadoop run on a single node&lt;/li>
&lt;li>each Hadoop daemon running on a single server node&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>five process
&lt;ul>
&lt;li>NameNode&lt;/li>
&lt;li>DataNode&lt;/li>
&lt;li>SecondaryNameNode&lt;/li>
&lt;li>ResourceManager&lt;/li>
&lt;li>NodeManager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="hdfs-daemon-process">HDFS Daemon Process
&lt;/h4>&lt;ul>
&lt;li>HDFS is used to store large amounts of data&lt;/li>
&lt;li>required for the normal operation of the HDFS
&lt;ul>
&lt;li>NameNode&lt;/li>
&lt;li>DataNode&lt;/li>
&lt;li>SecondaryNameNode&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>run the &lt;code>start-dfs.sh&lt;/code> command to start the HDFS daemon process to provide external services&lt;/li>
&lt;/ul>
&lt;h4 id="yarn-daemon-process">Yarn Daemon Process
&lt;/h4>&lt;ul>
&lt;li>the resource management system in Hadoop 3.x&lt;/li>
&lt;li>required
&lt;ul>
&lt;li>ResourceManager&lt;/li>
&lt;li>NodeManager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>run &lt;code>start-yarn.sh&lt;/code>&lt;/li>
&lt;/ul>
&lt;h4 id="pattern-configurationpseudo-distributed-mode">Pattern Configuration(pseudo-distributed mode)
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>HDFS Configuration&lt;/strong>
&lt;ul>
&lt;li>&lt;code>core-site.xml&lt;/code>: NameNode RPC remote communication address. The default port number is &lt;code>8020&lt;/code>&lt;/li>
&lt;li>&lt;code>HDFS-site.xml&lt;/code>: set the number of data block copies to 1&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>YARN Configuration&lt;/strong>
&lt;ul>
&lt;li>&lt;code>mapred-site.xml&lt;/code>: set the MapReduce operating framework to YARN&lt;/li>
&lt;li>&lt;code>yarn-site,xml&lt;/code>: set the ResourceManager communication address and aux-services of the NodeManager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Other Configuration&lt;/strong>
&lt;ul>
&lt;li>&lt;code>hadoop-env.sh&lt;/code>: set the java environment variables in &lt;code>hadoop.sh&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-ha-running-mode">Hadoop HA Running Mode
&lt;/h3>&lt;h4 id="hdfs-ha-architecture">HDFS HA Architecture
&lt;/h4>&lt;ul>
&lt;li>
&lt;p>HA architecture solve the problem of NameNode availability by allowing us to have two NameNodes in an active/passive configuration.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Active NameNode&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Standby/Passive NameNode&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Two main issues in maintaining consistency&lt;/p>
&lt;ul>
&lt;li>Active and Standby NameNode should always be in sync with each other&lt;/li>
&lt;li>There should be only one active NameNode at a time&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="implementation-of-ha-architecture">Implementation of HA Architecture
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>Using Quorum Journal Nodes&lt;/strong>
&lt;ul>
&lt;li>JournalNodes helps the standby and active NameNode keep in sync&lt;/li>
&lt;li>The active NameNode is responsible for updating the EditLogs present in the JournalNodes.&lt;/li>
&lt;li>The StandbyNode reads the changes made to the EditLogs in the JournalNode and applies it to its own
namespace in a constant manner.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Using Shared Storage&lt;/strong>
&lt;ul>
&lt;li>A shared storage device helps standby and active NameNode keep in sync&lt;/li>
&lt;li>The active NameNode logs the record of any modification done in its namespace to an EditLog
present in this shared storage.&lt;/li>
&lt;li>The StandbyNode reads the changes made to the EditLogs in this shared
storage and applies it to its own namespace.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>The administrator must configure at least one fencing&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-authority-management">Hadoop Authority Management
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>Hadoop access control is divided into two levels&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>system level&lt;/strong>: ServiceLevel Authorization. It is used to control whether specified services can be accessed.&lt;/li>
&lt;li>&lt;strong>scheduler level&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="add-datanode">Add DataNode
&lt;/h3>&lt;ul>
&lt;li>Add a host name on the master node and copy it on any DataNode node.&lt;/li>
&lt;li>Hadoop has configured the relevant parameters to the newly added DataNode and started it on the new node. Specific steps are as follows:
&lt;ul>
&lt;li>Increase hostname&lt;/li>
&lt;li>Copy the hadoop installation file&lt;/li>
&lt;li>Start new node&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="reduce-datanode">Reduce DataNode
&lt;/h3>&lt;ul>
&lt;li>Create an exclude file&lt;/li>
&lt;li>Add the node host name to be deleted in the exclude file&lt;/li>
&lt;/ul>
&lt;h3 id="load-balancing">Load Balancing
&lt;/h3>&lt;p>After adding new nodes, if you want to achieve load balancing, you need to use the balance command: &lt;code>bin/start-balancer.sh -threshold 10&lt;/code>&lt;/p>
&lt;h2 id="hadoop-and-big-data-computing-architecture">Hadoop and Big data Computing Architecture
&lt;/h2>&lt;h3 id="hadoop-and-big-data-architecture">Hadoop and Big Data Architecture
&lt;/h3>&lt;ul>
&lt;li>Hadoop Ecosystem is neither a programming language nor a service&lt;/li>
&lt;li>It is a platform or framework which solves big data problems&lt;/li>
&lt;li>Most of the services available in the Hadoop ecosystem are to supplement the main four core components
&lt;ul>
&lt;li>HDFS&lt;/li>
&lt;li>YARN&lt;/li>
&lt;li>MapReduce&lt;/li>
&lt;li>Common&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop-real-time-computing-architecture">Hadoop Real-time Computing Architecture
&lt;/h3>&lt;p>&lt;img src="https://example.com/img/Big_Data_Technology_Ecosystem.jpg"
loading="lazy"
alt="Big Data Technology Ecosystem"
>&lt;/p></description></item><item><title>MongoDB基本语法</title><link>https://example.com/p/mongodb%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/mongodb%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</guid><description>&lt;img src="https://example.com/post/img/9.png" alt="Featured image of post MongoDB基本语法" />&lt;h3 id="增">增
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;uesr&amp;#39;).insert({&amp;#34;userId&amp;#34; : &amp;#34;014&amp;#34;,&amp;#34;uclass&amp;#34; : &amp;#34;B&amp;#34;,&amp;#34;name&amp;#34; : &amp;#34;Back&amp;#34;,&amp;#34;age&amp;#34; : 11,&amp;#34;email&amp;#34; : &amp;#34;b14@sina.com&amp;#34;,&amp;#34;birthday&amp;#34; : ISODate(&amp;#34;2018-07-31T03:46:13.885Z&amp;#34;),&amp;#34;dataStatus&amp;#34; : 1})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="删">删
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).remove({&amp;#34;userId&amp;#34;:&amp;#34;014&amp;#34;})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="改">改
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).update({&amp;#34;userId&amp;#34;:&amp;#34;013&amp;#34;},{$set:{&amp;#34;email&amp;#34;:&amp;#34;b13@sina.com&amp;#34;, &amp;#34;age&amp;#34;:20}})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>在MongoDB中，&lt;code>$set&lt;/code>是一个更新操作符，用于修改文档中某个字段的值，或向文档中添加新的字段，而不会影响其他字段。&lt;/p>&lt;/blockquote>
&lt;h3 id="查">查
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}); // 查询所有
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({&amp;#34;uclass&amp;#34;:&amp;#34;A&amp;#34;}); // 查询条件:=
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).fing({&amp;#34;name&amp;#34;:/Ba/}); // 查询条件:like
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).distinct({&amp;#34;name&amp;#34;}); // 查询条件:distinct
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({&amp;#34;age&amp;#34;:&amp;#34;{$gt:16}&amp;#34;}) // 查询条件:$gt//greater than
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({&amp;#34;uclass&amp;#34;:{$in:[&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;]}}); // 查询条件: in
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({&amp;#34;uclass&amp;#34;:&amp;#34;B&amp;#34;,&amp;#34;age&amp;#34;:{$gt:16}}) // 查询条件: and
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({$or:[{&amp;#34;uclass&amp;#34;:&amp;#34;A&amp;#34;},{&amp;#34;class&amp;#34;:&amp;#34;B&amp;#34;}]});// 查询条件: or
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({&amp;#34;birthday&amp;#34;:{$gt: new Date(&amp;#34;2008-08-14T06:24:40.110Z&amp;#34;), $lt: new Date(&amp;#34;2015-08-14T06:14:40.089Z&amp;#34;)}}); // 查询条件: 时间
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({&amp;#34;uclass&amp;#34;:&amp;#34;A&amp;#34;}).count(); // 查询条件: count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}).sort({&amp;#34;age&amp;#34;:1}); // 查询条件: sort升序
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}).sort({&amp;#34;age&amp;#34;:-1}); // 查询条件: sort降序
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).aggregate([{$group:{_id:&amp;#34;$uclass&amp;#34;,num:{$sum:1}}}]); // 聚合查询: count单列
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).aggregate([{$group:{_id:{uclass:&amp;#34;$uclass&amp;#34;, age:&amp;#34;$age&amp;#34;},num:{$sum:1}}}]); // 聚合查询: count多列
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}).limit(5); // 分页查询: limit in
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}).limit(5).skip(5); // 分页查询: limit m, n
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}, {userId:1, name:1}); // 查询指定字段
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db.getCollection(&amp;#39;user&amp;#39;).find({}, {dataStatus:0, _id:0}); // 排查指定字段
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>正则表达式语法：
&lt;code>/^Ba/&lt;/code>:匹配以&lt;code>Ba&lt;/code>开头的字符串
&lt;code>/Ba$/&lt;/code>:匹配以&lt;code>Ba&lt;/code>结尾的字符串
&lt;code>/[Bb]a/&lt;/code>:匹配&lt;code>Ba&lt;/code>或&lt;code>ba&lt;/code>
&lt;code>/ba/i&lt;/code>:查找&lt;code>name&lt;/code>字段的值包含字符串&lt;code>ba&lt;/code>的文档，不区分大小写&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>distinct的意思是去重&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>&lt;code>$gt&lt;/code>: $&amp;gt;$
&lt;code>$gte&lt;/code>: $\ge$
&lt;code>$lt&lt;/code>: $\le$
&lt;code>$lte&lt;/code>: $\le$
&lt;code>$ne&lt;/code>: $!=$
&lt;code>$eq&lt;/code>: $==$&lt;/p>&lt;/blockquote></description></item><item><title>Pytorch实践（刘二大人）1：线性模型</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</guid><description>&lt;img src="https://example.com/post/img/13.jpg" alt="Featured image of post Pytorch实践（刘二大人）1：线性模型" />&lt;h2 id="使用穷举法寻找线性回归模型中最佳权重参数w">使用穷举法寻找线性回归模型中最佳权重参数&lt;code>w&lt;/code>
&lt;/h2>&lt;p>注意：&lt;/p>
&lt;ul>
&lt;li>对于&lt;code>numpy&lt;/code>需要先下载依赖&lt;code>pip install numpy&lt;/code>&lt;/li>
&lt;li>对于&lt;code>matplotlib.pyplot&lt;/code>，若有&lt;code>anaconda&lt;/code>则无需下载&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">3.0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">4.0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">6.0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">mse_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 定义前馈函数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">w&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 定义损失函数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">loss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">arange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">4.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;w = &amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># zip函数：将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">x_val&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_val&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_val&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_sum&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss_val&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="se">\t&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">y_val&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">y_pred_val&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">loss_val&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;MSE = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss_sum&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">w_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mse_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">loss_sum&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w_list&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mse_list&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">xlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;w&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ylabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;loss&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="实现线性模型并输出loss的3d图形">实现线性模型并输出loss的3D图形
&lt;/h2>&lt;h3 id="思路">思路
&lt;/h3>&lt;ol>
&lt;li>设计线性模型$y=\omega x+b$&lt;/li>
&lt;li>预估$\omega,b$的范围并用$W,B$数组存储&lt;/li>
&lt;li>$\omega=1_n \cdot W,b=B\cdot 1_m^T$构成参数空间$(w,b)$的笛卡尔积网络&lt;/li>
&lt;li>$L_{sum}=0_{n\times m}$&lt;/li>
&lt;li>$MSE=\frac{1}{N}\sum$&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">mpl_toolkits.mplot3d&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Axes3D&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">3.0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mf">5.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">8.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">11.0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">b&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">loss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">W&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">arange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">4.1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">B&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">arange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">4.1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">meshgrid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">B&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">loss_sum&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros_like&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">x_val&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_val&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">y_val&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_sum&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss_val&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">mse&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">loss_sum&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">fig&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">figure&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 创建一个新的窗口&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fig&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add_subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">111&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">projection&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;3d&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot_surface&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">mse&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;viridis&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># camp=&amp;#39;viridis&amp;#39;指定颜色映射&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_xlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;w&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_ylabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;b&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_zlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;MSE&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）2：梯度下降算法</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA2%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA2%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</guid><description>&lt;img src="https://example.com/post/img/14.jpg" alt="Featured image of post Pytorch实践（刘二大人）2：梯度下降算法" />&lt;h2 id="思路">思路
&lt;/h2>&lt;ol>
&lt;li>
&lt;p>&lt;strong>模型定义&lt;/strong>，如假设模型为$y=w \cdot x$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>损失函数&lt;/strong>：$MSE = \frac{1}{N}\sum_{i=1}^{N}(w\cdot x_i - y_i)^2$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>梯度计算&lt;/strong>：$\frac{\partial \text{MSE}}{\partial w} = \frac{2}{N} \sum_{i=1}^{N} x_i \cdot (w \cdot x_i - y_i)$&lt;/p>
&lt;ol>
&lt;li>&lt;strong>推导&lt;/strong>：$\frac{\partial (wx_i-y_i)^2}{\partial w} = 2x_i(wx_i-y_i)$&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>更新$w$&lt;/strong>： $w_{new} = w_{old}-\alpha \cdot \frac{\partial MSE}{\partial w}$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>开始训练&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="数学推导">数学推导
&lt;/h2>&lt;ol>
&lt;li>&lt;strong>单变量&lt;/strong>，如$f(x)=\frac{1}{2}x^2\Longrightarrow \nabla x=\frac{\partial f(x)}{\partial x}=x$&lt;/li>
&lt;li>&lt;strong>多变量&lt;/strong>，如$f_1(\theta)=2\theta_1^2+3\theta_2^2+4\theta_3^2\Longrightarrow \nabla \theta = (4\theta_1,6\theta_2,8\theta_3)$&lt;/li>
&lt;li>&lt;strong>迭代公式&lt;/strong>：$x^{k+1}=x^k - \lambda\nabla f(x^k)$&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>
&lt;ol>
&lt;li>由&lt;strong>一阶泰勒展开&lt;/strong>，假设当前参数为$x^k$，在附近寻找一个更小的函数值$f(x^{k+1})$，可近似为$f(x^{k+1})\approx f(x^k)+\nabla f(x^k)^T(x^{k+1}-x^k)$&lt;/li>
&lt;li>为了最小化$f(x^{k+1})$，需要选择$x^{k+1}$使得：$x^{k+1}-x^k=-\lambda\nabla f(x^k)$&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">3.0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">4.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">6.0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 初始化假设w的值&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">1.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 线性模型为y = w * x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">w&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 损失函数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">cost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ys&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cost&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ys&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cost&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">cost&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 梯度下降函数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">gradient&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ys&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">grad&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ys&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">grad&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">grad&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">epoch_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cost_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;predict (before training)&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cost_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">grad_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">gradient&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">w&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">grad_val&lt;/span> &lt;span class="c1"># 0.01 learning rate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;epoch:&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;w=&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;loss=&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cost_val&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">epoch_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cost_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cost_val&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;predict (after training)&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch_list&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cost_list&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ylabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;cost&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">xlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;epoch&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>在梯度下降法中，参数最终只能&lt;strong>逼近理论最优值&lt;/strong>而不会完全等于它.因为&lt;strong>导数为零的点是理论解&lt;/strong>，实际计算中梯度只能趋近于零，但不会严格为零&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>损失函数(Loss Function)和代价函数(Cost Function)经常交叉使用，但是损失函数是用于衡量模型对&lt;strong>单个样本&lt;/strong>的预测值与真实值之间的差异，代价函数是用于衡量模型对&lt;strong>整个训练集&lt;/strong>的预测值与真实值之间的总体误差。&lt;/p>&lt;/blockquote>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>这里的$x^k$表示第$k$次迭代，与幂运算无关&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）3：反向传播</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA3%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA3%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</guid><description>&lt;img src="https://example.com/post/img/15.jpg" alt="Featured image of post Pytorch实践（刘二大人）3：反向传播" />&lt;h2 id="基础知识">基础知识
&lt;/h2>&lt;h3 id="pytorch语法">PyTorch语法
&lt;/h3>&lt;p>&lt;a class="link" href="https://xn--8mr985eba830aiye.vip/p/pytorch%e8%af%ad%e6%b3%95/" target="_blank" rel="noopener"
>PyTorch语法&lt;/a>&lt;/p>
&lt;h3 id="张量tensor">张量（Tensor）
&lt;/h3>&lt;p>是一个广义的数学概念&lt;/p>
&lt;ul>
&lt;li>&lt;strong>0阶张量&lt;/strong>：标量（Scalar），如温度、质量&lt;/li>
&lt;li>&lt;strong>1阶张量&lt;/strong>：向量（vector），如速度、力&lt;/li>
&lt;li>&lt;strong>2阶张量&lt;/strong>：矩阵（Matrix），如应力张量、图像像素矩阵&lt;/li>
&lt;li>&lt;strong>更高阶张量&lt;/strong>：如RGB图像（3阶张量：$高度\times 宽度\times 通道$&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>）、视频数据（4阶张量：$时间\times 高度\times 宽度\times 通道$）&lt;sup id="fnref1:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/li>
&lt;/ul>
&lt;h3 id="计算图computational-graph">计算图（Computational Graph）
&lt;/h3>&lt;p>是一种用图形化方式表示数学运算流程的工具。它将复杂的计算过程分解为&lt;strong>节点（操作或变量）&lt;strong>和&lt;/strong>边（数据流动）&lt;/strong>，直观展示数据如何通过一系列运算得到最终结果。计算图是深度学习框架（如TensorFlow、PyTorch）实现自动微分和反向传播的核心基础。&lt;/p>
&lt;h2 id="思路">思路
&lt;/h2>&lt;ol>
&lt;li>&lt;strong>前向传播&lt;/strong>：计算预测值和损失&lt;/li>
&lt;li>&lt;strong>反向传播&lt;/strong>：计算梯度&lt;/li>
&lt;li>&lt;strong>更新参数&lt;/strong>：梯度下降&lt;/li>
&lt;li>&lt;strong>验证更新后的模型&lt;/strong>&lt;/li>
&lt;li>&lt;strong>下一次反向传播&lt;/strong>&lt;/li>
&lt;/ol>
&lt;h2 id="一个具体的例子">一个具体的例子
&lt;/h2>&lt;h4 id="设定初始条件">设定初始条件
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>训练样本&lt;/strong>：$x=2,y_{pred}=4$（真实模型是$y=2x$，即$w=2$）&lt;/li>
&lt;li>&lt;strong>初始参数&lt;/strong>：$w=1.0$（随机初始化）&lt;/li>
&lt;li>&lt;strong>学习率&lt;/strong>：$\eta=0.1$&lt;/li>
&lt;/ul>
&lt;h4 id="前向传播">前向传播
&lt;/h4>&lt;ol>
&lt;li>&lt;strong>计算预测值&lt;/strong>：$y_{pred}=w\cdot x=2.0$&lt;/li>
&lt;li>&lt;strong>计算损失&lt;/strong>：$L=(y_{pred} - y_{true})^2=4.0$&lt;/li>
&lt;/ol>
&lt;h4 id="反向传播">反向传播
&lt;/h4>&lt;ol>
&lt;li>
&lt;p>&lt;strong>前向传播&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>计算&lt;/strong>$\frac{\partial L}{\partial y_{pred}}$：$\frac{\partial L}{\partial y_{pred}}=2(y_{pred}-y_{true})=2(2.0-4.0)=-4.0$&lt;/li>
&lt;li>&lt;strong>计算&lt;/strong>$\frac {\partial y_{pred}}{\partial w}$：$\frac {\partial y_{pred}}{\partial w}=x=2.0$&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>链式法则组合梯度&lt;/strong>：$\frac{\partial L}{\partial w}=\frac{\partial L}{\partial y_{pred}}\cdot \frac {\partial y_pred}{\partial w}=(-4.0)\times 2.0=-8.0$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>更新参数&lt;/strong>：$w_{new}=w_{old}-\eta \frac{\partial L}{\partial w}=1.0-0.1\times (-8.0)=1.8$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>验证更新后的模型&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>预测值&lt;/strong>：$y_{pred}=1.8\times 2=3.6$&lt;/li>
&lt;li>&lt;strong>损失&lt;/strong>：$L=(3.6-4.0)^2=0.16$&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h4 id="下一次反向传播">下一次反向传播
&lt;/h4>&lt;ol>
&lt;li>&lt;strong>计算梯度&lt;/strong>：$\frac{\partial L}{\partial y_{pred}}=2(3.6-4.0)=-0.8$，$\frac {\partial y_{pred}}{\partial w}=2.0$，$\frac{\partial L}{\partial w}=(-0.8)\times 2.0=-1.6$&lt;/li>
&lt;li>&lt;strong>更新参数&lt;/strong>：$w=1.8-0.1\times(-1.6)=1.96$&lt;/li>
&lt;li>&lt;strong>新损失&lt;/strong>：$y_{pred}=1.96\times 2=3.92$，$L=(3.92-4.0)^2=0.0064$&lt;/li>
&lt;/ol>
&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">3.0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">4.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">6.0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="c1"># w的初值为1.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">requires_grad&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">True&lt;/span> &lt;span class="c1"># 需要计算梯度&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="c1"># w是一个Tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">loss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;predict (before training)&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">l&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">l&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="se">\t&lt;/span>&lt;span class="s1">grad:&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grad&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">w&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grad&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">w&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grad&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;progress:&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">l&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;predict (after training)&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>每个通道都是一个二维矩阵，组合成三维张量&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&amp;#160;&lt;a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）4：用PyTorch实现线性回归</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA4%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA4%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid><description>&lt;img src="https://example.com/post/img/16.jpg" alt="Featured image of post Pytorch实践（刘二大人）4：用PyTorch实现线性回归" />&lt;h2 id="思路">思路
&lt;/h2>&lt;h3 id="准备数据">准备数据
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">3.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">4.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">6.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="定义模型结构">定义模型结构
&lt;/h3>&lt;ul>
&lt;li>定义线性模型$y = w \times x + b$&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">LinearModel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 输入维度1，输出维度1（即 y = w*x + b）&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 计算预测值&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">y_pred&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">LinearModel&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 创建模型实例&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>torch.nn.Linear(1, 1)&lt;/code>：PyTorch提供的线性层，自动初始化&lt;code>w&lt;/code>和&lt;code>b&lt;/code>（比如 &lt;code>w=0.5&lt;/code>, &lt;code>b=0.3&lt;/code>，随机值）&lt;/li>
&lt;/ul>
&lt;h3 id="定义损失函数和优化器">定义损失函数和优化器
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MSELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;sum&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 均方误差损失（所有样本的误差平方和）&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 随机梯度下降优化器&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>损失函数&lt;/strong>：例如，如果模型预测 &lt;code>y_pred = [1.5, 3.0, 4.5]&lt;/code>，正确值是 &lt;code>[2,4,6]&lt;/code>，则损失为 &lt;code>(1.5-2)^2 + (3-4)^2 + (4.5-6)^2&lt;/code>&lt;/li>
&lt;li>&lt;strong>优化器&lt;/strong>：&lt;code>lr=0.01&lt;/code> 是学习率（每次调整的步长）。&lt;/li>
&lt;/ul>
&lt;h3 id="训练循环">训练循环
&lt;/h3>&lt;h4 id="前向传播">前向传播：
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>用当前的&lt;code>w&lt;/code>和&lt;code>b&lt;/code>计算预测值&lt;/p>
&lt;h4 id="计算损失">计算损失
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="反向传播">反向传播
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimize&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="更新参数">更新参数
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">3.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">4.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">6.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">LinearModel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">LinearModel&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">y_pred&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">LinearModel&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MSELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;sum&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;w = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;b = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bias&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">4.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;y_pred = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_test&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）5：逻辑斯蒂回归</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA5%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA5%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92/</guid><description>&lt;img src="https://example.com/post/img/17.jpg" alt="Featured image of post Pytorch实践（刘二大人）5：逻辑斯蒂回归" />&lt;h2 id="基础知识">基础知识
&lt;/h2>&lt;h3 id="交叉熵cross-entropy">交叉熵(Cross-Entropy)
&lt;/h3>&lt;p>交叉熵衡量的是估计的概率分布Q近似真实分布P时所需的平均信息量
$$
H(P,Q)=-\sum_i P(i)lnQ(i)
$$&lt;/p>
&lt;h3 id="似然函数likelihood-function">似然函数(Likelihood Function)
&lt;/h3>&lt;p>表示给定模型参数$\theta$时，观察到当前数据集$D$的概率
$$
L(\theta;D)=P(D|\theta)
$$
&lt;strong>核心思想&lt;/strong>：最大似然估计(MLE)：通过调整参数$\theta$，使当前数据出现的概率最大化&lt;/p>
&lt;h3 id="对数似然log-likelihood">对数似然(Log-Likelihood)
&lt;/h3>&lt;p>连乘容易导致数值下溢或溢出，取对数将乘法转为加法
$$
lnL(\theta;D)=\sum_{i=1}^N lnP(y_i|x_i;\theta)
$$&lt;/p>
&lt;h3 id="损失函数loss-function">损失函数(Loss Function)
&lt;/h3>&lt;p>在最大似然估计中，负对数似然常被用作损失函数
$$
\mathcal{L}(w,b)=-\sum_{i=1}^N[y_iln\hat{y_i}+(1-y_i)ln(1-\hat{y})]
$$&lt;/p>
&lt;h2 id="数学原理">数学原理
&lt;/h2>&lt;h3 id="模型结构线性组合sigmoid函数">模型结构：线性组合+Sigmoid函数
&lt;/h3>&lt;p>逻辑斯蒂回归的核心是将线性回归的输出映射到概率空间（0和1之间）&lt;/p>
&lt;ul>
&lt;li>&lt;strong>线性部分&lt;/strong>：
&lt;ul>
&lt;li>对于输入特征向量$\vec{x}=[x_1,x_2,&amp;hellip;,x_n]$，计算线性组合：$z=\vec{w}^T\vec{x}+b=w_1x_1+w_2x_2+&amp;hellip;+w_nx_n+b$&lt;/li>
&lt;li>其中，$\vec{w}$是权重向量，$b$是偏置项&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Sigmoid函数&lt;/strong>：
&lt;ul>
&lt;li>将线性输出$z$通过Sigmoid函数转换为概率：$P(y=1|\vec{x})=\sigma(z)=\frac{1}{1+e^{-z}}$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="损失函数交叉熵">损失函数：交叉熵
&lt;/h3>&lt;p>逻辑斯蒂回归通过&lt;strong>极大似然估计&lt;/strong>（MLE）求解参数，对应的损失函数是&lt;strong>交叉熵损失&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>似然函数&lt;/strong>：对每个样本$(x_i,y_i)$，其似然为$P(y_i|x_i)=\sigma(z_i)^{y_i}\cdot (1-\sigma(z_i))^{1-y_i}$&lt;/li>
&lt;li>&lt;strong>对数似然与损失似然&lt;/strong>：$\mathcal{L}(w,b)=-\sum_{i=1}^N [y_i ln\sigma(z_i)+(1-y_i)ln(1-\sigma(z_i))]$&lt;/li>
&lt;/ul>
&lt;h3 id="参数优化梯度下降">参数优化：梯度下降
&lt;/h3>&lt;p>通过梯度下降法迭代更新权重$w$和偏置$b$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>梯度计算&lt;/strong>：Sigmoid函数的导数$\sigma &amp;lsquo;(z)=\sigma(z)(1-\sigma(z))$，损失函数$w$和$b$的梯度为：&lt;/li>
&lt;/ul>
&lt;p>$$
\frac{\partial \mathcal{L}}{\partial w_j}=\sum_{i=1}^{N}(\sigma(z_i)-y_i)x_{ij},\frac{\partial\mathcal{L}}{\partial b}=\sum_{i=1}{N}(\sigma(z_i)-y_i)
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>参数更新&lt;/strong>:&lt;/li>
&lt;/ul>
&lt;p>$$
w=w-\eta \frac{\partial \mathcal{L}}{\partial w}, b=b-\eta\frac{\partial \mathcal{L}}{\partial b}
$$&lt;/p>
&lt;h3 id="决策边界">决策边界
&lt;/h3>&lt;p>逻辑斯蒂回归的决策边界是线性的，由方程$w^Tx+b=0$定义&lt;/p>
&lt;ul>
&lt;li>当$\sigma(z)\ge 0.5$，预测$y=1$（即$z\ge 0$）；&lt;/li>
&lt;li>否则预测$y=0$&lt;/li>
&lt;/ul>
&lt;h2 id="思路">思路
&lt;/h2>&lt;h3 id="数据准备">数据准备
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">],[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],[&lt;/span>&lt;span class="mf">3.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>输入数据&lt;/strong> &lt;code>x_data&lt;/code>：3个样本，每个样本1个特征（形状为 &lt;code>[3, 1]&lt;/code>）。&lt;/li>
&lt;li>&lt;strong>标签数据&lt;/strong> &lt;code>y_data&lt;/code>：对应的二分类标签（0或1）。
&lt;ul>
&lt;li>当特征值为1.0和2.0时，标签是0；特征值为3.0时，标签是1。&lt;/li>
&lt;li>这可以理解为模型需要学习“当特征值大于某个阈值时预测为1”。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="模型定义">模型定义
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">LogisticRegressionModel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">LogisticRegressionModel&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">__init&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 表示输入和输出维度均为1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">y_pred&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="损失函数与优化器">损失函数与优化器
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BCELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">size_average&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 二元交叉熵损失（累加模式）&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 随机梯度下降&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>损失函数&lt;/strong> &lt;code>BCELoss&lt;/code>：二元交叉熵损失（Binary Cross Entropy Loss），用于衡量预测概率与真实标签的差异。
&lt;ul>
&lt;li>&lt;code>size_average=False&lt;/code> 表示损失是&lt;strong>累加&lt;/strong>而非平均（PyTorch新版本中已更名为 &lt;code>reduction='sum'&lt;/code>）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>优化器&lt;/strong> &lt;code>SGD&lt;/code>：随机梯度下降，学习率 &lt;code>lr=0.01&lt;/code>。&lt;/li>
&lt;/ul>
&lt;h3 id="训练循环">训练循环
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1000&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 前向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 计算损失&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 清空梯度&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 反向传播计算梯度&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 更新参数（w和b）&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">3.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">4.0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">6.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">LinearModel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">LinearModel&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">y_pred&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">LinearModel&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MSELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;sum&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;w = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">weight&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;b = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bias&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">4.0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_test&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;y_pred = &amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_test&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）6：处理多维特征的输入</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA6%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA6%E5%A4%84%E7%90%86%E5%A4%9A%E7%BB%B4%E7%89%B9%E5%BE%81%E7%9A%84%E8%BE%93%E5%85%A5/</guid><description>&lt;img src="https://example.com/post/img/20.jpg" alt="Featured image of post Pytorch实践（刘二大人）6：处理多维特征的输入" />&lt;h2 id="思路">思路
&lt;/h2>&lt;h3 id="数据准备">数据准备
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">xy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loadtxt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;diabetes.csv&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">:&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>x_data&lt;/code>表示读取所有行，从第一列读到倒数第二列&lt;/p>
&lt;p>&lt;code>y_data&lt;/code>表示读取所有行的最后一列&lt;/p>
&lt;h3 id="模型设计">模型设计
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>三层全连接层&lt;/strong>：构建三层神经网络模型，维度变化：&lt;code>8 -&amp;gt; 6 -&amp;gt; 4 -&amp;gt; 1&lt;/code>，逐层降低维度&lt;/li>
&lt;li>&lt;strong>激活函数&lt;/strong>：每层后接Sigmoid，将输出压缩到[0, 1]范围&lt;/li>
&lt;li>&lt;strong>前向传播&lt;/strong>：数据依次通过各层和Sigmoid，最终输出预测值&lt;/li>
&lt;/ul>
&lt;h3 id="损失函数与优化器">损失函数与优化器
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BCELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;mean&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>BCELoss&lt;/strong>（二元交叉熵损失）&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/li>
&lt;/ul>
&lt;p>$$
BCELoss(y_{pred},y_{true})=-\frac{1}{N}\sum_{i=1}^{N}[y_{true}^{(i)}\cdot log(y_{pred}^{(i)})+(1-y_{true}^{(i)})\cdot log(1-y_{pred})^{(i)}]
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>SGD&lt;/strong>（随机梯度下降）&lt;/li>
&lt;/ul>
&lt;p>$$
\theta_{t+1}=\theta_{t}-\eta \cdot\nabla_{\theta}\mathcal{L}(\theta_{t})
$$&lt;/p>
&lt;h3 id="训练循环">训练循环
&lt;/h3>&lt;ol>
&lt;li>&lt;strong>前向传播&lt;/strong>：输入数据得到预测值&lt;code>y_pred&lt;/code>&lt;/li>
&lt;li>&lt;strong>计算损失&lt;/strong>：比较&lt;code>y_pred&lt;/code>与&lt;code>y_data&lt;/code>&lt;/li>
&lt;li>&lt;strong>反向传播&lt;/strong>：计算梯度&lt;code>loss.backward()&lt;/code>，清零历史梯度&lt;code>optimizer.zero_grad()&lt;/code>&lt;/li>
&lt;li>&lt;strong>参数更新&lt;/strong>：调整模型参数&lt;code>optimizer.step()&lt;/code>&lt;/li>
&lt;li>&lt;strong>记录损失&lt;/strong>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 前向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 计算损失&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">epoch_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 反向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 参数更新&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">xy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loadtxt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;diabetes.csv&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">:&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Model&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BCELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;mean&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">epoch_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">loss_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 前向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 计算损失&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">epoch_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 反向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 参数更新&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch_list&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss_list&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ylabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;loss&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">xlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;epoch&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>“二元”指分类任务中只有两个可能的类别&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）7：加载数据集</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA7%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA7%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86/</guid><description>&lt;img src="https://example.com/post/img/21.jpg" alt="Featured image of post Pytorch实践（刘二大人）7：加载数据集" />&lt;h2 id="思路">思路
&lt;/h2>&lt;h3 id="加载数据集">加载数据集
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">DiabetesDataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Dataset&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">filepath&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">xy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loadtxt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filepath&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">len&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">xy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">:&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__getitem__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y_data&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__len__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">len&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DiabetesDataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;diabetes.csv&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dataset&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">num_workers&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>filepath&lt;/code>是外部传入的参数（数据文件路径）&lt;/li>
&lt;li>&lt;code>np.loadtxt&lt;/code>从CSV文件加载数据，返回NumPy数组&lt;/li>
&lt;li>&lt;code>xy.shape[0]&lt;/code>表示数据的第一维大小，即数据集的样本总数（行数）&lt;/li>
&lt;li>&lt;code>torch.from_numpy()&lt;/code>将NumPy数组转换为PyTorch Tensor&lt;/li>
&lt;li>&lt;code>__getitem__&lt;/code>
&lt;ul>
&lt;li>允许对象支持下标访问（如&lt;code>dataset[i]&lt;/code>）&lt;/li>
&lt;li>参数&lt;code>index&lt;/code>表示要访问的数据索引&lt;/li>
&lt;li>返回一个元组&lt;code>(x, y)&lt;/code>，即特征和 标签&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>shuffle=True&lt;/code>表示是否在每个epoch开始时打乱数据顺序。&lt;code>True&lt;/code>打乱或&lt;code>False&lt;/code>不打乱&lt;/li>
&lt;li>&lt;code>num_workers=0&lt;/code>表示用于数据加载的子进程数量。&lt;/li>
&lt;/ul>
&lt;h3 id="模型定义">模型定义
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="损失函数与优化器">损失函数与优化器
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BCELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;mean&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="训练循环">训练循环
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">labels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>for i, data in enumerate(train_loader, 0)&lt;/code>
&lt;ul>
&lt;li>&lt;code>train_loader&lt;/code>表示PyTorch的&lt;code>DataLoader&lt;/code>对象，用于按批次加载数据&lt;/li>
&lt;li>&lt;code>0&lt;/code>表示索引从0开始计数&lt;/li>
&lt;li>返回迭代器，&lt;code>i&lt;/code>表示当前批次的索引，&lt;code>data&lt;/code>表示当前批次的数据&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>inputs, labes&lt;/code>表示元组解包&lt;/li>
&lt;/ul>
&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torch.utils.data&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torch.utils.data&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">DataLoader&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">DiabetesDataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Dataset&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">filepath&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">xy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loadtxt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filepath&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">delimiter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;,&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">len&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">xy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">:&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xy&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__getitem__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x_data&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y_data&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__len__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">len&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DiabetesDataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;diabetes.csv&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dataset&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">num_workers&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linear3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Model&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BCELoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">reduction&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;mean&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;__main__&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">labels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）8：多分类问题</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA8%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA8%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/</guid><description>&lt;img src="https://example.com/post/img/22.jpg" alt="Featured image of post Pytorch实践（刘二大人）8：多分类问题" />&lt;h2 id="数学思路">数学思路
&lt;/h2>&lt;h3 id="数据表征">数据表征
&lt;/h3>&lt;p>将$28 \times 28$像素的灰度图像展开为784维向量，$x ∈ ℝ^{784}$，像素值归一化至[0, 1]区间&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>。标签采用one-hot编码，构建目标函数$y ∈ {0,1}^{10}$&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;h3 id="前向传播">前向传播
&lt;/h3>&lt;p>网络维度变化$784\Longrightarrow 512\Longrightarrow 256\Longrightarrow 128\Longrightarrow 64\Longrightarrow 10$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>第一层&lt;/strong>：$z_1=W_1x+b_1,a_1=ReLU(z_1)=max(0,z_1)$&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;strong>第二层&lt;/strong>：$z_2=W_2a_1+b_2,a_2=ReLU(z_2)$&lt;/li>
&lt;li>&lt;strong>第三层&lt;/strong>：$z_3=W_3a_2+b_3,a_3=ReLU(z_3)$&lt;/li>
&lt;li>&lt;strong>第四层&lt;/strong>：$z_4=W_4a_3+b_4,a_4=ReLU(z_4)$&lt;/li>
&lt;li>&lt;strong>输出层&lt;/strong>：$z_5=W_5a_4+b_5,\hat{y} = \text{softmax}(z_5) = \frac{e^{z_5}}{\sum_{i=1}^{10} e^{z_5^{(i)}}}$&lt;/li>
&lt;/ul>
&lt;h3 id="反向传播">反向传播
&lt;/h3>&lt;p>$$
\frac{\partial L}{\partial W_1} = \underbrace{\frac{\partial L}{\partial \hat{y}} \frac{\partial \hat{y}}{\partial z_5}}_{\delta_5} \cdot \frac{\partial z_5}{\partial a_4} \cdot \frac{\partial a_4}{\partial z_4} \cdot \frac{\partial z_4}{\partial a_3} \cdot \frac{\partial a_3}{\partial z_3} \cdot \frac{\partial z_3}{\partial a_2} \cdot \frac{\partial a_2}{\partial z_2} \cdot \frac{\partial z_2}{\partial a_1} \cdot \frac{\partial a_1}{\partial z_1} \cdot \frac{\partial z_1}{\partial W_1}
$$&lt;/p>
&lt;h3 id="参数优化">参数优化
&lt;/h3>&lt;p>对全部参数${W_i, b_i}^{5}&lt;em>{i=1}$，使用带动量的SGD更新：
$$
\begin{aligned}
v&lt;/em>{W_i} &amp;amp;:= \gamma v_{W_i} + \eta \frac{\partial L}{\partial W_i} \
W_i &amp;amp;:= W_i - v_{W_i}
\end{aligned}
$$&lt;/p>
&lt;h3 id="评估指标">评估指标
&lt;/h3>&lt;p>$$
Accuracy = \frac{(Σ_{n=1}^N I(argmax(ŷ^{(n)}) = argmax(y^{(n)})))}{N}
$$&lt;/p>
&lt;h2 id="代码思路">代码思路
&lt;/h2>&lt;h3 id="库导入与数据预处理">库导入与数据预处理
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">datasets&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torch.utils.data&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">DataLoader&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.nn.functional&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">F&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.optim&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">optim&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">64&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">([&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Normalize&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mf">0.1307&lt;/span>&lt;span class="p">,),&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mf">0.3081&lt;/span>&lt;span class="p">,))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>ToTensor()&lt;/code>将PIL图像转换为张量，&lt;code>Normalize&lt;/code>进行归一化&lt;/li>
&lt;li>&lt;strong>batch_size=64&lt;/strong>：每批处理64张图片&lt;/li>
&lt;/ul>
&lt;h3 id="数据加载">数据加载
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist/&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>shuffle=True&lt;/code>表示训练数据打乱，以增强泛化性&lt;/li>
&lt;/ul>
&lt;h3 id="神经网络模型">神经网络模型
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Net&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Net&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">512&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">256&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l4&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">64&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l5&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">784&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l4&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l5&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>结构&lt;/strong>：5层全连接网络（784→512→256→128→64→10），逐步压缩特征。&lt;/li>
&lt;li>&lt;code>x = x.view(-1, 784)&lt;/code>表示将张量转换为一维向量。&lt;code>-1&lt;/code>表示自动推导维度&lt;/li>
&lt;/ul>
&lt;h3 id="损失函数与优化器">损失函数与优化器
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CrossEntropyLoss&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">momentum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>CrossEntroplLoss&lt;/code>用于定义交叉熵损失函数，适用于多分类任务，其中每个样本的标签是单个类别&lt;/li>
&lt;/ul>
&lt;h3 id="训练函数">训练函数
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">batch_idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">outputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">300&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;[&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">, &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">batch_idx&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">] loss: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">running_loss&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="mi">300&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s1">.3f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol>
&lt;li>&lt;strong>清空梯度&lt;/strong>：&lt;code>optimizer.zero_grad()&lt;/code>&lt;/li>
&lt;li>&lt;strong>前向传播&lt;/strong>：&lt;code>outputs = model(inputs)&lt;/code>&lt;/li>
&lt;li>&lt;strong>计算损失&lt;/strong>：&lt;code>loss = criterion(outputs, target)&lt;/code>&lt;/li>
&lt;li>&lt;strong>反向传播&lt;/strong>：&lt;code>loss.backward()&lt;/code>&lt;/li>
&lt;li>&lt;strong>参数更新&lt;/strong>：&lt;code>optimizer.step()&lt;/code>&lt;/li>
&lt;/ol>
&lt;h3 id="测试函数">测试函数
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">batch_idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">outputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">300&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;[&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">, &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">batch_idx&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">] loss: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">running_loss&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="mi">300&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s1">.3f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;strong>评估模式&lt;/strong>：&lt;code>torch.no_grad()&lt;/code>禁用梯度计算，节省内存&lt;/li>
&lt;li>&lt;strong>预测计算&lt;/strong>：取输出最大值的索引作为预测类别，统计正确率&lt;/li>
&lt;/ul>
&lt;h2 id="代码实现">代码实现
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;span class="lnt">70
&lt;/span>&lt;span class="lnt">71
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">transforms&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">datasets&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torch.utils.data&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">DataLoader&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.nn.functional&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">F&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.optim&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">optim&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">64&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">([&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Normalize&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mf">0.1307&lt;/span>&lt;span class="p">,),&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mf">0.3081&lt;/span>&lt;span class="p">,))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist/&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Net&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Net&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">784&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">512&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">256&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l4&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">64&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l5&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">784&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l4&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">l5&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Net&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CrossEntropyLoss&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">momentum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">batch_idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">outputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">300&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;[&lt;/span>&lt;span class="si">%d&lt;/span>&lt;span class="s1">, &lt;/span>&lt;span class="si">%5d&lt;/span>&lt;span class="s1">] loss: &lt;/span>&lt;span class="si">%.3f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">300&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">test&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">correct&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">with&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">no_grad&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">test_loader&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">images&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">images&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">predicted&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">outputs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dim&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">total&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">labels&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">correct&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">predicted&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">labels&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;accuracy on test set: &lt;/span>&lt;span class="si">%d&lt;/span>&lt;span class="s1"> &lt;/span>&lt;span class="si">%%&lt;/span>&lt;span class="s1"> &amp;#39;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">correct&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">total&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;__main__&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">test&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>MNIST图像是灰度图，每个像素值用8位无符号整数，取值范围[0, 255]。通过线性缩放将像素值映射到[0, 1]区间：$x_{归一化}=\frac{x_{原始}}{255}$&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>One-Hot编码是一种将类别标签（如数字0-9）转换为二进制向量的方法。在MNIST中，假设某张图片的数字是3，One-Hot编码后：[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]。&lt;strong>y ∈ {0,1}¹⁰&lt;/strong> 表示这是一个长度为10的向量，每个元素只能是0或1，且&lt;strong>有且仅有一个1&lt;/strong>。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>ReLU函数：$f(x)=max(0, x)$&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Pytorch实践（刘二大人）9：卷积神经网络</title><link>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA9%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E5%AE%9E%E8%B7%B5%E5%88%98%E4%BA%8C%E5%A4%A7%E4%BA%BA9%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid><description>&lt;img src="https://example.com/post/img/23.jpg" alt="Featured image of post Pytorch实践（刘二大人）9：卷积神经网络" />&lt;h2 id="思路">思路
&lt;/h2>&lt;h3 id="导入库">导入库
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">transforms&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">datasets&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torch.utils.data&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">DataLoader&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.nn.functional&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">F&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.optim&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">optim&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>import torch&lt;/code>：PyTorch的核心库，提供张量(Tensor)操作、自动微分、GPU加速等功能&lt;/li>
&lt;li>&lt;code>from torchvision import transforms&lt;/code>：提供图像预处理工具，如尺寸调整、归一化、数据增强、&lt;/li>
&lt;li>&lt;code>from torchvision import datasets&lt;/code>：提供预置数据集（如MNIST、CIFAR）的快速下载和加载接口&lt;/li>
&lt;li>&lt;code>from torch.utils.data import DataLoader&lt;/code>：数据加载器，将数据集分批次(batch)加载，支持多线程加速和数据打乱&lt;/li>
&lt;li>&lt;code>import torch.nn.functional as F&lt;/code>：包含无需学习参数的神经网络函数（如激活函数、损失函数）&lt;/li>
&lt;li>&lt;code>import torch.optim as optim&lt;/code>：提供优化算法，如SGD等&lt;/li>
&lt;/ul>
&lt;h3 id="准备数据集">准备数据集
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">64&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Normalize&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">1307&lt;/span>&lt;span class="p">,),&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mf">0.3801&lt;/span>&lt;span class="p">,))])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MINST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>0.1307&lt;/code>是总像素的均值&lt;/li>
&lt;li>&lt;code>0.3081&lt;/code>是总像素的标准差&lt;/li>
&lt;/ul>
&lt;h3 id="模型定义">模型定义
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Net&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Net&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pooling&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MaxPool2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">320&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pooling&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pooling&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>__init__(self)&lt;/code>
&lt;ul>
&lt;li>&lt;strong>浅层&lt;/strong>(&lt;code>conv1&lt;/code>)：提取基础特征（如边缘）&lt;/li>
&lt;li>&lt;strong>深层&lt;/strong>(&lt;code>conv2&lt;/code>)：组合基础特征为高级特征&lt;/li>
&lt;li>&lt;strong>池化&lt;/strong>：逐步压缩空间信息，保留重要特征&lt;/li>
&lt;li>&lt;strong>全连接&lt;/strong>：将空间特征转换为分类结果&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>forward(self, x)&lt;/code>
&lt;ul>
&lt;li>&lt;strong>特征提取&lt;/strong>：通过两次$卷积\Rightarrow池化\Rightarrow ReLU$组合，逐步提取从简单到复杂的特征&lt;/li>
&lt;li>&lt;strong>非线性激活&lt;/strong>：每次卷积后使用&lt;code>ReLU&lt;/code>激活函数，增强模型非线性表达能力&lt;/li>
&lt;li>&lt;strong>维度压缩&lt;/strong>：池化层减少计算量并增强平移不变性&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;strong>分类输出&lt;/strong>：全连接层直接输出分类结果&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="损失函数和优化器">损失函数和优化器
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CrossEntropyLoss&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">momentum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>model.parameters()&lt;/code>返回模型中所有需要被优化（训练）的参数
&lt;ul>
&lt;li>&lt;code>conv&lt;/code>层的权重&lt;code>weight&lt;/code>和偏置&lt;code>bias&lt;/code>&lt;/li>
&lt;li>&lt;code>fc&lt;/code>层的权重和偏置&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>momentum=0.5&lt;/code>：SGD优化器的动量参数&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{aligned}
v_{W_i} &amp;amp;:= \gamma v_{W_i} + \eta \frac{\partial L}{\partial W_i} \
W_i &amp;amp;:= W_i - v_{W_i}
\end{aligned}
$$&lt;/p>
&lt;h3 id="训练函数">训练函数
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">batch_idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">outputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">300&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;[&lt;/span>&lt;span class="si">%d&lt;/span>&lt;span class="s1">, &lt;/span>&lt;span class="si">%5d&lt;/span>&lt;span class="s1">] loss: &lt;/span>&lt;span class="si">%.3f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">300&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>&lt;code>for batch_idx, data in enumerate(train_loader, 0)&lt;/code>
&lt;ul>
&lt;li>&lt;code>train_loader&lt;/code>：PyTorch的&lt;code>DataLoader&lt;/code>，按批次加载训练数据&lt;/li>
&lt;li>&lt;code>enumerate(train_loader, 0)&lt;/code>
&lt;ul>
&lt;li>返回批次索引&lt;code>batch_idx&lt;/code>（从0开始）和对应批次数据&lt;code>data&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>inputs, target = data&lt;/code>
&lt;ul>
&lt;li>&lt;code>inputs&lt;/code>是模型输入&lt;/li>
&lt;li>&lt;code>target&lt;/code>是真实标签&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="代码">代码
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">transforms&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torchvision&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">datasets&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">torch.utils.data&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">DataLoader&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.nn.functional&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">F&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.optim&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">optim&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">64&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Normalize&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mf">0.1307&lt;/span>&lt;span class="p">,),&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mf">0.3081&lt;/span>&lt;span class="p">,))])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist/&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">datasets&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MNIST&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">root&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;../dataset/mnist/&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">train&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">download&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">transform&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">DataLoader&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Net&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Module&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">super&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Net&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="fm">__init__&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pooling&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MaxPool2d&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Linear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">320&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pooling&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv1&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pooling&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conv2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Net&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">device&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;cuda&amp;#34;&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cuda&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">is_available&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="s2">&amp;#34;cpu&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">to&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">criterion&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CrossEntropyLoss&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">momentum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">train&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">batch_idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_loader&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">inputs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">to&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">to&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zero_grad&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">criterion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">outputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="mi">300&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;[&lt;/span>&lt;span class="si">%d&lt;/span>&lt;span class="s1">, &lt;/span>&lt;span class="si">%5d&lt;/span>&lt;span class="s1">] loss: &lt;/span>&lt;span class="si">%.3f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">epoch&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_idx&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">300&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">running_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>池化层通过保留局部区域最大值并降低空间分辨率，使得模型更关注“是否存在特征”而非“特征的具体位置”&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>PyTorch语法</title><link>https://example.com/p/pytorch%E8%AF%AD%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/pytorch%E8%AF%AD%E6%B3%95/</guid><description>&lt;img src="https://example.com/post/img/12.jpg" alt="Featured image of post PyTorch语法" />&lt;h2 id="在anaconda中使用pytorch">在Anaconda中使用PyTorch
&lt;/h2>&lt;ol>
&lt;li>查看CUDA版本的三种方法&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">nvcc -V
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">nvcc --version
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">nvidia -smi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>快速搭建虚拟环境&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 创建环境并指定Python版本&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda create -n &amp;lt;env_name&amp;gt; &lt;span class="nv">python&lt;/span>&lt;span class="o">=&lt;/span>3.9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 激活环境&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda activate &amp;lt;env_name&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 安装PyTorch版本&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda install pytorch torchvision torchaudio pytorch-cuda&lt;span class="o">=&lt;/span>12.1 -c pytorch -c nvidia
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 退出虚拟环境&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda deactivate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>使用Python代码进行验证是否安装成功torch&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span> &lt;span class="c1"># 如果pytorch安装成功即可导入&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cuda&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">is_available&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 查看CUDA是否可用&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cuda&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device_count&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 查看可用的CUDA数量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">version&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cuda&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 查看CUDA的版本号&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="张量tensor">张量（Tensor）
&lt;/h2>&lt;p>在PyTorch中，张量类似于Numpy中的数组，但PyTorch中的张量可以运行在不同设备，如CPU和GPU，Numpy数组只能在CPU上运行&lt;/p>
&lt;ul>
&lt;li>&lt;strong>维度（Dimensionality）&lt;/strong>：张量的维度指的是数据的多维数组结构。例如，一个标量（0维张量）是一个单独的数字，一个向量（1维张量）是一个一维数组，一个矩阵（2维张量）是一个二维数组，以此类推。&lt;/li>
&lt;li>&lt;strong>形状（Shape）&lt;/strong>：张量的形状是指每个维度上的大小。例如，一个形状为&lt;code>(3, 4)&lt;/code>的张量意味着它有3行4列。&lt;/li>
&lt;li>&lt;strong>数据类型（Dtype）&lt;/strong>：张量中的数据类型定义了存储每个元素所需的内存大小和解释方式。PyTorch支持多种数据类型，包括整数型（如&lt;code>torch.int8&lt;/code>、&lt;code>torch.int32&lt;/code>）、浮点型（如&lt;code>torch.float32&lt;/code>、&lt;code>torch.float64&lt;/code>）和布尔型（&lt;code>torch.bool&lt;/code>）。&lt;/li>
&lt;/ul>
&lt;h3 id="张量创建">张量创建
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 创建一个 2x3 的全 0 张量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">a&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 创建一个 2x3 的全 1 张量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ones&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 创建一个 2x3 的随机数张量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 从 NumPy 数组创建张量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">numpy_array&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tensor_from_numpy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_numpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">numpy_array&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tensor_from_numpy&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 在指定设备（CPU/GPU）上创建张量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">device&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;cuda&amp;#34;&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cuda&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">is_available&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="s2">&amp;#34;cpu&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">d&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">device&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">d&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>输出结果&lt;/p>
&lt;p>&lt;img src="https://example.com/img/tensor_output.jpg"
loading="lazy"
alt="输出结果"
>&lt;/p>
&lt;h3 id="常见张量操作">常见张量操作
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 张量相加&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">e&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">f&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 逐元素乘法&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 张量的转置&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">g&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 张量的形状&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>输出结果&lt;/p>
&lt;p>&lt;img src="https://example.com/img/tensor_output1.jpg"
loading="lazy"
alt="输出结果"
>&lt;/p>
&lt;p>&lt;code>item()&lt;/code>方法&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 将包含单个元素的张量转换为Python标量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="c1"># 输出：tensor([0.8], grad_fn=&amp;lt;SigmoidBackward&amp;gt;)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="c1"># 输出：0.8&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>仅限单元素张量。如果张量包含多个元素，调用&lt;code>item()&lt;/code>会报错&lt;/p>&lt;/blockquote>
&lt;h2 id="自动求导autograd">自动求导(Autograd)
&lt;/h2>&lt;p>自动求导允许计算机自动计算数学函数的导数&lt;/p>
&lt;p>在深度学习中，自动求导主要用于两个方面&lt;/p>
&lt;ol>
&lt;li>训练神经网络时计算梯度&lt;/li>
&lt;li>进行反向传播算法的实现&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>动态图与静态图&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>动态图(Dynamic Graph)&lt;/strong>：在动态图中，计算图在运行时动态构建。每次执行操作时，计算图都会更新，这使得调试和修改模型变得更加容易。PyTorch使用的是动态图。&lt;/li>
&lt;li>&lt;strong>静态图（Static Graph）&lt;/strong>：在静态图中，计算图在开始执行之前构建完成，并且不会改变。TensorFlow最初使用的是静态图，但后来也支持动态图。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 创建一个需要计算梯度的张量&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">requires_grad&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 执行某些操作&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">z&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">z&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mean&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>输出结果&lt;/p>
&lt;p>&lt;img src="https://example.com/img/autograd.jpg"
loading="lazy"
alt="输出结果"
>&lt;/p>
&lt;h3 id="反向传播backpropagation">反向传播(Backpropagation)
&lt;/h3>&lt;p>一旦定义了计算图，可以通过&lt;code>.backward()&lt;/code>方法来计算梯度&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># 反向传播，计算梯度
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">out.backward()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># 查看x的梯度
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">print(x.gred)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>输出结果&lt;/p>
&lt;p>&lt;img src="https://example.com/img/autograd1.jpg"
loading="lazy"
alt="输出结果"
>&lt;/p>
&lt;h3 id="停止梯度计算">停止梯度计算
&lt;/h3>&lt;p>如果你不希望某些张量的梯度被计算（例如，当你不需要反向传播时），可以使用 &lt;code>torch.no_grad()&lt;/code> 或设置 &lt;code>requires_grad=False&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 使用 torch.no_grad() 禁用梯度计算&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">no_grad&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>操作系统（王道）第一章：计算机系统概述</title><link>https://example.com/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%8E%8B%E9%81%93%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%8E%8B%E9%81%93%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</guid><description>&lt;img src="https://example.com/post/img/11.jpg" alt="Featured image of post 操作系统（王道）第一章：计算机系统概述" />&lt;h2 id="操作系统的基本概念">操作系统的基本概念
&lt;/h2>&lt;h3 id="操作系统的基本概念-1">操作系统的基本概念
&lt;/h3>&lt;p>&lt;!-- raw HTML omitted -->操作系统&lt;!-- raw HTML omitted -->是指&lt;!-- raw HTML omitted -->控制和管理&lt;!-- raw HTML omitted -->整个计算机系统的&lt;!-- raw HTML omitted -->硬件与软件资源&lt;!-- raw HTML omitted -->，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件&lt;!-- raw HTML omitted -->提供方便接口与环境&lt;!-- raw HTML omitted -->的程序集合。操作系统是计算机系统中最基本的系统软件&lt;/p>
&lt;p>&lt;img src="https://example.com/img/%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%b3%bb%e7%bb%9f%e7%9a%84%e5%b1%82%e6%ac%a1%e7%bb%93%e6%9e%84.png"
loading="lazy"
alt="计算机系统的层次结构"
>&lt;/p>
&lt;h3 id="操作系统的功能和目标">操作系统的功能和目标
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>&lt;strong>操作系统作为计算机系统资源的管理者&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>处理机管理&lt;/li>
&lt;li>存储器管理&lt;/li>
&lt;li>文件管理&lt;/li>
&lt;li>设备管理&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>操作系统作为用户与计算机硬件系统之间的接口&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>命令接口&lt;/strong>
&lt;ol>
&lt;li>&lt;strong>联机命令接口&lt;/strong>：也称&lt;strong>交互式命令接口&lt;/strong>，适用于分时或实时系统的接口（说一句话，做一件事）&lt;/li>
&lt;li>&lt;strong>脱机命令接口&lt;/strong>：也称&lt;strong>批处理命令接口&lt;/strong>，适用于批处理系统（说一堆话，做一堆事）&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>程序接口&lt;/strong>
&lt;ol>
&lt;li>由一组&lt;strong>系统调用&lt;/strong>（也称&lt;strong>广义指令&lt;/strong>）组成。用户在程序中使用这些系统调用来请求操作系统为其提供服务&lt;/li>
&lt;li>图形接口不是操作系统的一部分，但图形接口所调用的系统调用命令是操作系统的一部分&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>操作系统实现了对计算机资源的扩充&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>我们通常将覆盖了软件的机器称为&lt;strong>扩充机器&lt;/strong>或&lt;strong>虚拟机&lt;/strong>&lt;/li>
&lt;li>没有任何软件支持的计算机称为裸机&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="操作系统的特征">操作系统的特征
&lt;/h3>&lt;ol>
&lt;li>&lt;strong>并发&lt;/strong>：两个或多个事件在同一时间间隔内发生。注意区分并发和并行[^1]&lt;/li>
&lt;li>&lt;strong>共享&lt;/strong>：指系统中的资源可供内存中多个并发执行的进程共同使用
&lt;ol>
&lt;li>&lt;strong>互斥共享&lt;/strong>：一段时间内只允许一个进程访问&lt;/li>
&lt;li>&lt;strong>同时访问&lt;/strong>：宏观上“同时”，微观上可能是交替的对该资源进行访问，即“分时共享”&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>虚拟&lt;/strong>：将一个物理上的实体变为若干逻辑上的对应物。实现虚拟的技术称为&lt;!-- raw HTML omitted -->虚拟技术&lt;!-- raw HTML omitted -->
&lt;ol>
&lt;li>&lt;strong>时分复用技术&lt;/strong>：如虚拟处理器。将物理资源（如CPU）的使用时间划分为多个时间片（Time Slice），供多个用户或进程轮流使用。让每个进程误以为自己独占CPU资源，而实际是分时共享。&lt;/li>
&lt;li>&lt;strong>空分复用技术&lt;/strong>：如虚拟存储器。将物理资源（如内存或磁盘）划分为独立区域，分配给不同进程使用。为每个进程提供连续且独立的地址空间，隐藏物理内存的碎片化和容量限制。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>异步&lt;/strong>：多道程序环境允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，他以不可预知的速度向前推进，这就是进程的异步性&lt;/li>
&lt;/ol>
&lt;p>并发和共享是操作系统两个&lt;!-- raw HTML omitted -->最基本&lt;!-- raw HTML omitted -->的特征，两者之间互为存在的条件&lt;/p>
&lt;h2 id="操作系统发展历程">操作系统发展历程
&lt;/h2>&lt;h3 id="手工操作阶段">手工操作阶段
&lt;/h3>&lt;ul>
&lt;li>此阶段无操作系统&lt;/li>
&lt;li>两个突出的缺点：
&lt;ol>
&lt;li>用户独占全机，资源利用率低&lt;/li>
&lt;li>CPU等待手工操作，CPU的利用不充分&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h3 id="批处理阶段">批处理阶段
&lt;/h3>&lt;ul>
&lt;li>操作系统开始出现&lt;/li>
&lt;/ul>
&lt;h4 id="单道批处理系统">单道批处理系统
&lt;/h4>&lt;p>&lt;strong>主要特征&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>自动性&lt;/strong>：在顺利的情况下，磁带上的一批作业能自动的逐个运行，而无须人工干预&lt;/li>
&lt;li>&lt;strong>顺序性&lt;/strong>：磁带上的各道作业顺序地进入内存，先调入内存的先完成&lt;/li>
&lt;li>&lt;strong>单道性&lt;/strong>：内存中仅有一道程序运行&lt;/li>
&lt;/ol>
&lt;h4 id="多道批处理系统">多道批处理系统
&lt;/h4>&lt;p>&lt;strong>主要特征&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>多道&lt;/strong>&lt;/li>
&lt;li>&lt;strong>宏观上并行&lt;/strong>&lt;/li>
&lt;li>&lt;strong>微观上串行&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>优点&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>资源利用率高&lt;/strong>，多道程序共享计算机资源，从而使各种资源得到充分的利用&lt;/li>
&lt;li>&lt;strong>系统吞吐量大&lt;/strong>，CPU和其他资源保持“忙碌”状态&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>缺点&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>用户时间响应较长&lt;/li>
&lt;li>不提供人机交互能力&lt;/li>
&lt;li>用户既不能了解自己的程序的运行情况，又不能控制计算机&lt;/li>
&lt;/ol>
&lt;h3 id="分时操作系统">分时操作系统
&lt;/h3>&lt;p>所谓&lt;!-- raw HTML omitted -->分时技术&lt;!-- raw HTML omitted -->，是指将处理器的运行时间分成很短的时间片，按时间片轮流将处理器分配给各联机作业使用&lt;/p>
&lt;p>分时系统的主要特点：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>同时性&lt;/strong>。同时性也称&lt;!-- raw HTML omitted -->多路性&lt;!-- raw HTML omitted -->，指允许多个终端用户同时使用一台计算机&lt;/li>
&lt;li>&lt;strong>交互性&lt;/strong>。用户使用终端采用人机对话的方式直接控制程序运行，与同程序进行交互&lt;/li>
&lt;li>&lt;strong>独立性&lt;/strong>。系统中多个用户独立的进行操作，互不干扰&lt;/li>
&lt;li>&lt;strong>及时性&lt;/strong>。用户请求能在很短时间内获得响应&lt;/li>
&lt;/ol>
&lt;h3 id="实时操作系统">实时操作系统
&lt;/h3>&lt;p>为了能在某个时间限制内完成某些紧急任务而不需要时间片排队，诞生了实时操作系统&lt;/p>
&lt;ol>
&lt;li>&lt;strong>硬实时系统&lt;/strong>：某个动作必须绝对地在规定的时刻发生&lt;/li>
&lt;li>&lt;strong>软实时系统&lt;/strong>：能够接受偶尔违反时间规定且不会引起任何永久性的损害&lt;/li>
&lt;/ol>
&lt;h3 id="网络操作系统和分布式计算机系统">网络操作系统和分布式计算机系统
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>网络操作系统&lt;/strong>把网络中的各台计算机有机地结合起来，实现各台计算机之间的通信和数据传输等功能，实现网络中各种资源的共享&lt;/li>
&lt;li>&lt;strong>分布式计算机系统&lt;/strong>由多台计算机组成，并满足以下条件
&lt;ul>
&lt;li>系统中任意两台计算机通过通信方式交换信息&lt;/li>
&lt;li>每台计算机都具有同等的地位&lt;/li>
&lt;li>每台计算机上的资源为所有用户共享&lt;/li>
&lt;li>系统中的任意台计算机都可以构成一个子系统，并且能够重构&lt;/li>
&lt;li>任何有工作都可以分布在几台计算机上，由它们并行工作、协同完成&lt;/li>
&lt;li>&lt;strong>特点&lt;/strong>：分布性和并行性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="个人计算机操作系统">个人计算机操作系统
&lt;/h3>&lt;p>如Windows、Linux和MacOS&lt;/p>
&lt;h2 id="操作系统的运行环境">操作系统的运行环境
&lt;/h2>&lt;h3 id="处理器运行模式">处理器运行模式
&lt;/h3>&lt;blockquote>
&lt;p>计算机“指令”和高级语言“代码”是两码事。CPU看不懂高级语言程序的含义，需要将它们“翻译”成CPU能懂的机器语言，即一条条“指令”&lt;/p>&lt;/blockquote>
&lt;p>计算机系统中，通常CPU执行两种程序&lt;/p>
&lt;ol>
&lt;li>操作系统内核程序&lt;/li>
&lt;li>用户自编程序&lt;/li>
&lt;/ol>
&lt;p>前者是后者的管理者，要执行一些&lt;!-- raw HTML omitted -->特权指令&lt;!-- raw HTML omitted -->。后者出于安全考虑不能执行这些特权指令&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>特权指令&lt;/strong>，指不允许用户直接使用的指令&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>非特权指令&lt;/strong>，指允许用户直接使用的指令&lt;/p>
&lt;/li>
&lt;li>
&lt;p>CPU的运行模式分为&lt;!-- raw HTML omitted -->用户态（目态）&lt;!-- raw HTML omitted -->和&lt;!-- raw HTML omitted -->内核态（管态、核心态）&lt;!-- raw HTML omitted -->。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>应用程序运行在用户态，操作系统内核程序运行在内核态&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>内核&lt;/strong>是计算机上配置的底层软件，管理着系统的各种资源。大多数操作系统的内核包括以下4个内容&lt;/p>
&lt;ol>
&lt;li>&lt;strong>时钟管理&lt;/strong>
&lt;ol>
&lt;li>计时&lt;/li>
&lt;li>通过时钟中断，实现进程的切换&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>中断机制&lt;/strong>
&lt;ol>
&lt;li>初衷：提高多道程序运行时的CPU利用率&lt;/li>
&lt;li>发展：形成多种类型，&lt;!-- raw HTML omitted -->成为操作系统各项操作的基础&lt;!-- raw HTML omitted -->&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>原语&lt;/strong>
&lt;ol>
&lt;li>处于操作系统的底层，是&lt;!-- raw HTML omitted -->最接近&lt;!-- raw HTML omitted -->硬件的部分&lt;/li>
&lt;li>这些程序的运行具有原子性，其操作只能一气呵成&lt;/li>
&lt;li>这些程序的运行时间都较短，而且调用频繁&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>系统控制的数据结构及处理&lt;/strong>
&lt;ol>
&lt;li>&lt;strong>进程管理&lt;/strong>。进程状态管理、进程调度和分派、创建与撤销进程控制块等&lt;/li>
&lt;li>&lt;strong>存储器管理&lt;/strong>。存储器的空间分配和回收、内存信息保护程序、代码对换程序等&lt;/li>
&lt;li>&lt;strong>设备管理&lt;/strong>。缓冲区管理、设备分配和回收等&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="中断和异常的概念">中断和异常的概念
&lt;/h3>&lt;ol>
&lt;li>
&lt;p>中断和异常的定义&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>中断&lt;/strong>也称&lt;!-- raw HTML omitted -->外中断&lt;!-- raw HTML omitted -->，是指来自CPU执行指令外部的事件&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>异常&lt;/strong>也称&lt;!-- raw HTML omitted -->内中断&lt;!-- raw HTML omitted -->，是指来自CPU执行指令内部的事件引起的事件&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>中断和异常的分类&lt;/p>
&lt;ul>
&lt;li>&lt;strong>外中断&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>可屏蔽中断&lt;/strong>：指通过INTR(Interrupt Request)线发出的中断请求，通过改变屏蔽字可以实现多重中断，从而使得中断处理更加灵活&lt;/li>
&lt;li>&lt;strong>不可屏蔽中断&lt;/strong>：指通过NMI(Non-Maskable Interrupt)线发出的中断请求&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>异常&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>故障&lt;/strong>(Fault)：由指令引起的异常&lt;/li>
&lt;li>&lt;strong>自陷&lt;/strong>(Trap)：一种事先安排的“异常”事件&lt;/li>
&lt;li>&lt;strong>终止&lt;/strong>(Abort)：出现了使得CPU无法继续执行的硬件故障&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>故障异常和自陷异常属于软件中断，终止属于硬件中断&lt;/p>&lt;/blockquote>
&lt;/li>
&lt;/ol>
&lt;h3 id="中断和异常的处理过程">中断和异常的处理过程
&lt;/h3>&lt;ol>
&lt;li>CPU在执行用户指令的第$i$条指令时检测到一个异常事件，或在执行第$i$条指令后发现一个中断请求信号&lt;/li>
&lt;li>CPU打断当前用户程序&lt;/li>
&lt;li>转到相应中断或异常程序去处理
&lt;ol>
&lt;li>若能解决，则在处理程序最后CPU返回指令，回到第$i$条指令或第$i+1$条指令继续执行&lt;/li>
&lt;li>若不能解决，则终止用户程序&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="系统调用">系统调用
&lt;/h3>&lt;p>系统调用按&lt;strong>功能&lt;/strong>大致可分如下几类：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>设备管理&lt;/strong>&lt;/li>
&lt;li>&lt;strong>文件管理&lt;/strong>&lt;/li>
&lt;li>&lt;strong>进程控制&lt;/strong>&lt;/li>
&lt;li>&lt;strong>进程通信&lt;/strong>&lt;/li>
&lt;li>&lt;strong>内存管理&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>系统调用的&lt;strong>处理过程&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>第一步&lt;/strong>
&lt;ol>
&lt;li>将系统调用号和所需参数压入堆栈&lt;/li>
&lt;li>调用实际的调用指令&lt;/li>
&lt;li>执行陷入指令，将CPU从用户态转为内核态&lt;/li>
&lt;li>硬件和操作系统内核程序保护被中断的现场&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>第二步&lt;/strong>
&lt;ol>
&lt;li>分析系统调用类型&lt;/li>
&lt;li>转入相应系统调用处理子程序&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>第三步&lt;/strong>
&lt;ol>
&lt;li>系统调用处理子程序执行结束后&lt;/li>
&lt;li>恢复被中断的或设置新进程的CPU现场&lt;/li>
&lt;li>返回被中断进程或新进程&lt;/li>
&lt;li>继续往下执行&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h2 id="操作系统结构">操作系统结构
&lt;/h2>&lt;h3 id="分层法">分层法
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>将操作系统分为若干层，底层（层0）为硬件，顶层（层N）为用户接口，每层只能调用紧邻它的底层的功能和服务（单向依赖）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>分层法的&lt;strong>优点&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>便于系统的调试和验证，简化了系统的设计和实现&lt;/li>
&lt;li>易扩充和易维护&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>分层法的&lt;strong>缺点&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>合理定义各层比较困难&lt;/li>
&lt;li>效率较差&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="模块化">模块化
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>将操作系统按功能划分为若干具有一定独立性的模块。每个模块具有某方面的管理功能，并规定好各模块间的接口，使各模块之间能够通过接口进行通信。这种设计方法被称为&lt;!-- raw HTML omitted -->模块-接口法&lt;!-- raw HTML omitted -->&lt;/p>
&lt;/li>
&lt;li>
&lt;p>衡量模块独立性主要有两个标准&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>内聚性&lt;/strong>，模块内部各部分间联系的紧密程度。内聚性越高，模块独立性越好&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>耦合度&lt;/strong>，模块间相互联系和相互影响的程度。耦合度越低，模块独立性越好&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>模块化的&lt;strong>优点&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>提高了操作系统设计的正确性、可理解性和可维护性&lt;/li>
&lt;li>增强了操作系统的可适应性&lt;/li>
&lt;li>加速了操作系统的开发过程&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>模块化的&lt;strong>缺点&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>模块间的接口规定很难满足对接口的实际需求&lt;/li>
&lt;li>无法找到一个可靠的决定顺序&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="宏内核">宏内核
&lt;/h3>&lt;p>宏内核，也称&lt;!-- raw HTML omitted -->单内核&lt;!-- raw HTML omitted -->或&lt;!-- raw HTML omitted -->大内核&lt;!-- raw HTML omitted -->，是指将系统的主要功能模块都作为一个紧密联系的整体运行在内核态，从而为用户程序提供高性能的系统服务&lt;/p>
&lt;h3 id="微内核">微内核
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>微内核构架&lt;/strong>，是指将内核中最基本的功能保留在内核，而将那些不需要在内核态执行的功能移到用户态执行，从而降低内核的设计复杂性&lt;/li>
&lt;li>微内核架构将操作系统分为&lt;!-- raw HTML omitted -->微内核&lt;!-- raw HTML omitted -->和&lt;!-- raw HTML omitted -->多个服务器&lt;!-- raw HTML omitted -->
&lt;ul>
&lt;li>&lt;strong>微内核&lt;/strong>
&lt;ul>
&lt;li>与硬件紧密相关的部分&lt;/li>
&lt;li>一些较基本的功能&lt;/li>
&lt;li>客户和服务器之间的通信&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>服务器&lt;/strong>
&lt;ul>
&lt;li>绝大部分功能都存放在服务器&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>微内核的&lt;strong>基本功能&lt;/strong>
&lt;ul>
&lt;li>进程(线程)管理&lt;/li>
&lt;li>低级存储器管理&lt;/li>
&lt;li>中断和陷入处理&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>微内核的&lt;strong>特点&lt;/strong>
&lt;ul>
&lt;li>扩展性和灵活性&lt;/li>
&lt;li>可靠性和安全性&lt;/li>
&lt;li>可移植性&lt;/li>
&lt;li>分布式计算&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="外核">外核
&lt;/h3>&lt;ul>
&lt;li>在内核态中运行。任务是为虚拟机分配资源，并检查这些资源使用的安全性&lt;/li>
&lt;li>外核机制的&lt;strong>优点&lt;/strong>
&lt;ul>
&lt;li>减少了资源的“映射层”&lt;/li>
&lt;li>将多道程序与用户操作系统代码加以分隔，而且相应的负载并不重&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="操作系统引导">操作系统引导
&lt;/h2>&lt;ol>
&lt;li>激活CPU&lt;/li>
&lt;li>硬件自检&lt;/li>
&lt;li>加载带有操作系统的硬盘&lt;/li>
&lt;li>加载主引导记录&lt;/li>
&lt;li>扫描硬盘分区表&lt;/li>
&lt;li>加载分区引导记录&lt;/li>
&lt;li>加载启动管理器&lt;/li>
&lt;li>加载操作系统&lt;/li>
&lt;/ol>
&lt;h2 id="虚拟机">虚拟机
&lt;/h2>&lt;p>虚拟机是指利用虚拟化技术，将一台物理机器虚拟化为多台虚拟机器，通过隐藏特定计算平台的实际物理特性，为用户提供抽象的、统一的、模拟的计算环境&lt;/p>
&lt;h3 id="第一类虚拟机管理程序">第一类虚拟机管理程序
&lt;/h3>&lt;p>&lt;img src="https://example.com/img/%e7%ac%ac%e4%b8%80%e7%b1%bb%e8%99%9a%e6%8b%9f%e6%9c%ba.jpg"
loading="lazy"
alt="第一类虚拟机"
>&lt;/p>
&lt;ul>
&lt;li>直接运行在硬件之上，能直接控制和分配物理资源&lt;/li>
&lt;li>运行在最高特权级(Ring 0)，可以执行最高特权的指令&lt;/li>
&lt;/ul>
&lt;h3 id="第二类虚拟机管理程序">第二类虚拟机管理程序
&lt;/h3>&lt;p>&lt;img src="https://example.com/img/%e7%ac%ac%e4%ba%8c%e7%b1%bb%e8%99%9a%e6%8b%9f%e6%9c%ba.jpg"
loading="lazy"
alt="第二类虚拟机"
>&lt;/p>
&lt;ul>
&lt;li>运行在Host OS之上，依赖于Host OS为其分配物理资源&lt;/li>
&lt;li>运行在用户态、部分运行在内核态。GuestOS发出的系统调用会被VMM截获，并转化为VMM对HostOS的系统调用&lt;/li>
&lt;/ul></description></item><item><title>大数据开发技术第一章中文版</title><link>https://example.com/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF%E7%AC%AC%E4%B8%80%E7%AB%A0%E4%B8%AD%E6%96%87%E7%89%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF%E7%AC%AC%E4%B8%80%E7%AB%A0%E4%B8%AD%E6%96%87%E7%89%88/</guid><description>&lt;img src="https://example.com/post/img/19.jpg" alt="Featured image of post 大数据开发技术第一章中文版" />&lt;blockquote>
&lt;p>说明：本笔记内容基于NIIT PPT，结合个人理解整理&lt;/p>&lt;/blockquote>
&lt;h2 id="第一章a部分">第一章A部分
&lt;/h2>&lt;h3 id="大数据定义">大数据定义
&lt;/h3>&lt;p>大数据是指&lt;strong>体量庞大且随时间呈指数级增长&lt;/strong>的数据集合。&lt;/p>
&lt;h3 id="大数据类型">大数据类型
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>结构化数据&lt;/strong>（Structured）
示例：关系型数据库中的订单表&lt;/li>
&lt;li>&lt;strong>非结构化数据&lt;/strong>（Unstructured）
示例：社交媒体图片、视频文件&lt;/li>
&lt;li>&lt;strong>半结构化数据&lt;/strong>（Semi-structured）
示例：JSON格式的日志文件&lt;/li>
&lt;/ul>
&lt;h3 id="大数据核心特征4v模型">大数据核心特征（4V模型）
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>数据体量&lt;/strong>（Volume） - TB/PB级规模&lt;/li>
&lt;li>&lt;strong>处理速度&lt;/strong>（Velocity） - 数据生成与处理的时效性&lt;/li>
&lt;li>&lt;strong>数据多样性&lt;/strong>（Variety） - 多源异构数据格式&lt;/li>
&lt;li>&lt;strong>数据真实性&lt;/strong>（Veracity） - 数据质量与可信度&lt;/li>
&lt;/ul>
&lt;h3 id="大数据处理优势">大数据处理优势
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>商业洞察&lt;/strong>：通过用户行为分析优化营销策略&lt;/li>
&lt;li>&lt;strong>客户服务提升&lt;/strong>：实时反馈用户需求（如推荐系统）&lt;/li>
&lt;li>&lt;strong>风险预警&lt;/strong>：金融领域的欺诈交易识别&lt;/li>
&lt;li>&lt;strong>运营效率&lt;/strong>：物流路径优化降低运输成本&lt;/li>
&lt;/ul>
&lt;h3 id="核心术语对照表">核心术语对照表
&lt;/h3>&lt;blockquote>
&lt;p>说明：修正部分NIIT翻译以符合技术规范&lt;/p>&lt;/blockquote>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>英文术语&lt;/th>
&lt;th>NIIT官方翻译&lt;/th>
&lt;th>优化翻译&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Exponential&lt;/td>
&lt;td>指数型&lt;/td>
&lt;td>&lt;strong>指数级（增长）&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Generates&lt;/td>
&lt;td>产生&lt;/td>
&lt;td>生成&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Processed&lt;/td>
&lt;td>处理&lt;/td>
&lt;td>处理&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Structured&lt;/td>
&lt;td>结构化的&lt;/td>
&lt;td>结构化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Unstructured&lt;/td>
&lt;td>处理非结构化&lt;/td>
&lt;td>非结构化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Semi-structured&lt;/td>
&lt;td>处理半结构化&lt;/td>
&lt;td>半结构化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Enormous&lt;/td>
&lt;td>巨大的&lt;/td>
&lt;td>&lt;strong>海量的&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Heterogeneous&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/td>
&lt;td>异质&lt;/td>
&lt;td>&lt;strong>异构的&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Analyzing&lt;/td>
&lt;td>分析&lt;/td>
&lt;td>分析&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Volume&lt;/td>
&lt;td>体积&lt;/td>
&lt;td>&lt;strong>数据体量&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Velocity&lt;/td>
&lt;td>种类&lt;/td>
&lt;td>&lt;strong>处理速度&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Variety&lt;/td>
&lt;td>速度&lt;/td>
&lt;td>&lt;strong>数据多样性&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Veracity&lt;/td>
&lt;td>真实性&lt;/td>
&lt;td>&lt;strong>数据真实性&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Intelligence&lt;/td>
&lt;td>智力&lt;/td>
&lt;td>&lt;strong>智能&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="第一章b部分">第一章B部分
&lt;/h2>&lt;h3 id="hadoop生态系统工具架构">Hadoop生态系统工具架构
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>数据存储层&lt;/strong>
&lt;ul>
&lt;li>HDFS（分布式文件系统）&lt;/li>
&lt;li>HBase（分布式NoSQL数据库）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数据处理层&lt;/strong>
&lt;ul>
&lt;li>MapReduce（批处理框架）&lt;/li>
&lt;li>YARN（集群资源管理器）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数据访问层&lt;/strong>
&lt;ul>
&lt;li>Hive（SQL化查询引擎）&lt;/li>
&lt;li>Pig（数据流脚本工具）&lt;/li>
&lt;li>Mahout（机器学习库）&lt;/li>
&lt;li>Avro（序列化/RPC框架）&lt;/li>
&lt;li>Sqoop（关系型数据库连接器）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数据管理层&lt;/strong>
&lt;ul>
&lt;li>Oozie（工作流调度）&lt;/li>
&lt;li>Chukwa/Flume（日志采集）&lt;/li>
&lt;li>ZooKeeper（分布式协调服务）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="hadoop生态协作流程">Hadoop生态协作流程
&lt;/h3>&lt;ol>
&lt;li>&lt;strong>存储&lt;/strong>：用HDFS存原始数据，HBase存需快速访问的数据&lt;/li>
&lt;li>&lt;strong>处理&lt;/strong>：YARN调度资源，MapReduce做离线计算&lt;/li>
&lt;li>&lt;strong>访问&lt;/strong>：Hive执行SQL查询，Sqoop导出结果到MySQL&lt;/li>
&lt;li>&lt;strong>管理&lt;/strong>：Oozie调度任务链，ZooKeeper确保服务高可用&lt;/li>
&lt;/ol>
&lt;h4 id="hbase详解">HBase详解
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>技术特性&lt;/strong>
&lt;ul>
&lt;li>开源非关系型分布式数据库，基于Google BigTable设计&lt;/li>
&lt;li>构建于HDFS之上，提供类BigTable的低延迟读写能力&lt;/li>
&lt;li>Java语言开发，支持海量数据随机访问&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>应用场景&lt;/strong>
实时用户画像更新、物联网设备状态监控&lt;/li>
&lt;/ul>
&lt;h4 id="hive详解">Hive详解
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>技术特性&lt;/strong>
&lt;ul>
&lt;li>Hadoop生态的数据仓库工具，支持类SQL语法（HQL）&lt;/li>
&lt;li>将查询转换为MapReduce/Tez/Spark任务执行&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>应用场景&lt;/strong>
跨PB级数据集的交互式分析，如电商月度销售统计&lt;/li>
&lt;/ul>
&lt;h4 id="hdfs核心设计">HDFS核心设计
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>架构特点&lt;/strong>
&lt;ul>
&lt;li>专为商用硬件设计的分布式文件系统&lt;/li>
&lt;li>数据分块存储（默认128MB/块），跨节点冗余备份&lt;/li>
&lt;li>包含NameNode（元数据管理）与DataNode（数据存储）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="apache-storm特性">Apache Storm特性
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>实时处理能力&lt;/strong>
&lt;ul>
&lt;li>毫秒级延迟的流数据处理框架&lt;/li>
&lt;li>支持水平扩展与自动容错&lt;/li>
&lt;li>典型应用：金融实时风控、舆情监控&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="zookeeper核心功能">ZooKeeper核心功能
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>分布式协调服务&lt;/strong>
&lt;ul>
&lt;li>维护集群配置信息（如HBase RegionServer状态）&lt;/li>
&lt;li>实现分布式锁与领导者选举（如Kafka Broker选举）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="sqoop工作机制">Sqoop工作机制
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>数据迁移流程&lt;/strong>
&lt;ol>
&lt;li>通过JDBC连接关系型数据库&lt;/li>
&lt;li>生成MapReduce任务并行导入数据到HDFS&lt;/li>
&lt;li>支持增量数据同步与多种数据格式转换&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h3 id="分布式系统评估指标">分布式系统评估指标
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>评估维度&lt;/th>
&lt;th>说明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>性能表现&lt;/td>
&lt;td>处理吞吐量与资源利用率&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>可扩展性&lt;/td>
&lt;td>支持节点横向扩容的能力&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>系统可靠性&lt;/td>
&lt;td>故障自动恢复与数据完整性保障&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="核心术语对照表-1">核心术语对照表
&lt;/h3>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>英文术语&lt;/th>
&lt;th>NIIT官方翻译&lt;/th>
&lt;th>优化翻译&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Ecosystem&lt;/td>
&lt;td>生态系统&lt;/td>
&lt;td>生态系统&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Fault-tolerant&lt;/td>
&lt;td>容错&lt;/td>
&lt;td>&lt;strong>容错性&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Latency&lt;/td>
&lt;td>潜伏&lt;/td>
&lt;td>&lt;strong>延迟&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Configuration&lt;/td>
&lt;td>配置&lt;/td>
&lt;td>配置&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Synchronization&lt;/td>
&lt;td>同步化&lt;/td>
&lt;td>&lt;strong>同步&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Scalability&lt;/td>
&lt;td>可拓展性&lt;/td>
&lt;td>&lt;strong>可扩展性&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bottlenecks&lt;/td>
&lt;td>瓶颈&lt;/td>
&lt;td>瓶颈&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Clustered&lt;/td>
&lt;td>成簇的&lt;/td>
&lt;td>&lt;strong>集群化&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Replication&lt;/td>
&lt;td>复制&lt;/td>
&lt;td>&lt;strong>数据复制&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Analytics&lt;/td>
&lt;td>分析&lt;/td>
&lt;td>&lt;strong>数据分析&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;p>本翻译重点优化：&lt;/p>
&lt;ol>
&lt;li>专业术语标准化（如将&amp;quot;可拓展性&amp;quot;修正为&amp;quot;可扩展性&amp;quot;）&lt;/li>
&lt;li>补充技术细节说明（如HBase应用场景）&lt;/li>
&lt;li>通过Mermaid图表增强流程可视化&lt;/li>
&lt;li>修正原PPT中术语混淆问题（如Velocity/Variety的对应关系）&lt;/li>
&lt;/ol>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>指系统中存在多种不同形式的组成部分（如CPU/GPU混合计算集群）&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>对于机器学习公式的例子</title><link>https://example.com/p/%E5%AF%B9%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%8F%E7%9A%84%E4%BE%8B%E5%AD%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E5%AF%B9%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%8F%E7%9A%84%E4%BE%8B%E5%AD%90/</guid><description>&lt;img src="https://example.com/post/img/3.jpg" alt="Featured image of post 对于机器学习公式的例子" />&lt;h2 id="得到权重的值">得到权重的值
&lt;/h2>&lt;p>以下是一个 &lt;strong>单层神经网络（感知机）&lt;/strong> 的完整示例，通过 &lt;strong>手动模拟训练过程&lt;/strong>，展示如何从数据中学习权重。我们以 &lt;strong>房价预测&lt;/strong> 为例，假设数据仅包含一个样本，目标是让模型学会调整权重和偏置。&lt;/p>
&lt;h3 id="问题设定">&lt;strong>问题设定&lt;/strong>
&lt;/h3>&lt;h4 id="输入特征">&lt;strong>输入特征&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>$ x_1 $（面积）：1（标准化后的值，如100平方米）&lt;/li>
&lt;li>$ x_2 $（房龄）：1（标准化后的值，如5年）&lt;/li>
&lt;/ul>
&lt;h4 id="真实输出">&lt;strong>真实输出&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>$ y_{\text{true}} = 3 $（单位：万元）&lt;/li>
&lt;/ul>
&lt;h4 id="模型结构">&lt;strong>模型结构&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>线性模型&lt;/strong>：$ y_{\text{pred}} = w_1 x_1 + w_2 x_2 + b $&lt;/li>
&lt;li>&lt;strong>初始参数&lt;/strong>（随机初始化）：
&lt;ul>
&lt;li>权重：$ w_1 = 0.5 $, $ w_2 = -0.3 $&lt;/li>
&lt;li>偏置：$ b = 0.2 $&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="目标">&lt;strong>目标&lt;/strong>
&lt;/h4>&lt;p>通过梯度下降，调整 $ w_1, w_2, b $，使得 $ y_{\text{pred}} $ 接近真实值 3。&lt;/p>
&lt;h3 id="训练过程">&lt;strong>训练过程&lt;/strong>
&lt;/h3>&lt;h4 id="前向传播计算预测值">&lt;strong>前向传播（计算预测值）&lt;/strong>
&lt;/h4>&lt;p>$$
y_{\text{pred}} = w_1 x_1 + w_2 x_2 + b = 0.5 \times 1 + (-0.3) \times 1 + 0.2 = 0.5 - 0.3 + 0.2 = 0.4
$$
此时预测值为 0.4 万元，与真实值 3 相差较大。&lt;/p>
&lt;h4 id="计算损失均方误差">&lt;strong>计算损失（均方误差）&lt;/strong>
&lt;/h4>&lt;p>$$
\text{Loss} = (y_{\text{true}} - y_{\text{pred}})^2 = (3 - 0.4)^2 = 6.76
$$&lt;/p>
&lt;h4 id="反向传播计算梯度">&lt;strong>反向传播（计算梯度）&lt;/strong>
&lt;/h4>&lt;p>对每个参数求偏导（链式法则）：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>损失对 $ w_1 $ 的梯度&lt;/strong>：
$$
\frac{\partial \text{Loss}}{\partial w_1} = 2(y_{\text{pred}} - y_{\text{true}}) \cdot x_1 = 2(0.4 - 3) \times 1 = -5.2
$$&lt;/li>
&lt;li>&lt;strong>损失对 $ w_2 $ 的梯度&lt;/strong>：
$$
\frac{\partial \text{Loss}}{\partial w_2} = 2(y_{\text{pred}} - y_{\text{true}}) \cdot x_2 = 2(0.4 - 3) \times 1 = -5.2
$$&lt;/li>
&lt;li>&lt;strong>损失对 $ b $ 的梯度&lt;/strong>：
$$
\frac{\partial \text{Loss}}{\partial b} = 2(y_{\text{pred}} - y_{\text{true}}) = 2(0.4 - 3) = -5.2
$$&lt;/li>
&lt;/ul>
&lt;h4 id="更新参数梯度下降">&lt;strong>更新参数（梯度下降）&lt;/strong>
&lt;/h4>&lt;p>设定学习率 $ \eta = 0.1 $，更新规则：
$$
w_{\text{new}} = w_{\text{old}} - \eta \cdot \frac{\partial \text{Loss}}{\partial w}
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>更新 $ w_1 $&lt;/strong>：
$$
w_1 = 0.5 - 0.1 \times (-5.2) = 0.5 + 0.52 = 1.02
$$&lt;/li>
&lt;li>&lt;strong>更新 $ w_2 $&lt;/strong>：
$$
w_2 = -0.3 - 0.1 \times (-5.2) = -0.3 + 0.52 = 0.22
$$&lt;/li>
&lt;li>&lt;strong>更新 $ b $&lt;/strong>：
$$
b = 0.2 - 0.1 \times (-5.2) = 0.2 + 0.52 = 0.72
$$&lt;/li>
&lt;/ul>
&lt;h3 id="更新后的预测">&lt;strong>更新后的预测&lt;/strong>
&lt;/h3>&lt;p>使用新参数重新计算预测值：
$$
y_{\text{pred}} = 1.02 \times 1 + 0.22 \times 1 + 0.72 = 1.02 + 0.22 + 0.72 = 1.96
$$
损失更新为：
$$
\text{Loss} = (3 - 1.96)^2 = 1.08
$$
&lt;strong>仅一次迭代，损失从 6.76 下降到 1.08&lt;/strong>，说明权重调整有效。&lt;/p>
&lt;h3 id="多轮迭代后的结果">&lt;strong>多轮迭代后的结果&lt;/strong>
&lt;/h3>&lt;p>重复上述过程（假设学习率不变）：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>迭代次数&lt;/th>
&lt;th>$ w_1 $&lt;/th>
&lt;th>$ w_2 $&lt;/th>
&lt;th>$ b $&lt;/th>
&lt;th>$ y_{\text{pred}} $&lt;/th>
&lt;th>Loss&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>0&lt;/td>
&lt;td>0.5&lt;/td>
&lt;td>-0.3&lt;/td>
&lt;td>0.2&lt;/td>
&lt;td>0.4&lt;/td>
&lt;td>6.76&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>1.02&lt;/td>
&lt;td>0.22&lt;/td>
&lt;td>0.72&lt;/td>
&lt;td>1.96&lt;/td>
&lt;td>1.08&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>1.45&lt;/td>
&lt;td>0.65&lt;/td>
&lt;td>1.17&lt;/td>
&lt;td>2.60&lt;/td>
&lt;td>0.16&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>1.68&lt;/td>
&lt;td>0.89&lt;/td>
&lt;td>1.43&lt;/td>
&lt;td>2.96&lt;/td>
&lt;td>0.0016&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>经过3次迭代，预测值 $ y_{\text{pred}} = 2.96 $ 接近真实值3，损失降至0.0016。&lt;/p>
&lt;h3 id="关键结论">&lt;strong>关键结论&lt;/strong>
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>权重的本质&lt;/strong>：模型通过梯度下降，沿着损失减小的方向调整权重，逐步逼近真实值。&lt;/li>
&lt;li>&lt;strong>学习率的作用&lt;/strong>：学习率 $ \eta $ 控制参数更新步幅（过大可能导致震荡，过小收敛慢）。&lt;/li>
&lt;li>&lt;strong>实际训练&lt;/strong>：真实场景中需使用大量数据分批训练，而非单个样本。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>附：Python代码模拟&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 初始参数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">w1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mf">0.3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_true&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">eta&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">epoch&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 前向传播&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">y_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">w1&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">x1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">w2&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">x2&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">b&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">y_true&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y_pred&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">**&lt;/span>&lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 计算梯度&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dL_dw1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y_true&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">x1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dL_dw2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y_true&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">x2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dL_db&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y_pred&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">y_true&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 更新参数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">w1&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="n">eta&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">dL_dw1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">w2&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="n">eta&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">dL_dw2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">b&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="n">eta&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">dL_db&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Epoch &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">epoch&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">: w1=&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">w1&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s2">.2f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">, w2=&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">w2&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s2">.2f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">, b=&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s2">.2f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">, y_pred=&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">y_pred&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s2">.2f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">, Loss=&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">loss&lt;/span>&lt;span class="si">:&lt;/span>&lt;span class="s2">.4f&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="y--b--sum_i-c_i--textsigmoidb_i--sum_j-w_ij-x_j">$y = b + \sum_i c_i , \text{sigmoid}(b_i + \sum_j w_{ij} x_j)$
&lt;/h2>&lt;p>假设我们要根据房屋的两个特征预测房价&lt;/p>
&lt;ul>
&lt;li>&lt;strong>特征1($x_1$)&lt;/strong>：面积（平方米）&lt;/li>
&lt;li>&lt;strong>特征2($x_2$)&lt;/strong>：房龄（年）&lt;/li>
&lt;/ul>
&lt;p>我们设计一个简单的神经网络，结构如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>输入层：&lt;/strong> 两个特征（$x_1,x_2$）&lt;/li>
&lt;li>&lt;strong>隐藏层&lt;/strong>： 2个神经元（$i=1,2$）&lt;/li>
&lt;li>&lt;strong>输出层&lt;/strong>： 1个输出（房价$y$）&lt;/li>
&lt;/ul>
&lt;h3 id="step-1设定参数值">step 1：设定参数值
&lt;/h3>&lt;p>假设模型已经训练完成，参数如下：&lt;/p>
&lt;p>&lt;strong>隐藏层参数&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>神经元&lt;/th>
&lt;th>权重$w_{i1}$（面积权重）&lt;/th>
&lt;th>权重$w_{i2}$(房龄权重)&lt;/th>
&lt;th>偏置$b_i$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1$(i=1)$&lt;/td>
&lt;td>0.8&lt;/td>
&lt;td>-0.2&lt;/td>
&lt;td>0.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2$(i=2)$&lt;/td>
&lt;td>0.5&lt;/td>
&lt;td>-0.6&lt;/td>
&lt;td>-0.3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>输出层参数&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>权重$c_i$&lt;/th>
&lt;th>偏置$b$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>$c_1=10$&lt;/td>
&lt;td>$b=5$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>$c_2=-8$&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="step-2输出数据">step 2：输出数据
&lt;/h3>&lt;p>假设有一套房子的特征值为：&lt;/p>
&lt;ul>
&lt;li>面积$x_1=100m^2$&lt;/li>
&lt;li>房龄$x_2=5年$&lt;/li>
&lt;/ul>
&lt;h3 id="step-3计算隐藏层输出">step 3：计算隐藏层输出
&lt;/h3>&lt;p>对每个隐藏层神经元，计算$z_i,=,b_i,+,w_{i1}x_1,+,w_{i2}x_2$，然后通过$sigmoid$激活函数得到$a_i=sigmoid(z_i)$&lt;/p>
&lt;p>&lt;strong>神经元1($i=1$)的计算&lt;/strong>&lt;/p>
&lt;p>$$
\begin{aligned}
z_1 = b_1 + w_{11}x_1 + w_{12}x_2 = 0.5 + 0.8 \times 100 + (-0.2) \times 5 = 0.5 + 80 - 1 = 79.5\
a_1 = \text{sigmoid}(79.5) = \frac{1}{1 + e^{-79.5}} \approx 1.0 \quad (\text{几乎完全激活})
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>神经元2($i=2$)的计算&lt;/strong>&lt;/p>
&lt;p>$$
\begin{aligned}
z_2 = b_2 + w_{21}x_1 + w_{22}x_2 = -0.3 + 0.5 \times 100 + (-0.6) \times 5 = -0.3 + 50 - 3 = 46.7\
a_2 = \text{sigmoid}(46.7) = \frac{1}{1 + e^{-46.7}} \approx 1.0 \quad (\text{几乎完全激活})
\end{aligned}
$$&lt;/p>
&lt;h3 id="step-4计算输出层结果">step 4：计算输出层结果
&lt;/h3>&lt;p>$$
y = b + c_1 a_1 + c_2 a_2 = 5 + 10 \times 1.0 + (-8) \times 1.0 = 5 + 10 - 8 = 7
$$&lt;/p>
&lt;h2 id="lthetaapprox-ltheta-ltheta---thetagfrac12theta-thetaththeta-theta-">$L(\theta)\approx L(\theta ^{&amp;rsquo;})+L(\theta - \theta^{&amp;rsquo;})g+\frac{1}{2}(\theta-\theta^{&amp;rsquo;})^{T}H(\theta-\theta ^{&amp;rsquo;})$
&lt;/h2>&lt;p>由于&lt;del>线性代数学艺不精&lt;/del>热爱线性代数，重新推导这个公式&lt;/p>
&lt;ol>
&lt;li>&lt;strong>回忆一维泰勒展开&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>例如，在$x&amp;rsquo;$附件展开$f(x)$
$$
f(x)\approx f(x&amp;rsquo;)+f&amp;rsquo;(x&amp;rsquo;)(x-x&amp;rsquo;)+\frac{1}{2}f&amp;quot;(x&amp;rsquo;)(x-x&amp;rsquo;)^2
$$&lt;/p>
&lt;p>对于泰勒展开公式：
$$
f(x_0,x)=\sum_{i=0}^n \frac{f^{(i)}(x_0)}{i!}(x-x_0)^i
$$&lt;/p>
&lt;ol start="2">
&lt;li>&lt;strong>扩展到多维情况（参数$\theta$是向量）&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>$L(\theta)\approx L(\theta ^{&amp;rsquo;})+L(\theta - \theta^{&amp;rsquo;})g+\frac{1}{2}(\theta-\theta^{&amp;rsquo;})^{T}H(\theta-\theta ^{&amp;rsquo;})$&lt;/p>
&lt;p>在多维情况下，参数是向量$\theta = [\theta_1,\theta_2,&amp;hellip;\theta_n]^T$，梯度$g$是一阶导数的推广&lt;/p>
&lt;p>对于&lt;strong>Hessian&lt;/strong>矩阵，是多元函数的二阶偏导数构成的矩阵
$$
H = \nabla^2 f = \begin{bmatrix}
\frac{\partial^2 f}{\partial \theta_1^2} &amp;amp; \frac{\partial^2 f}{\partial \theta_1 \partial \theta_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial \theta_1 \partial \theta_n} \
\frac{\partial^2 f}{\partial \theta_2 \partial \theta_1} &amp;amp; \frac{\partial^2 f}{\partial \theta_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial \theta_2 \partial \theta_n} \
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \
\frac{\partial^2 f}{\partial \theta_n \partial \theta_1} &amp;amp; \frac{\partial^2 f}{\partial \theta_n \partial \theta_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial \theta_n^2}
\end{bmatrix}
$$&lt;/p>
&lt;p>&lt;strong>为什么需要转置 $(\theta - \theta&amp;rsquo;)^\top$？&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>维度匹配&lt;/strong>：假设 $\theta$ 是 $n \times 1$ 向量，梯度 $g$ 也是 $n \times 1$，Hessian H$ $H$是 $n \times n$。
&lt;ul>
&lt;li>一阶项：$(\theta - \theta &amp;lsquo;)^Tg$是$n \times 1$向量，梯度$g$也是$n\times 1$，Hessian $H$是$n \times n$（标量）
&lt;ul>
&lt;li>一阶项：$(\theta - \theta &amp;lsquo;)g$是$1\times n*n\times n * n \times 1=1\times 1$（标量）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>数学必要性&lt;/strong>：转置确保矩阵乘法维度相容。&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>&lt;strong>一个具体的例子&lt;/strong>&lt;/li>
&lt;/ol>
&lt;h5 id="1-定义函数">&lt;strong>1. 定义函数&lt;/strong>
&lt;/h5>&lt;p>设损失函数 $L(\theta) = \theta_1^2 + 2\theta_2^2 + \theta_1\theta_2$，参考点 $\theta&amp;rsquo; = [0, 0]^\top$。&lt;/p>
&lt;h5 id="2-计算梯度-g">&lt;strong>2. 计算梯度 $g$&lt;/strong>
&lt;/h5>&lt;p>$$
g = \nabla L(\theta&amp;rsquo;) = \begin{bmatrix} 2\theta_1 + \theta_2 \ 4\theta_2 + \theta_1 \end{bmatrix} \bigg|_{\theta&amp;rsquo;=[0,0]} = \begin{bmatrix} 0 \ 0 \end{bmatrix}
$$&lt;/p>
&lt;h5 id="3-计算-hessian-矩阵-h">&lt;strong>3. 计算 Hessian 矩阵 $H$&lt;/strong>
&lt;/h5>&lt;p>$$
H = \nabla^2 L(\theta&amp;rsquo;) = \begin{bmatrix}
\frac{\partial^2 L}{\partial \theta_1^2} &amp;amp; \frac{\partial^2 L}{\partial \theta_1 \partial \theta_2} \
\frac{\partial^2 L}{\partial \theta_2 \partial \theta_1} &amp;amp; \frac{\partial^2 L}{\partial \theta_2^2}
\end{bmatrix} = \begin{bmatrix} 2 &amp;amp; 1 \ 1 &amp;amp; 4 \end{bmatrix}
$$&lt;/p>
&lt;h5 id="4-泰勒展开公式">&lt;strong>4. 泰勒展开公式&lt;/strong>
&lt;/h5>&lt;p>在 $\theta&amp;rsquo; = [0, 0]^\top$ 处展开：
$$
L(\theta) \approx \underbrace{0}&lt;em>{L(\theta&amp;rsquo;)} + \underbrace{(\theta - 0)^\top \begin{bmatrix} 0 \ 0 \end{bmatrix}}&lt;/em>{\text{一阶项}} + \frac{1}{2}(\theta - 0)^\top \begin{bmatrix} 2 &amp;amp; 1 \ 1 &amp;amp; 4 \end{bmatrix} (\theta - 0)
$$&lt;/p>
&lt;p>化简后：
$$
L(\theta) \approx \frac{1}{2}\theta^\top \begin{bmatrix} 2 &amp;amp; 1 \ 1 &amp;amp; 4 \end{bmatrix} \theta = \frac{1}{2}(2\theta_1^2 + 2\theta_1\theta_2 + 4\theta_2^2)
$$&lt;/p>
&lt;p>展开后与原函数一致：
$$
L(\theta) = \theta_1^2 + 2\theta_2^2 + \theta_1\theta_2
$$&lt;/p></description></item><item><title>防晒衣购买指南</title><link>https://example.com/p/%E9%98%B2%E6%99%92%E8%A1%A3%E8%B4%AD%E4%B9%B0%E6%8C%87%E5%8D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E9%98%B2%E6%99%92%E8%A1%A3%E8%B4%AD%E4%B9%B0%E6%8C%87%E5%8D%97/</guid><description>&lt;img src="https://example.com/post/img/18.jpg" alt="Featured image of post 防晒衣购买指南" />&lt;h2 id="材质选择">材质选择
&lt;/h2>&lt;ol>
&lt;li>尽量不选&lt;!-- raw HTML omitted -->聚酯纤维&lt;!-- raw HTML omitted -->，会不透气&lt;/li>
&lt;li>面料成分建议要有&lt;!-- raw HTML omitted -->80%&lt;!-- raw HTML omitted -->以上是&lt;!-- raw HTML omitted -->锦纶&lt;!-- raw HTML omitted -->，穿上更舒服、透气&lt;/li>
&lt;/ol>
&lt;h2 id="防晒指数">防晒指数
&lt;/h2>&lt;ol>
&lt;li>&lt;strong>UPF&lt;/strong>：紫外线防护指数。国标&lt;!-- raw HTML omitted -->UPF50+&lt;!-- raw HTML omitted -->表示防晒能力优秀&lt;/li>
&lt;li>&lt;strong>UVA&lt;/strong>：长波紫外线。国标&lt;!-- raw HTML omitted -->UVA的透射率 &amp;lt; 5%&lt;!-- raw HTML omitted -->&lt;/li>
&lt;/ol>
&lt;h2 id="工艺选择">工艺选择
&lt;/h2>&lt;ol>
&lt;li>&lt;strong>原纱线&lt;/strong>：耐用耐洗质量稳定&lt;/li>
&lt;li>&lt;strong>染色助剂&lt;/strong>：价格适中，透气性好，防晒效果会随洗涤次数减少&lt;/li>
&lt;li>&lt;strong>涂层工艺&lt;/strong>：价格便宜，透气性差，不耐用&lt;/li>
&lt;/ol></description></item><item><title>购买指南</title><link>https://example.com/p/%E8%B4%AD%E4%B9%B0%E6%8C%87%E5%8D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E8%B4%AD%E4%B9%B0%E6%8C%87%E5%8D%97/</guid><description>&lt;h2 id="电饭煲的购买">电饭煲的购买
&lt;/h2>&lt;h3 id="电饭煲容量">电饭煲容量
&lt;/h3>&lt;ol>
&lt;li>&lt;strong>1-2人&lt;/strong>选择$\le 3L$&lt;/li>
&lt;li>&lt;strong>3-5人&lt;/strong>选择$3-4L$&lt;/li>
&lt;li>&lt;strong>大家庭&lt;/strong>选择$5L$以上的&lt;/li>
&lt;/ol>
&lt;h3 id="内胆">内胆
&lt;/h3>&lt;h4 id="材质">材质
&lt;/h4>&lt;ul>
&lt;li>铁质内胆＞多层复合内胆＞铝合金内胆＞不锈钢内胆＞陶瓷内胆&lt;/li>
&lt;li>多层复合内胆锌价比较高，如铝合金＋不锈钢&lt;/li>
&lt;/ul>
&lt;h4 id="涂层">涂层
&lt;/h4>&lt;p>建议复合涂层：PEEK+PFA/PTFE＞PFA＞PFA+PTFE＞PTFE&lt;/p>
&lt;h4 id="厚度">厚度
&lt;/h4>&lt;ul>
&lt;li>厚一点为佳&lt;/li>
&lt;li>3mm＞2mm＞1.5mm&lt;/li>
&lt;/ul>
&lt;h4 id="形状">形状
&lt;/h4>&lt;ul>
&lt;li>异形＞圆柱形&lt;/li>
&lt;li>异形，包括球釜、本釜、弧形等等&lt;/li>
&lt;/ul>
&lt;h3 id="加热方式">加热方式
&lt;/h3>&lt;p>远红外加热/多段IH电磁加热＞IH电磁加热＞三维立体加热＞底盘加热&lt;/p></description></item><item><title>机器学习（李宏毅）笔记 2：预测本频道观测人数（下）</title><link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-2%E9%A2%84%E6%B5%8B%E6%9C%AC%E9%A2%91%E9%81%93%E8%A7%82%E6%B5%8B%E4%BA%BA%E6%95%B0%E4%B8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-2%E9%A2%84%E6%B5%8B%E6%9C%AC%E9%A2%91%E9%81%93%E8%A7%82%E6%B5%8B%E4%BA%BA%E6%95%B0%E4%B8%8B/</guid><description>&lt;img src="https://example.com/post/img/5.jpg" alt="Featured image of post 机器学习（李宏毅）笔记 2：预测本频道观测人数（下）" />&lt;p>使用线性模型有很多缺点，比如&lt;strong>Model Bias&lt;/strong>（模型偏差）&lt;/p>
&lt;p>&lt;img src="https://example.com/img/%e5%87%bd%e6%95%b0.png"
loading="lazy"
alt="函数"
>&lt;/p>
&lt;p>红色的曲线可以表示为一系列蓝色曲线的和&lt;/p>
&lt;p>对于连续曲线函数，可以用一条分段线性函数来近似。为了有好的相似，我们需要足够多的片段&lt;/p>
&lt;p>&lt;img src="https://example.com/img/%e5%88%86%e6%ae%b5%e5%87%bd%e6%95%b0%e7%9a%84%e8%bf%91%e4%bc%bc.png"
loading="lazy"
alt="对于分段函数的近似"
>&lt;/p>
&lt;p>我们可以用&lt;code>sigmoid函数&lt;/code>来近似表示分段函数
$$
y,=,c \frac{1}{1,+,e^{-(b+wx_1)}}
$$&lt;/p>
&lt;p>也就是说，对于蓝色的曲线，我们有：
$$
曲线1：c_1sigmoid(b_1,+,w_1x_1)
$$
$$
曲线2：c_2sigmoid(b_2,+,w_2x_2)
$$
$$
&amp;hellip;
$$
$$
曲线i: c_isigmoid(b_i,+,w_ix_i)
$$&lt;/p>
&lt;p>因此，对于红色的曲线则有
$$
y,=,b,+,\sum_i c_isigmoid(b_i,+,w_ix_i)
$$&lt;/p>
&lt;blockquote>
&lt;p>$w_{ij}$: 对于第$i$个$Sigmoid$函数来说，$x_j$的权重 。&lt;/p>&lt;/blockquote>
&lt;p>对于:
$$
y,=,b,+,\sum_i c_isigmoid(b_i,+\sum_j,w_{ij}x_i)
$$
$i:1, 2, 3$: no. of sigmoid
$j: 1, 2,3$: no. of features&lt;/p>
&lt;p>（说实话第一次看见这个公式的时候还是比较懵的，之后通过一个具体的例子了解了这个公式）&lt;/p>
&lt;p>&lt;a class="link" href="https://xn--8mr985eba830aiye.vip/p/%e5%af%b9%e4%ba%8e%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%85%ac%e5%bc%8f%e7%9a%84%e4%be%8b%e5%ad%90/" target="_blank" rel="noopener"
>对于机器学习公式的例子&lt;/a>&lt;/p>
&lt;p>$$
r_1,=,b_1,+,w_{11}x_1,+,w_{12}x_2,+,w_{13}x_3
$$
$$
r_2,=,b_2,+,w_{21}x_1,+,w_{22}x_2,+,w_{23}x_3
$$
$$
r_3,=,b_3,+,w_{31}x_1,+,w_{32}x_2,+,w_{33}x_3
$$&lt;/p>
&lt;p>也即&lt;/p>
&lt;p>$$
\begin{bmatrix}
r_1\
r_2\
r_3
\end{bmatrix}=\begin{bmatrix}
b_1\
b_2\
b_3
\end{bmatrix}+
\begin{bmatrix}
w_{11} &amp;amp; w_{12} &amp;amp; w_{13}\
w_{21} &amp;amp; w_{22} &amp;amp; w_{23}\
w_{31} &amp;amp; w_{32} &amp;amp; w_{33}
\end{bmatrix}
\begin{bmatrix}
x_1\
x_2\
x_3
\end{bmatrix}
$$
故有&lt;/p>
&lt;p>$$
\mathbf{r},=,\mathbf{b},+,W,\mathbf{x}
$$&lt;/p>
&lt;p>不妨设$\mathbf{a}=\sigma{(r)}$
则有$y,=,b,+,\mathbf{c}^T\mathbf{a}$&lt;/p></description></item><item><title>机器学习（李宏毅）笔记 3：机器学习任务攻略</title><link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E6%94%BB%E7%95%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E6%94%BB%E7%95%A5/</guid><description>&lt;img src="https://example.com/post/img/6.jpg" alt="Featured image of post 机器学习（李宏毅）笔记 3：机器学习任务攻略" />&lt;h2 id="机器学习的框架">机器学习的框架
&lt;/h2>&lt;p>训练集：${(x^1,\widehat{y}^1),(x^2,\widehat{y}^2),&amp;hellip;,{x^n,\widehat{y}^n}}$&lt;/p>
&lt;p>测试集：${x^{n+1},x^{n+2}},&amp;hellip;,x^{n+m}$&lt;/p>
&lt;p>&lt;strong>训练步骤&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>带有未知参数的函数：$y=f_{\theta}(x)$&lt;/li>
&lt;li>根据训练数据定义损失函数：$L(\theta)$&lt;/li>
&lt;li>优化：$\theta ^{*}=arg min_{\theta}L$&lt;/li>
&lt;/ol>
&lt;h2 id="通用指南">通用指南
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-markdown" data-lang="markdown">&lt;span class="line">&lt;span class="cl">&lt;div id="" class="mindmap mindmap-md">&lt;ul>
&lt;li>loss on training data
&lt;ul>
&lt;li>large
&lt;ul>
&lt;li>model bias
&lt;ul>
&lt;li>make your model complex&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>optimization
&lt;ul>
&lt;li>next lecture&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>small
&lt;ul>
&lt;li>loss on testing data
&lt;ul>
&lt;li>small
&lt;ul>
&lt;li>＜（＾－＾）＞&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>large
&lt;ul>
&lt;li>overfitting
&lt;ul>
&lt;li>more training data&lt;/li>
&lt;li>data augmentation&lt;/li>
&lt;li>make your model simpler&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>mismatch&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="模型偏差和优化问题的对比">模型偏差和优化问题的对比
&lt;/h2>&lt;h3 id="模型偏差">模型偏差
&lt;/h3>&lt;ul>
&lt;li>模型过简单&lt;/li>
&lt;li>解决方式：重新设置你的模型，使其更加有弹性&lt;/li>
&lt;/ul>
&lt;h3 id="优化问题">优化问题
&lt;/h3>&lt;ol>
&lt;li>通过对比获得洞见
&lt;ol>
&lt;li>当深层网络效果不如浅层网络时，需排除模型容量不足的可能。&lt;/li>
&lt;li>若浅层网络能拟合训练数据，而深层网络不能，说明优化存在问题（而非模型表达能力不足）。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>从较浅的网络开始训练
&lt;ol>
&lt;li>浅层网络更容易优化（梯度传播路径短，参数少）。&lt;/li>
&lt;li>若浅层网络能正常训练，但加深后效果变差，可定位到优化问题（如梯度消失/爆炸）。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>深层网络训练损失不降
&lt;ol>
&lt;li>深层网络的假设空间包含浅层网络（例如深层网络的前几层可模拟浅层网络）。&lt;/li>
&lt;li>理论上，深层网络在训练数据上的损失应 ≤ 浅层网络损失（因其模型容量更大）。&lt;/li>
&lt;li>若实际训练中深层网络损失更高，说明优化器未能找到更优解（而非模型能力不足）。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="模型复杂度和损失的关系">模型复杂度和损失的关系
&lt;/h3>&lt;h4 id="1-训练损失training-loss">&lt;strong>1. 训练损失（Training Loss）&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>规律&lt;/strong>：随着模型复杂度增加，训练损失单调递减。&lt;/li>
&lt;li>&lt;strong>原因&lt;/strong>：复杂模型有更强的拟合能力，可以逼近甚至完美拟合训练数据。&lt;/li>
&lt;li>&lt;strong>极端情况&lt;/strong>：过参数化模型（如深度神经网络）可实现训练损失趋近于零（记忆训练样本）。&lt;/li>
&lt;/ul>
&lt;h4 id="2-验证测试损失validationtest-loss">&lt;strong>2. 验证/测试损失（Validation/Test Loss）&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>
&lt;p>规律&lt;/p>
&lt;p>：先降低后升高，形成U型曲线。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>低复杂度&lt;/strong>：模型无法捕捉数据规律（欠拟合），损失较高。&lt;/li>
&lt;li>&lt;strong>适当复杂度&lt;/strong>：模型拟合数据真实分布，损失最低。&lt;/li>
&lt;li>&lt;strong>高复杂度&lt;/strong>：模型过度拟合噪声（过拟合），损失回升。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>数学解释：
$$
泛化误差=偏差^2+方差+不可约方差
$$&lt;/p>
&lt;h3 id="训练资料和测试资料的mismatch">训练资料和测试资料的mismatch
&lt;/h3>&lt;p>&lt;strong>原因：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>训练集和测试集的特征（如数值范围、类别比例）差异大。&lt;/li>
&lt;li>分类任务中类别比例差异，或回归任务中目标值范围不同。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>体现：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>训练集表现&lt;/strong>：模型损失低、准确率高（看似“表现优秀”）。&lt;/li>
&lt;li>&lt;strong>测试集表现&lt;/strong>：损失显著升高、准确率骤降（模型无法泛化）。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>解决办法（举例）&lt;/strong>：&lt;/p>
&lt;ol>
&lt;li>将数据集分为A, B, C三份&lt;/li>
&lt;li>首先用A, B作为训练集，C为测试集&lt;/li>
&lt;li>第二次用A, C作为训练集，B为测试集&lt;/li>
&lt;li>第三次用B, C作为训练集，A为测试集&lt;/li>
&lt;/ol></description></item><item><title>机器学习（李宏毅）笔记 4：局部最小值与鞍点</title><link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-4%E5%B1%80%E9%83%A8%E6%9C%80%E5%B0%8F%E5%80%BC%E4%B8%8E%E9%9E%8D%E7%82%B9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-4%E5%B1%80%E9%83%A8%E6%9C%80%E5%B0%8F%E5%80%BC%E4%B8%8E%E9%9E%8D%E7%82%B9/</guid><description>&lt;img src="https://example.com/post/img/7.jpg" alt="Featured image of post 机器学习（李宏毅）笔记 4：局部最小值与鞍点" />&lt;h2 id="critical-point情况">Critical Point情况
&lt;/h2>&lt;ol>
&lt;li>&lt;strong>局部最小值（local minima）&lt;/strong>。如果是**卡在local minima,那可能就没有路可以走了，**因为四周都比较高，你现在所在的位置已经是最低的点，loss最低的点了，往四周走 loss都会比较高，你会不知道怎么走到其他地方去。&lt;/li>
&lt;li>&lt;strong>鞍点（saddle point）&lt;/strong>。（如图可看出，左右是比红点高，前后比红点低，红点既不是local minima,也不是local maxima的地方）如果是卡在saddle point，saddle point旁边还是有其他路可以让你的loss更低的，你只要逃离saddle point，你就有可能让你的loss更低。&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://example.com/img/%e5%b1%80%e9%83%a8%e6%9c%80%e5%b0%8f%e5%80%bc.png"
loading="lazy"
alt="局部最小值"
>&lt;/p>
&lt;p>&lt;img src="https://example.com/img/%e9%9e%8d%e7%82%b9.png"
loading="lazy"
alt="鞍点"
>&lt;/p>
&lt;h2 id="确定critical-point类型">确定Critical Point类型
&lt;/h2>&lt;p>使用泰勒级数近似
$$
L(\theta)\approx L(\theta ^{&amp;rsquo;})+L(\theta - \theta^{&amp;rsquo;})g+\frac{1}{2}(\theta-\theta^{&amp;rsquo;})^{T}H(\theta-\theta ^{&amp;rsquo;})
$$
&lt;strong>计算Hessian矩阵的特征值&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>正定&lt;/strong>（所有特征值 &amp;gt; 0）→ &lt;strong>局部极小值&lt;/strong>&lt;/li>
&lt;li>&lt;strong>负定&lt;/strong>（所有特征值 &amp;lt; 0）→ &lt;strong>局部极大值&lt;/strong>&lt;/li>
&lt;li>&lt;strong>不定&lt;/strong>（特征值有正有负）→ &lt;strong>鞍点&lt;/strong>&lt;/li>
&lt;li>&lt;strong>半正定/半负定&lt;/strong>（存在零特征值）→ &lt;strong>需更高阶分析&lt;/strong>（如退化临界点）&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>具体例子&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>案例1：正定Hessian → 局部极小值&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>$$
H=\begin{bmatrix}
2 &amp;amp; 1 \
1 &amp;amp; 2
\end{bmatrix}
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>特征值&lt;/strong>：3和1（均 &amp;gt; 0）→ 正定&lt;/li>
&lt;li>&lt;strong>结论&lt;/strong>：局部极小值&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>&lt;strong>案例2：负定Hessian → 局部极大值&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>$$
H=\begin{bmatrix}
-2 &amp;amp; 0 \
0 &amp;amp; -2
\end{bmatrix}
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>特征值&lt;/strong>：-2 和 -2（均 &amp;lt; 0）→ 负定&lt;/li>
&lt;li>&lt;strong>结论&lt;/strong>：局部极大值。&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>&lt;strong>案例3：不定Hessian → 鞍点&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>$$
H = \begin{bmatrix}
2 &amp;amp; 0 \
0 &amp;amp; -2
\end{bmatrix}
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>特征值&lt;/strong>：2 和 -2（有正有负）→ 不定&lt;/li>
&lt;li>&lt;strong>结论&lt;/strong>：鞍点&lt;/li>
&lt;/ul>
&lt;h2 id="逃离saddle-point">逃离Saddle Point
&lt;/h2>&lt;h3 id="利用hessian矩阵逃离鞍点saddle-point">利用Hessian矩阵逃离鞍点（Saddle Point）
&lt;/h3>&lt;p>&lt;strong>核心思想&lt;/strong>：通过Hessian矩阵的负特征值对应的特征向量方向更新参数，使优化方向逃离鞍点。&lt;/p>
&lt;p>&lt;strong>具体步骤&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1. 检测鞍点&lt;/strong>
&lt;ul>
&lt;li>计算梯度$\nabla f$，若$||\nabla f|| \approx 0$，则可能为临界点&lt;/li>
&lt;li>计算Hessian矩阵$H$，并分析其特征值&lt;/li>
&lt;li>若存在负特征值，则为鞍点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>2. 找到负曲率方向&lt;/strong>
&lt;ul>
&lt;li>对Hessian矩阵进行特征分解，找到最小特征值$\lambda_{\min} &amp;lt; 0$及其对应的特征向量$v_{\min}$。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>3. 沿负曲率方向更新参数&lt;/strong>
&lt;ul>
&lt;li>选择步长$\eta$（通常与学习率相关），沿$v_{min}$方向更新参数：$\theta_{new}=\theta_{old}+\eta v_{min}$&lt;/li>
&lt;li>**验证方向：**通过计算$\theta_{new}=\theta_{old}+\eta v_{min}$和$\theta_{new}=\theta_{old}-\eta v_{min}$，选择使函数值下降的方向&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>4. 迭代直至逃离&lt;/strong>
&lt;ul>
&lt;li>重复步骤1-3，直到梯度不再接近0或Hessian矩阵变为正定（局部最小值）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="利用momentum逃离鞍点">利用momentum逃离鞍点
&lt;/h3>&lt;h4 id="动量法的基本原理">&lt;strong>动量法的基本原理&lt;/strong>
&lt;/h4>&lt;p>动量法（Momentum）是梯度下降的改进版本，通过&lt;strong>积累历史梯度方向&lt;/strong>加速收敛并抑制振荡。其更新公式为：
$$
v_t = \beta v_{t-1} + (1-\beta) \nabla f(\theta_t)
$$&lt;/p>
&lt;p>$$
\theta{t+1} = \theta_t - \eta v_t
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>动量系数&lt;/strong>：$$\beta \in [0, 1)$$，通常取0.9或0.99。&lt;/li>
&lt;li>&lt;strong>核心思想&lt;/strong>：梯度方向被赋予“惯性”，在平坦区域（如鞍点）积累动量，帮助逃离。&lt;/li>
&lt;/ul>
&lt;h4 id="动量如何帮助逃离鞍点">&lt;strong>动量如何帮助逃离鞍点？&lt;/strong>
&lt;/h4>&lt;p>鞍点的特征：梯度$$\nabla f \approx 0$$，但Hessian矩阵存在&lt;strong>负曲率方向&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>梯度下降的缺陷&lt;/strong>：在鞍点附近，梯度接近零，参数更新停滞。&lt;/li>
&lt;li>&lt;strong>动量的优势&lt;/strong>：
&lt;ol>
&lt;li>&lt;strong>历史梯度累积&lt;/strong>：即使当前梯度为零，动量项$$v_t$$仍可能保留之前方向的惯性。&lt;/li>
&lt;li>&lt;strong>噪声放大&lt;/strong>：随机梯度（如SGD的小批量噪声）会被动量放大，打破对称性。&lt;/li>
&lt;li>&lt;strong>负曲率方向探索&lt;/strong>：动量推动参数沿历史梯度方向移动，可能进入负曲率区域。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="动量逃离鞍点的数学解释">&lt;strong>动量逃离鞍点的数学解释&lt;/strong>
&lt;/h4>&lt;p>假设在鞍点附近，梯度方向存在随机扰动$$\epsilon_t$$（如小批量噪声）：
$$
\nabla f(\theta_t) = \epsilon_t \quad (\mathbb{E}[\epsilon_t] = 0, \text{Var}(\epsilon_t) = \sigma^2)
$$
动量更新公式变为：
$$
v_t = \beta v_{t-1} + (1-\beta) \epsilon_t
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>动量积累&lt;/strong>：经过$$k$$步后，动量近似为：
$$
v_t \approx (1-\beta) \sum_{i=0}^{k} \beta^{k-i} \epsilon_i
$$&lt;/li>
&lt;li>&lt;strong>逃离机制&lt;/strong>：噪声的加权和可能指向负曲率方向，使参数突破鞍点。&lt;/li>
&lt;/ul>
&lt;h4 id="具体步骤与算法">&lt;strong>具体步骤与算法&lt;/strong>
&lt;/h4>&lt;h5 id="步骤1初始化动量">&lt;strong>步骤1：初始化动量&lt;/strong>
&lt;/h5>&lt;p>设置初始动量$$v_0 = 0$$，选择动量系数$\beta$和学习率$\eta$。&lt;/p>
&lt;h5 id="步骤2迭代更新">&lt;strong>步骤2：迭代更新&lt;/strong>
&lt;/h5>&lt;p>对每次迭代$t$：&lt;/p>
&lt;ol>
&lt;li>计算当前梯度$\nabla f(\theta_t)$（可含噪声，如SGD）。&lt;/li>
&lt;li>更新动量：
$$
v_t = \beta v_{t-1} + (1-\beta) \nabla f(\theta_t)
$$&lt;/li>
&lt;li>更新参数：
$$
\theta_{t+1} = \theta_t - \eta v_t
$$&lt;/li>
&lt;/ol>
&lt;h5 id="步骤3逃离鞍点的动态">&lt;strong>步骤3：逃离鞍点的动态&lt;/strong>
&lt;/h5>&lt;ul>
&lt;li>&lt;strong>鞍点附近&lt;/strong>：梯度$\nabla f \approx 0$，但动量$v_t$可能因历史梯度或噪声不为零。&lt;/li>
&lt;li>&lt;strong>持续更新&lt;/strong>：动量推动参数离开平坦区域，进入梯度较大的区域。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h4 id="实验案例动量法逃离二元鞍点">&lt;strong>实验案例：动量法逃离二元鞍点&lt;/strong>
&lt;/h4>&lt;h5 id="目标函数">&lt;strong>目标函数&lt;/strong>
&lt;/h5>&lt;p>$$
f(x, y) = x^2 - y^2
$$&lt;/p>
&lt;ul>
&lt;li>&lt;strong>鞍点&lt;/strong>：$(0, 0)$，Hessian矩阵特征值为$2$和$-2$。&lt;/li>
&lt;/ul>
&lt;h5 id="参数设置">&lt;strong>参数设置&lt;/strong>
&lt;/h5>&lt;ul>
&lt;li>初始点：$(0.1, 0.1)$，学习率$\eta = 0.1$，动量系数$\beta = 0.9$。&lt;/li>
&lt;/ul>
&lt;h5 id="迭代过程">&lt;strong>迭代过程&lt;/strong>
&lt;/h5>&lt;ol>
&lt;li>&lt;strong>第1步&lt;/strong>：梯度$\nabla f = (0.2, -0.2)$，动量$v_1 = 0.1 \times (0.2, -0.2)$，更新后点$(0.08, 0.12)$。&lt;/li>
&lt;li>&lt;strong>第2步&lt;/strong>：梯度$\nabla f = (0.16, -0.24)$，动量$v_2 = 0.9v_1 + 0.1 \times (0.16, -0.24)$，更新后点$(0.064, 0.144)$。&lt;/li>
&lt;li>&lt;strong>持续迭代&lt;/strong>：动量在$y$方向逐渐积累，推动逃离鞍点区域。&lt;/li>
&lt;/ol>
&lt;h4 id="动量法的理论支持">&lt;strong>动量法的理论支持&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>收敛性证明&lt;/strong>：在凸函数中，动量法可加速收敛（Nesterov加速）。&lt;/li>
&lt;li>&lt;strong>逃离鞍点能力&lt;/strong>：
&lt;ul>
&lt;li>&lt;strong>随机梯度（SGD）&lt;/strong>：噪声+动量可概率性逃离鞍点（Ge et al., 2015）。&lt;/li>
&lt;li>&lt;strong>确定性梯度&lt;/strong>：动量法需依赖Hessian的负曲率方向隐含在历史梯度中。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="与其他方法的对比">&lt;strong>与其他方法的对比&lt;/strong>
&lt;/h4>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>方法&lt;/strong>&lt;/th>
&lt;th>&lt;strong>逃离鞍点机制&lt;/strong>&lt;/th>
&lt;th>&lt;strong>计算成本&lt;/strong>&lt;/th>
&lt;th>&lt;strong>适用场景&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>动量法&lt;/strong>&lt;/td>
&lt;td>历史梯度惯性 + 噪声放大&lt;/td>
&lt;td>低（一阶）&lt;/td>
&lt;td>高维、随机优化（如深度学习）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Hessian矩阵法&lt;/strong>&lt;/td>
&lt;td>显式利用负曲率方向&lt;/td>
&lt;td>高（二阶）&lt;/td>
&lt;td>低维、确定性优化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>SGD + 扰动&lt;/strong>&lt;/td>
&lt;td>纯随机噪声探索&lt;/td>
&lt;td>低（一阶）&lt;/td>
&lt;td>大规模非凸优化&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="实际应用技巧">&lt;strong>实际应用技巧&lt;/strong>
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>动量系数选择&lt;/strong>：$\beta$越大，惯性越强，但可能“冲过头”。常用$\beta=0.9$。&lt;/li>
&lt;li>&lt;strong>与自适应方法结合&lt;/strong>：如Adam（动量+RMSProp），平衡方向与步长。&lt;/li>
&lt;li>&lt;strong>学习率调整&lt;/strong>：在鞍点附近可短暂增大学习率以加速逃离。&lt;/li>
&lt;/ul>
&lt;h4 id="优缺点分析">&lt;strong>优缺点分析&lt;/strong>
&lt;/h4>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>优点&lt;/strong>&lt;/th>
&lt;th>&lt;strong>缺点&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>低计算成本，适合高维问题。&lt;/td>
&lt;td>无显式二阶信息，依赖噪声或历史梯度。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>天然抗噪声，适合随机优化。&lt;/td>
&lt;td>对某些鞍点（如高阶退化点）可能失效。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>易与其他优化器结合（如Adam）。&lt;/td>
&lt;td>需调参（$\beta$, $\eta$）。&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>机器学习（李宏毅）笔记 5：批次与动量</title><link>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-5%E6%89%B9%E6%AC%A1%E4%B8%8E%E5%8A%A8%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%8E%E5%AE%8F%E6%AF%85%E7%AC%94%E8%AE%B0-5%E6%89%B9%E6%AC%A1%E4%B8%8E%E5%8A%A8%E9%87%8F/</guid><description>&lt;img src="https://example.com/post/img/8.jpg" alt="Featured image of post 机器学习（李宏毅）笔记 5：批次与动量" />&lt;h2 id="批次batch与动量momentum">批次（batch）与动量（momentum）
&lt;/h2>&lt;h3 id="批次">批次
&lt;/h3>&lt;ol>
&lt;li>&lt;strong>小批量梯度下降（Mini-batch Gradient Descent）&lt;/strong>
&lt;ol>
&lt;li>在训练模型时，不直接使用全部数据计算梯度，而是将数据划分为多个小批量（batch），每次用一个batch的数据计算损失（Loss）和梯度，并更新模型参数。&lt;/li>
&lt;li>相比全量梯度下降（计算所有数据），减少内存占用和计算量，同时比随机梯度下降（单个样本）更稳定。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>Batch（批次）与Epoch（轮次）&lt;/strong>
&lt;ol>
&lt;li>&lt;strong>Batch&lt;/strong>：将训练数据分成若干固定大小的子集（如B个样本），每个子集称为一个batch。&lt;/li>
&lt;li>&lt;strong>Epoch&lt;/strong>：完整遍历一次全部训练数据的过程（即所有batch被计算一遍）。每个epoch结束后，模型完成一次完整训练。&lt;/li>
&lt;li>&lt;strong>关系&lt;/strong>：1个epoch = 所有batch依次计算并更新参数。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>参数更新机制&lt;/strong>
&lt;ol>
&lt;li>&lt;strong>逐batch更新&lt;/strong>：每个batch计算一次Loss和梯度后，立即更新参数（而非累积所有batch的梯度再更新）。&lt;/li>
&lt;li>&lt;strong>优点&lt;/strong>：加快收敛速度，避免全量数据计算的资源瓶颈。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>&lt;strong>Shuffle&lt;/strong>
&lt;ol>
&lt;li>&lt;strong>作用&lt;/strong>：在每个epoch开始前，随机打乱训练数据的顺序，再划分batch。&lt;/li>
&lt;li>&lt;strong>目的&lt;/strong>：防止模型因数据顺序产生偏差（如学习到数据排列规律），增强泛化能力。&lt;/li>
&lt;li>&lt;strong>结果&lt;/strong>：每个epoch的batch组成不同，提升训练随机性。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://example.com/img/batch.png"
loading="lazy"
>&lt;/p>
&lt;p>为什么训练时需要用batch？&lt;/p>
&lt;p>参数更新更快，每看一笔资料即会更新一次参数&lt;/p>
&lt;p>&lt;img src="https://example.com/img/batch%e6%af%94%e8%be%83.png"
loading="lazy"
alt="左侧无batch，右侧的batch size为1"
>&lt;/p>
&lt;h3 id="small-batch-vs-large-batch">Small batch vs Large batch
&lt;/h3>&lt;ul>
&lt;li>没有平行运算时，Small Batch比Large Batch更有效&lt;/li>
&lt;li>有平行运算时，Small Batch与Large Batch运算时间没有太大差距，除非大的超出一定界限&lt;/li>
&lt;li>在一个epoch时间内，Large Batch比Small Batch更快，Large Batch更有效率&lt;/li>
&lt;li>Small Batch比较陡，Large Batch比较稳定&lt;/li>
&lt;li>比较noisy的batch size比比较stable 的batch size在训练和测试时占有优势&lt;/li>
&lt;/ul>
&lt;h2 id="自动调整学习率">自动调整学习率
&lt;/h2>&lt;p>随着参数的更新，loss值逐渐变小并保持在一定值不再下降&lt;/p>
&lt;p>&lt;img src="https://example.com/img/%e8%b0%83%e6%95%b4%e5%ad%a6%e4%b9%a0%e7%8e%87.png"
loading="lazy"
>&lt;/p>
&lt;p>将gradient decent做的更好的方法是设置每一个参数的学习效率&lt;/p>
&lt;ul>
&lt;li>如果在某一个方向上，gradient值很小（比较平稳），那么应该把学习效率调高；&lt;/li>
&lt;li>如果在某一个方向上，gradient值很大（比较陡峭），那么应该把学习效率调低。&lt;/li>
&lt;/ul></description></item><item><title>论文笔记：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title><link>https://example.com/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/</guid><description>&lt;img src="https://example.com/post/img/26.jpg" alt="Featured image of post 论文笔记：DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning" />&lt;h2 id="知识笔记">知识笔记
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;strong>多阶段训练(multi-stage training)&lt;/strong>：指模型训练过程中分为多个阶段（阶段间目标或数据不同），每个阶段针对性地优化模型的不同能力，最终提升整体性能。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>冷启动数据(cold start data)&lt;/strong>：指在模型训练初期（或新任务启动时）使用的特定引导数据，用于解决模型初期因缺乏足够信息导致的性能低下或不稳定问题。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>训练后阶段&lt;/strong>：指在机器学习模型完成训练后的一系列操作，包括模型评估、优化、部署、监控等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>预训练与训练的差别&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>预训练&lt;/strong>：在大规模通用数据集上进行&lt;/li>
&lt;li>&lt;strong>训练&lt;/strong>：在特定任务上调整模型参数的过程&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>推理导向的强化学习(Reasoning-Oriented RL)&lt;/strong>：动态奖励机制和结构化探索策略&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://arxiv.org/pdf/2501.12948" target="_blank" rel="noopener"
>原文传送门&lt;/a>&lt;/p>
&lt;p>膜拜大佬&lt;/p>
&lt;h2 id="读书笔记">读书笔记
&lt;/h2>&lt;h3 id="abstract">Abstract
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>DeepSeek-R1-Zero&lt;/strong>
&lt;ul>
&lt;li>通过强化学习训练，且没监督微调&lt;/li>
&lt;li>推理能力优秀&lt;/li>
&lt;li>可读性差，语言混合&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>DeepSeek-R1&lt;/strong>
&lt;ul>
&lt;li>在强化学习之前结合多阶段训练和冷启动数据&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="introduction">Introduction
&lt;/h3>&lt;ul>
&lt;li>训练后阶段可提高推理任务的准确性
&lt;ul>
&lt;li>所需计算资源比预训练少&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>OpenAI o1引入了思考时间
&lt;ul>
&lt;li>有效的测试时间缩放的挑战依旧是一个问题&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>使用纯强化学习过程的自我进化，使得DeepSeek-R1-Zero在推理基准测试上与OpenAI-01相当
&lt;ul>
&lt;li>使用DeepSeek-v3-Base作为基础模型&lt;/li>
&lt;li>采用PRPO作为强化学习框架&lt;/li>
&lt;li>可读性差，语言混乱&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>引入DeepSeek-R1。结合少量冷启动数据和多级训练流水线
&lt;ul>
&lt;li>&lt;strong>冷启动数据微调&lt;/strong>：修复基础语言能力
&lt;ul>
&lt;li>收集数千条高质量冷启动数据（例如：人工标注的数学解题步骤、语法规范的写作范文）&lt;/li>
&lt;li>用这些数据对基础模型 &lt;code>DeepSeek-V3-Base&lt;/code> 进行监督微调（SFT）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>推理导向的RL训练&lt;/strong>：提升特定任务的推理能力
&lt;ul>
&lt;li>使用强化学习（如PPO算法）训练模型，奖励函数侧重推理正确性（如解题步骤分、最终答案分）。&lt;/li>
&lt;li>训练接近收敛时，模型能稳定生成正确但可能可读性较差的答案&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>拒绝采样生成新SFT数据&lt;/strong>：从RL模型的结果中提取高质量数据，重新注入监督训练
&lt;ul>
&lt;li>让RL模型的结果中提取高质量数据，重新注入监督训练&lt;/li>
&lt;li>通过规则或奖励模型筛选出推理正确且可读性高的结果（例如保留前10%的优质答案）&lt;/li>
&lt;li>混入新RL数据和原有监督数据&lt;/li>
&lt;li>用混合数据重新微调DeepSeek-V3-Base&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>全场景二次RL训练&lt;/strong>：在多任务竞争中进一步平衡性能
&lt;ul>
&lt;li>输入涵盖所有任务的提示（如同时包含数学题、写作要求、事实问答）&lt;/li>
&lt;li>设计多维度奖励函数，如数学任务：步骤正确性+答案准确性；写作任务：流畅性+语法正确性&lt;/li>
&lt;li>基于混合奖励进行RL训练，迫使模型兼顾多领域性能&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="核心贡献">核心贡献
&lt;/h4>&lt;ol>
&lt;li>
&lt;p>&lt;strong>后训练(Post-Training)&lt;/strong>：直接对基础模型进行大规模强化学习（RL）&lt;/p>
&lt;ol>
&lt;li>创新点
&lt;ol>
&lt;li>跳过监督微调(SFT)&lt;/li>
&lt;li>激励模型自主探索思维链(CoT)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>意义：证明纯RL训练可激发LLM推理能力（无需SFT提供参考答案）&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-TEXT" data-lang="TEXT">&lt;span class="line">&lt;span class="cl">步骤1：将方程改写为 3x² - 2x - 8 = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">步骤2：尝试因式分解 → 失败 → 反思：“可能需要使用求根公式。”
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">步骤3：应用求根公式 x = [2 ± √(4 + 96)] / 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">步骤4：计算判别式 √100 = 10 → x = (2 ± 10)/6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">步骤5：验证解是否满足原方程 → 确认 x=2 和 x=-4/3 均为解
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>开发流程
&lt;ol>
&lt;li>&lt;strong>第一阶段RL&lt;/strong>：基于基础模型进行RL训练，奖励函数侧重推理正确性。探索更优推理模式（如数学解题策略、代码调试逻辑）&lt;/li>
&lt;li>&lt;strong>第一阶段SFT&lt;/strong>：混合RL生成的优质推理数据与通用领域SFT数据。固化RL探索到的优质推理模式，并补充非推理能力（如写作、对话）。&lt;/li>
&lt;li>&lt;strong>第二阶段RL&lt;/strong>：引入人类反馈（如人工标注偏好排序）优化奖励模型。对齐人类偏好（如可读性、安全性）&lt;/li>
&lt;li>&lt;strong>第二阶段SFT&lt;/strong>：平衡多任务性能，防止RL过度优化单一领域&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>蒸馏(Distillation)&lt;/strong>：让小模型继承大模型推理能力&lt;/p>
&lt;ol>
&lt;li>&lt;strong>核心思想&lt;/strong>：用大模型生成的推理数据训练小模型，使其超越RL训练的小模型&lt;/li>
&lt;li>降低推理成本，促进小模型实际应用&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;h3 id="discussion">Discussion
&lt;/h3>&lt;h4 id="蒸馏和强化学习的比较">蒸馏和强化学习的比较
&lt;/h4>&lt;ul>
&lt;li>将更强大的模型提炼成更小的模型可以得到很好的结果，而依赖于大规模RL的模型需要巨大的计算能力，甚至可能达不到提炼的性能&lt;/li>
&lt;li>尽管提炼策略既经济又有效，但要超越智能的界限，可能仍然需要更强大的基础模型和更大规模的强化学习&lt;/li>
&lt;/ul>
&lt;h4 id="未成功的尝试">未成功的尝试
&lt;/h4>&lt;ul>
&lt;li>&lt;strong>过程奖励模型(Process Reward Model, PRM)&lt;/strong>
&lt;ul>
&lt;li>在一般推理中明确定义一个细粒度的步骤是一个挑战&lt;/li>
&lt;li>确定当前中间步骤是否正确是一项具有挑战性的任务&lt;/li>
&lt;li>一旦引入了基于模型的PRM，就不可避免地会导致奖励黑客行为。而重新培训奖励模型需要额外的培训资源，这使整个培训流程变得复杂&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>蒙特卡洛树搜索(Monte Carlo Tree Search, MCTS)&lt;/strong>
&lt;ul>
&lt;li>将答案分解为更小的部分，以允许模型系统地探索解决方案空间&lt;/li>
&lt;li>为了方便这一点，提示模型生成多个标签，这些标签对应于搜索所需的特定推理步骤&lt;/li>
&lt;li>难点：
&lt;ul>
&lt;li>token的生成有很多空间。解决方案：为每个节点设置最大扩展限制，但可能会陷入局部最优&lt;/li>
&lt;li>价值模型直接影响生成的质量&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item></channel></rss>